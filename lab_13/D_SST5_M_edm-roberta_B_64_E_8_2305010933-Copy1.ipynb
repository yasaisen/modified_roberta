{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_SST5_M_edm-roberta_B_64_E_8\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'SST5'\n",
    "# DATASET = 'SST2'\n",
    "BSZ = 64\n",
    "EPOCH = 8\n",
    "# MODEL = 'bert'\n",
    "# MODEL = 'roberta'\n",
    "# MODEL = 'xlnet'\n",
    "# MODEL = 'distilbert'\n",
    "MODEL = 'edm-roberta'\n",
    "\n",
    "KOKONOTEST = 'D_' + DATASET + '_M_' + MODEL + '_B_' + str(BSZ) + '_E_' + str(EPOCH)\n",
    "print(KOKONOTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  2 06:42:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 30%   34C    P2    52W / 200W |   8621MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (23.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-sbivll11\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git': 'git' while executing command git version\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: fastai==1.0.58 in /opt/conda/lib/python3.7/site-packages (1.0.58)\n",
      "Requirement already satisfied: bottleneck in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.3.7)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (4.9.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.4.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.8.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.18.1)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (7.352.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (20.9)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (5.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.22.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.9.0+cu111)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.5.2)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (0.10.0+cu111)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.42.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.11.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (45.2.0.post20200210)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->fastai==1.0.58) (2.4.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2020.4.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->fastai==1.0.58) (2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai==1.0.58) (2019.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fastai==1.0.58) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.18.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (7.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.7/site-packages (0.1.98)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mtokenizers             0.13.3\n",
      "transformers           4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q transformers==4.28.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install fastai==1.0.58\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install SentencePiece\n",
    "    \n",
    "!pip list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version: 1.0.58\n",
      "transformers version: 4.28.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version: %s' %(fastai.__version__))\n",
    "print('transformers version: %s' %(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu vars\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True # speed up with gpu\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449287,
     "status": "ok",
     "timestamp": 1681898134125,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YPh_dtQJJhej",
    "outputId": "36283b7b-0e31-41ea-8815-1eba40f7d2fb",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681898192514,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZEvggolFoRbH",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def checkpath(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681898192514,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "RbdAfW1vHmbn",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# for dirname, _, filenames in os.walk('/content/drive/My Drive/LAB/kge_sentiment_anlysis'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "K8ol3_URCad5",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#  # tokenizer version\n",
    "# Version = 'T_v_1.3.3'\n",
    "\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "\n",
    "# tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "fgSOFnkTEMwv",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    " # model version\n",
    "Version = 'M_v_7.0.0'\n",
    "\n",
    "root_folder = os.path.abspath(os.path.join(ROOT_PATH, Version))\n",
    "\n",
    "model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "checkpath(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1681898193371,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6ZSnPW0GPA9V",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Data selection\n",
    "\n",
    "if DATASET == 'SST5':\n",
    "    dataset = 'SST5'\n",
    "    DATA_ROOT = Path(os.path.join(ROOT_PATH, 'finetune_dataset/kge_sentiment_analysis'))\n",
    "    train_cols = 'Phrase'\n",
    "    label_cols = 'Sentiment'\n",
    "    classification_head = 5\n",
    "elif DATASET == 'SST2':\n",
    "    dataset = 'SST2'\n",
    "    DATA_ROOT = Path(os.path.join(ROOT_PATH, 'finetune_dataset/IMDB_MovieReviews'))\n",
    "    train_cols = 'review'\n",
    "    label_cols = 'sentiment'\n",
    "    classification_head = 2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "\n",
    "lr = 1e-5\n",
    "bsz = BSZ\n",
    "epoch = EPOCH\n",
    "\n",
    "# model_name = 'bsz2048_DEM-RoBERTa.pkl'\n",
    "\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "BOOM = 4\n",
    "\n",
    "# Model selection\n",
    "\n",
    "if MODEL == 'bert':\n",
    "    model_type = 'bert'\n",
    "    pretrained_model_name='bert-base-uncased'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'roberta':\n",
    "    model_type = 'roberta'\n",
    "    pretrained_model_name = 'roberta-large'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'xlnet':\n",
    "    model_type = 'xlnet'\n",
    "    pretrained_model_name = 'xlnet-base-cased'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'distilbert':\n",
    "    model_type = 'distilbert'\n",
    "    pretrained_model_name = 'distilbert-base-uncased'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'edm-roberta':\n",
    "    model_type = 'roberta'\n",
    "    pretrained_model_name = 'roberta-large'\n",
    "    pretrained_tokenizer_name = pretrained_model_name#tokenizer_folder\n",
    "    EDM = True\n",
    "\n",
    "# model_type = 'xlm'\n",
    "# pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "# pretrained_tokenizer_name = pretrained_model_name\n",
    "# EDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1681898194705,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YI1PkOgsK7Vc",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST5'):\n",
    "  train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
    "  test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "vckhJ1W1BMKO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST2'):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  df = pd.read_csv(DATA_ROOT / 'IMDB_Dataset.csv.zip')\n",
    "  df['Sentiment'] = df['sentiment'].replace(['negative', 'positive'], [0, 1])\n",
    "  train, test = train_test_split(df, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "m9pUQJP2Bgyy",
    "outputId": "7d961fd5-bfc6-4820-8d1b-5c8cf9f62bb1",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ9ZzGHlPPo0"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZSBBSBpZPODx",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type='bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.model_max_length\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] + [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUnibZpXdnVF"
   },
   "source": [
    "- bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "\n",
    "- distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- xlnet:      padding + tokens + [SEP] + [CLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "qfSwieon8K-N",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# # from transformers import RobertaTokenizerFast\n",
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "# MAX_LEN = 128\n",
    "# # Create the tokenizer from a trained one\n",
    "# # transformer_tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)\n",
    "# transformer_tokenizer = RobertaTokenizer.from_pretrained(tokenizer_folder)#, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9f9ee57980f64607aed63201e44d2263",
      "0d1764eea96f42b59b0613a32675d84c",
      "af7c57c570614472b160423724a07590",
      "e388830b59ba4f9d837ea6cdb9c698e7",
      "a46848278e9a45bdbf87f4513a5da72a",
      "ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "4f06c58c7d7f4db499237ce58193f37c",
      "d14ec50a29224593a87a902c5a23d581",
      "7f018262d1a047109366e216f9e83e64",
      "5e4d7c27ceab4bf5bd780770c6b829fb",
      "10c337408ee34116ab68750ca4016873",
      "332a2f4786154442b5296395129c2e71",
      "28c07e0b489a4929926d1002df24b091",
      "016e9d4951dc4ffaa116b68651b5a5e9",
      "38edf987d8fc4ce58ec72c4ed0e4ed67",
      "c12a0a03c11641d996cedcb2554837e7",
      "ef60fa55102d4902b9ddbcc45b6090ab",
      "8532ee00cdbe476796eaec8355396cea",
      "82ac39008291438abe8a0cdec6d0b48e",
      "5f0efcec51584512801c27a3cd6955c1",
      "1ff839855735448bafa7c923e3c82058",
      "c99275e215d44398809e6d5accd8f6b4",
      "132793e6053c41a5a775a7b4d3dc190c",
      "870b2aaafdab485c9c84d37ca50e3751",
      "18192a8ad1094e05bb8679cdc82b0015",
      "19dd2d607cc7428093d7974a3dc630c5",
      "7628994d5e6f4802a9a7edb25a3d3da9",
      "66ab18b60f5e4294b4309d3fd293e7a4",
      "c5dfa7b8af9448b1b4cb3b10812a9102",
      "4931528732d14b7da8a4bc12fc66acd3",
      "800850935d4d4d41973e053ff7e9be7d",
      "65077ad08d2a4d869053cf49875ac04c",
      "1f23acd2e5414a2493bc041d17d35d65"
     ]
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1681898196569,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zZGIeSCFXoGz",
    "outputId": "42421471-3daf-48c5-a1c2-ea3f120450a4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_tokenizer_name)\n",
    "transformer_tokenizer.model_max_length = 128#512\n",
    "\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "dk4SteMRFhG7",
    "outputId": "57d6ca64-5e8a-442e-943f-51588c4c7633",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='roberta-large', vocab_size=50265, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umdWd40_dyqq"
   },
   "source": [
    "#### Custom Numericallizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "LbYVAu1ocCsm",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Jmxwz5k3HY"
   },
   "source": [
    "#### Custom Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5CPXNWsQk0f8",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuI3ked5pzdC"
   },
   "source": [
    "#### Settings up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QxhRoqhxpx3x",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681898196928,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "KV95r6jY6UC5",
    "outputId": "35d5d19d-1024-4736-91e3-70924e008d19",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "# print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 52010,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "F_l7LDgGgYNG",
    "outputId": "bab52ad6-db61-4eb0-de43-045a7850c000",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols=train_cols, processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= label_cols)\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bsz, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "W6S_eJ6DhLgy",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "# print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "# print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "# databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1681898248935,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "i-rzhHnki7Vb",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print('[CLS] id: ', transformer_tokenizer.cls_token_id)\n",
    "# print('[SEP] id: ', transformer_tokenizer.sep_token_id)\n",
    "# print('[PAD] id: ', pad_idx)\n",
    "# test_one_batch = databunch.one_batch()[0]\n",
    "# print('Batch shape: ', test_one_batch.shape)\n",
    "# print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import roBerta + Boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1681898248936,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "pQceykzqDAwk",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaClassificationHead, RobertaPreTrainedModel\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch import Tensor\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"roberta-base\"\n",
    "_CONFIG_FOR_DOC = \"RobertaConfig\"\n",
    "_TOKENIZER_FOR_DOC = \"RobertaTokenizer\"\n",
    "\n",
    "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "            Indices can be obtained using [`RobertaTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
    "            1]`:\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1681898248938,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "W_Fz8OriNhGL",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "xOKF3ELT-dDd",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Boom_new(nn.Module):\n",
    "     def __init__(self, in_features: int, out_features: int, dropout=0.1, shortcut: bool = True, device=None, dtype=None) -> None:\n",
    "         factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "         super(Boom_new, self).__init__()\n",
    "\n",
    "         self.linear1 = nn.Linear(in_features, out_features)\n",
    "         self.dropout = nn.Dropout(dropout) if dropout else None\n",
    "         if not shortcut:\n",
    "             self.linear2 = nn.Linear(out_features, in_features)\n",
    "         self.shortcut = shortcut\n",
    "         self.act = GELU()\n",
    " \n",
    "     def forward(self, input: Tensor) -> Tensor:\n",
    "        #  print('A  ', input.shape, type(input))\n",
    "         x = self.act(self.linear1(input))\n",
    "        #  print('B  ', x.shape, type(x))\n",
    "         if self.dropout: x = self.dropout(x)\n",
    "        #  print('C  ', x.shape, type(x))\n",
    "         if self.shortcut:\n",
    "             ninp = input.shape[-1]\n",
    "             x = torch.narrow(x, -1, 0, x.shape[-1] // ninp * ninp)\n",
    "            #  print('D  ', x.shape, type(x))\n",
    "             x = x.view(*x.shape[:-1], x.shape[-1] // ninp, ninp)\n",
    "            #  print('E  ', x.shape, type(x))\n",
    "             z = x.sum(dim=-2)\n",
    "            #  print('F  ', x.shape, type(x))\n",
    "         else:\n",
    "             z = self.linear2(x)\n",
    "            #  print('G  ', x.shape, type(x))\n",
    "        #  print('Z  ', x.shape, type(x))\n",
    "         return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "RtV9jcUVDD-W",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class ModifiedRobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.Boom = Boom_new(config.hidden_size, (config.hidden_size * BOOM))\n",
    "        self.LINEAR = nn.Linear(config.hidden_size,config.hidden_size)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        processor_class=_TOKENIZER_FOR_DOC,\n",
    "        checkpoint=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=\"'optimism'\",\n",
    "        expected_loss=0.08,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.Boom(sequence_output)\n",
    "        sequence_output = self.LINEAR(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        # return logits\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5ePMI5LllI2s",
    "outputId": "7253e07b-58de-4951-8d6d-6ea222f438ea",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 10,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.28.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = classification_head\n",
    "\n",
    "if EDM: config.num_hidden_layers = 10\n",
    "\n",
    "if use_fp16: config.torch_dtype = \"float16\"\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "WZtevDMIjiBr",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type())\n",
    "        logits = self.transformer(input_ids, attention_mask = attention_mask)[0]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "42032dc8a67d4f6cae837fd6c381fa38",
      "844024c43a194e08a1951bdb90c3d20a",
      "9114752678be4ec2a52116ac2c4ac632",
      "20be103a8b6e4c05a5dc25015cfd358d",
      "591a0f885fa94b4aba32a13f567864a2",
      "96e86f098f5f442ea05e1aed9309bb2f",
      "3d59f5ebbe854243b3543b89c3e55c50",
      "e2a72c584dca4d618ebfb185cc23b9fc",
      "633267e43eba4060bebdc1d043c0f155",
      "5ba466b3677542d290e5edc913bbf915",
      "918d275243764415b4aacd122ede250c"
     ]
    },
    "executionInfo": {
     "elapsed": 10946,
     "status": "ok",
     "timestamp": 1681898259865,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zfuO_xApoAxv",
    "outputId": "2a3cbf79-2910-4416-b575-eab83a6ec744",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/M_v_7.0.0/model were not used when initializing ModifiedRobertaForSequenceClassification: ['roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.13.output.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.11.intermediate.dense.weight']\n",
      "- This IS expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ModifiedRobertaForSequenceClassification were not initialized from the model checkpoint at /home/M_v_7.0.0/model and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if(EDM):\n",
    "      transformer_model = ModifiedRobertaForSequenceClassification.from_pretrained(model_folder, config=config)\n",
    "  # transformer_model = ModifiedRobertaForSequenceClassification.from_pretrained(pretrained_model_name, config=config)\n",
    "else:\n",
    "      transformer_model = model_class.from_pretrained(pretrained_model_name, config=config)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model=transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681898259865,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "N_FwWBBCqakA",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# transformer_model = RobertaForSequenceClassification.from_pretrained(model_folder, config=config)\n",
    "\n",
    "# custom_transformer_model = CustomTransformerModel(transformer_model=transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHODnf4pcgu"
   },
   "source": [
    "### Learner: Optimizer & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 5515,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "nPc6oee7paNw",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, custom_transformer_model,\n",
    "                  opt_func = CustomAdamW,\n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "jz3GnOgnqiw6",
    "outputId": "bf0fb0d7-e49a-4bc9-a163-0f1f6742146a",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): ModifiedRobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Boom): Boom_new(\n",
      "      (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (act): GELU()\n",
      "    )\n",
      "    (LINEAR): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z90uvKUHql9t"
   },
   "source": [
    "#### Discriminative Fine-tuning and Gradual unfreezing (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7315,
     "status": "ok",
     "timestamp": 1681898272676,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "tmfkOBh08lY_",
    "outputId": "c1174a30-f221-463e-b791-10a91d94db61",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [79, 1024]           51,471,360 True      \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           526,336    True      \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           1,024      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "GELUActivation       [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           4,195,328  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Linear               [1024]               1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1024]               0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  5,125      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 184,265,733\n",
       "Total trainable params: 184,265,733\n",
       "Total non-trainable params: 0\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Uskf0SJ1slYi",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# learner.save('untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "hDG-vipRs3vg",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# learner.load('untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QAnyjWTTDNuu",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "e75D0iAFCjg_",
    "outputId": "8e09e02e-6f78-4ec4-9d74-fd273ecc0488",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05 64 False 4 roberta-large True\n"
     ]
    }
   ],
   "source": [
    "print(lr, bsz, use_fp16, BOOM, pretrained_model_name, EDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YSvBSD6VuCIL",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# learner.fit(epochs=epoch, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "executionInfo": {
     "elapsed": 31875,
     "status": "ok",
     "timestamp": 1681898304549,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "B9zNGbD-U4RK",
    "outputId": "82ac4952-314e-4ff4-e784-d778f44030e4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='70' class='' max='2194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.19% [70/2194 00:13&lt;06:58 5.2669]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 6.92E-06\n",
      "Min loss divided by 10: 8.32E-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "HLHDaxYcDUUK",
    "outputId": "dbd29885-e573-40d0-d251-e340667692b3",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='64' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      64.00% [64/100 3:52:54&lt;2:11:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.294131</td>\n",
       "      <td>1.293540</td>\n",
       "      <td>0.500256</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.259644</td>\n",
       "      <td>1.255738</td>\n",
       "      <td>0.500256</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.230665</td>\n",
       "      <td>1.236552</td>\n",
       "      <td>0.500256</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.220095</td>\n",
       "      <td>1.222009</td>\n",
       "      <td>0.500256</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.277605</td>\n",
       "      <td>1.199363</td>\n",
       "      <td>0.500256</td>\n",
       "      <td>0.499744</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.135410</td>\n",
       "      <td>1.167555</td>\n",
       "      <td>0.504165</td>\n",
       "      <td>0.495835</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.124927</td>\n",
       "      <td>1.122402</td>\n",
       "      <td>0.542932</td>\n",
       "      <td>0.457068</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.098508</td>\n",
       "      <td>1.065377</td>\n",
       "      <td>0.575676</td>\n",
       "      <td>0.424324</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.009444</td>\n",
       "      <td>0.970547</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>0.389978</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.912467</td>\n",
       "      <td>0.911059</td>\n",
       "      <td>0.625721</td>\n",
       "      <td>0.374279</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.904938</td>\n",
       "      <td>0.880779</td>\n",
       "      <td>0.637575</td>\n",
       "      <td>0.362425</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.841178</td>\n",
       "      <td>0.859117</td>\n",
       "      <td>0.647892</td>\n",
       "      <td>0.352108</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.869985</td>\n",
       "      <td>0.843852</td>\n",
       "      <td>0.651032</td>\n",
       "      <td>0.348968</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.868519</td>\n",
       "      <td>0.828801</td>\n",
       "      <td>0.656927</td>\n",
       "      <td>0.343073</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.820837</td>\n",
       "      <td>0.816146</td>\n",
       "      <td>0.661797</td>\n",
       "      <td>0.338203</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.805200</td>\n",
       "      <td>0.665449</td>\n",
       "      <td>0.334551</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.805372</td>\n",
       "      <td>0.790712</td>\n",
       "      <td>0.672626</td>\n",
       "      <td>0.327374</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.807761</td>\n",
       "      <td>0.788770</td>\n",
       "      <td>0.672049</td>\n",
       "      <td>0.327951</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.755751</td>\n",
       "      <td>0.775463</td>\n",
       "      <td>0.678970</td>\n",
       "      <td>0.321030</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.734593</td>\n",
       "      <td>0.772511</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.321543</td>\n",
       "      <td>03:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.781128</td>\n",
       "      <td>0.760392</td>\n",
       "      <td>0.684608</td>\n",
       "      <td>0.315392</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.770671</td>\n",
       "      <td>0.755949</td>\n",
       "      <td>0.685506</td>\n",
       "      <td>0.314494</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.746091</td>\n",
       "      <td>0.750759</td>\n",
       "      <td>0.686659</td>\n",
       "      <td>0.313341</td>\n",
       "      <td>03:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.736623</td>\n",
       "      <td>0.744781</td>\n",
       "      <td>0.689478</td>\n",
       "      <td>0.310522</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.713728</td>\n",
       "      <td>0.737937</td>\n",
       "      <td>0.694925</td>\n",
       "      <td>0.305075</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.706305</td>\n",
       "      <td>0.739614</td>\n",
       "      <td>0.691977</td>\n",
       "      <td>0.308023</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.708110</td>\n",
       "      <td>0.736498</td>\n",
       "      <td>0.694028</td>\n",
       "      <td>0.305972</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.686858</td>\n",
       "      <td>0.736317</td>\n",
       "      <td>0.693259</td>\n",
       "      <td>0.306741</td>\n",
       "      <td>03:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.709013</td>\n",
       "      <td>0.738433</td>\n",
       "      <td>0.694028</td>\n",
       "      <td>0.305972</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.668935</td>\n",
       "      <td>0.730675</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>03:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.698433</td>\n",
       "      <td>0.728096</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>0.301038</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.680232</td>\n",
       "      <td>0.730766</td>\n",
       "      <td>0.697809</td>\n",
       "      <td>0.302191</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.732996</td>\n",
       "      <td>0.697232</td>\n",
       "      <td>0.302768</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.648524</td>\n",
       "      <td>0.730270</td>\n",
       "      <td>0.698129</td>\n",
       "      <td>0.301871</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.660015</td>\n",
       "      <td>0.730014</td>\n",
       "      <td>0.700308</td>\n",
       "      <td>0.299692</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.647369</td>\n",
       "      <td>0.735793</td>\n",
       "      <td>0.698513</td>\n",
       "      <td>0.301487</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.615142</td>\n",
       "      <td>0.738612</td>\n",
       "      <td>0.697296</td>\n",
       "      <td>0.302704</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.613408</td>\n",
       "      <td>0.729112</td>\n",
       "      <td>0.702678</td>\n",
       "      <td>0.297322</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.639014</td>\n",
       "      <td>0.735852</td>\n",
       "      <td>0.698513</td>\n",
       "      <td>0.301487</td>\n",
       "      <td>03:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.641047</td>\n",
       "      <td>0.735769</td>\n",
       "      <td>0.699731</td>\n",
       "      <td>0.300269</td>\n",
       "      <td>03:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.605883</td>\n",
       "      <td>0.735074</td>\n",
       "      <td>0.700564</td>\n",
       "      <td>0.299436</td>\n",
       "      <td>03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.611823</td>\n",
       "      <td>0.738208</td>\n",
       "      <td>0.701717</td>\n",
       "      <td>0.298283</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.609880</td>\n",
       "      <td>0.746214</td>\n",
       "      <td>0.695245</td>\n",
       "      <td>0.304755</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.602854</td>\n",
       "      <td>0.742444</td>\n",
       "      <td>0.698257</td>\n",
       "      <td>0.301743</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.607591</td>\n",
       "      <td>0.745874</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.300718</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.578761</td>\n",
       "      <td>0.745236</td>\n",
       "      <td>0.699154</td>\n",
       "      <td>0.300846</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.608488</td>\n",
       "      <td>0.750150</td>\n",
       "      <td>0.697552</td>\n",
       "      <td>0.302448</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.585447</td>\n",
       "      <td>0.751695</td>\n",
       "      <td>0.697873</td>\n",
       "      <td>0.302127</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.575859</td>\n",
       "      <td>0.756275</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.303665</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.583038</td>\n",
       "      <td>0.754593</td>\n",
       "      <td>0.695310</td>\n",
       "      <td>0.304691</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.756329</td>\n",
       "      <td>0.698001</td>\n",
       "      <td>0.301999</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.570640</td>\n",
       "      <td>0.757551</td>\n",
       "      <td>0.697680</td>\n",
       "      <td>0.302320</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.581903</td>\n",
       "      <td>0.758540</td>\n",
       "      <td>0.696847</td>\n",
       "      <td>0.303153</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.590691</td>\n",
       "      <td>0.766166</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.572101</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.696591</td>\n",
       "      <td>0.303409</td>\n",
       "      <td>03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.550108</td>\n",
       "      <td>0.775623</td>\n",
       "      <td>0.695310</td>\n",
       "      <td>0.304691</td>\n",
       "      <td>03:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.542323</td>\n",
       "      <td>0.774174</td>\n",
       "      <td>0.695822</td>\n",
       "      <td>0.304178</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.562914</td>\n",
       "      <td>0.776490</td>\n",
       "      <td>0.695566</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.539691</td>\n",
       "      <td>0.777204</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.576055</td>\n",
       "      <td>0.779830</td>\n",
       "      <td>0.694220</td>\n",
       "      <td>0.305780</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.549442</td>\n",
       "      <td>0.779085</td>\n",
       "      <td>0.695758</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>03:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.549834</td>\n",
       "      <td>0.787064</td>\n",
       "      <td>0.693003</td>\n",
       "      <td>0.306997</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.564143</td>\n",
       "      <td>0.788132</td>\n",
       "      <td>0.692490</td>\n",
       "      <td>0.307510</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.542544</td>\n",
       "      <td>0.787501</td>\n",
       "      <td>0.693323</td>\n",
       "      <td>0.306677</td>\n",
       "      <td>03:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='42' class='' max='2194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.91% [42/2194 00:08&lt;07:30 0.5407]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(100, max_lr=1e-6, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(1, max_lr=lr, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(1, max_lr=lr, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(epochs=20, lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt4oKggTDX57",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner.predict('This movie is the worst one so far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6PBVCNobiXf",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "advFmtFNQsa9",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner.save(os.path.join(ROOT_PATH, 'results', KOKONOTEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7xjC8rrGWZK",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHQy4layD63X"
   },
   "source": [
    "#### Export Learner (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OTgPawjDrVp",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# learner.export(model_name)\n",
    "# !mv ./export.pkl /content/drive/My\\ Drive/LAB/kge_sentiment_analysis\n",
    "# !mv /content/drive/My\\ Drive/LAB/kge_sentiment_analysis/export.pkl /content/drive/My\\ Drive/LAB/bsz2048_DEM-RoBERTa.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQvEKBH_Eq7V",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/My Drive/LAB/'\n",
    "# export_learner = load_learner(path, file = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMQr88C2FAO0",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# export_learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txW64dH8FPkI"
   },
   "source": [
    "#### Creating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CL7otQdLFRUX",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "#     preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "#     sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "#     reverse_sampler = np.argsort(sampler)\n",
    "#     return preds[reverse_sampler, :]\n",
    "\n",
    "# test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dP6IBczGZRD",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv(DATA_ROOT / 'sampleSubmission.csv')\n",
    "# sample_submission['Sentiment'] = np.argmax(test_preds, axis = 1)\n",
    "# sample_submission.to_csv('prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBkUrEZpG13m",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFGWNvhPG39j",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CfueTuqG6v0",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# def create_download_link(title = 'Download CSV file', filename = 'data.csv'):\n",
    "#     html = '<a href=(filename)->(title)</a>'\n",
    "#     html = html.format(title=title, filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# create_download_link(filename='prediciton.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "10ceIJFxiecuBcRtznBcInn3Q8OBPR-rG",
     "timestamp": 1659685428876
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016e9d4951dc4ffaa116b68651b5a5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ac39008291438abe8a0cdec6d0b48e",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f0efcec51584512801c27a3cd6955c1",
      "value": 456318
     }
    },
    "0d1764eea96f42b59b0613a32675d84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_4f06c58c7d7f4db499237ce58193f37c",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "10c337408ee34116ab68750ca4016873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "132793e6053c41a5a775a7b4d3dc190c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_870b2aaafdab485c9c84d37ca50e3751",
       "IPY_MODEL_18192a8ad1094e05bb8679cdc82b0015",
       "IPY_MODEL_19dd2d607cc7428093d7974a3dc630c5"
      ],
      "layout": "IPY_MODEL_7628994d5e6f4802a9a7edb25a3d3da9"
     }
    },
    "18192a8ad1094e05bb8679cdc82b0015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4931528732d14b7da8a4bc12fc66acd3",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_800850935d4d4d41973e053ff7e9be7d",
      "value": 482
     }
    },
    "19dd2d607cc7428093d7974a3dc630c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65077ad08d2a4d869053cf49875ac04c",
      "placeholder": "​",
      "style": "IPY_MODEL_1f23acd2e5414a2493bc041d17d35d65",
      "value": " 482/482 [00:00&lt;00:00, 20.6kB/s]"
     }
    },
    "1f23acd2e5414a2493bc041d17d35d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff839855735448bafa7c923e3c82058": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20be103a8b6e4c05a5dc25015cfd358d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ba466b3677542d290e5edc913bbf915",
      "placeholder": "​",
      "style": "IPY_MODEL_918d275243764415b4aacd122ede250c",
      "value": " 1.43G/1.43G [00:05&lt;00:00, 257MB/s]"
     }
    },
    "28c07e0b489a4929926d1002df24b091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef60fa55102d4902b9ddbcc45b6090ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8532ee00cdbe476796eaec8355396cea",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "332a2f4786154442b5296395129c2e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28c07e0b489a4929926d1002df24b091",
       "IPY_MODEL_016e9d4951dc4ffaa116b68651b5a5e9",
       "IPY_MODEL_38edf987d8fc4ce58ec72c4ed0e4ed67"
      ],
      "layout": "IPY_MODEL_c12a0a03c11641d996cedcb2554837e7"
     }
    },
    "38edf987d8fc4ce58ec72c4ed0e4ed67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ff839855735448bafa7c923e3c82058",
      "placeholder": "​",
      "style": "IPY_MODEL_c99275e215d44398809e6d5accd8f6b4",
      "value": " 456k/456k [00:00&lt;00:00, 3.75MB/s]"
     }
    },
    "3d59f5ebbe854243b3543b89c3e55c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42032dc8a67d4f6cae837fd6c381fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_844024c43a194e08a1951bdb90c3d20a",
       "IPY_MODEL_9114752678be4ec2a52116ac2c4ac632",
       "IPY_MODEL_20be103a8b6e4c05a5dc25015cfd358d"
      ],
      "layout": "IPY_MODEL_591a0f885fa94b4aba32a13f567864a2"
     }
    },
    "4931528732d14b7da8a4bc12fc66acd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f06c58c7d7f4db499237ce58193f37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "591a0f885fa94b4aba32a13f567864a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba466b3677542d290e5edc913bbf915": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e4d7c27ceab4bf5bd780770c6b829fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f0efcec51584512801c27a3cd6955c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "633267e43eba4060bebdc1d043c0f155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65077ad08d2a4d869053cf49875ac04c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66ab18b60f5e4294b4309d3fd293e7a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7628994d5e6f4802a9a7edb25a3d3da9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f018262d1a047109366e216f9e83e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "800850935d4d4d41973e053ff7e9be7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82ac39008291438abe8a0cdec6d0b48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844024c43a194e08a1951bdb90c3d20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96e86f098f5f442ea05e1aed9309bb2f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d59f5ebbe854243b3543b89c3e55c50",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "8532ee00cdbe476796eaec8355396cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "870b2aaafdab485c9c84d37ca50e3751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66ab18b60f5e4294b4309d3fd293e7a4",
      "placeholder": "​",
      "style": "IPY_MODEL_c5dfa7b8af9448b1b4cb3b10812a9102",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "9114752678be4ec2a52116ac2c4ac632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2a72c584dca4d618ebfb185cc23b9fc",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_633267e43eba4060bebdc1d043c0f155",
      "value": 1425941629
     }
    },
    "918d275243764415b4aacd122ede250c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96e86f098f5f442ea05e1aed9309bb2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f9ee57980f64607aed63201e44d2263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d1764eea96f42b59b0613a32675d84c",
       "IPY_MODEL_af7c57c570614472b160423724a07590",
       "IPY_MODEL_e388830b59ba4f9d837ea6cdb9c698e7"
      ],
      "layout": "IPY_MODEL_a46848278e9a45bdbf87f4513a5da72a"
     }
    },
    "a46848278e9a45bdbf87f4513a5da72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7c57c570614472b160423724a07590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d14ec50a29224593a87a902c5a23d581",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f018262d1a047109366e216f9e83e64",
      "value": 898823
     }
    },
    "c12a0a03c11641d996cedcb2554837e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5dfa7b8af9448b1b4cb3b10812a9102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c99275e215d44398809e6d5accd8f6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d14ec50a29224593a87a902c5a23d581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2a72c584dca4d618ebfb185cc23b9fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e388830b59ba4f9d837ea6cdb9c698e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e4d7c27ceab4bf5bd780770c6b829fb",
      "placeholder": "​",
      "style": "IPY_MODEL_10c337408ee34116ab68750ca4016873",
      "value": " 899k/899k [00:00&lt;00:00, 3.27MB/s]"
     }
    },
    "ea8af2f6e8c44a7ab9457f15c6c13ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef60fa55102d4902b9ddbcc45b6090ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
