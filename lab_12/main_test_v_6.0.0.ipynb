{"cells":[{"cell_type":"markdown","metadata":{"id":"M1oqh0F6W3ad"},"source":["# Train a language model (Masked Language Modelling) from scratch using Huggingface Transformers and a custom tokenizer\n","\n","### Inspired from the great notebook by Huggingfce (link to blogpost [link](https://huggingface.co/blog/how-to-train)).\n","\n","# Brief Introduction\n","This blog post is the first part of a series where we want to create a product names generator using a transformer model. For a few weeks I was investigating different models and alternatives in Huggingface to train a text generation model. We have a short list of products with their description and our goal is to obtain the name of the product. I did some experiments with the Transformer model in Tensorflow as well as the T5 summarizer. Finally, in order to deepen the use of Huggingface transformers, I decided to approach the problem with a somewhat more complex approach, an encoder decoder model. Maybe it was not the best option but I wanted to learn new things about huggingface Transformers. In the next post of the series we will introduce you deeper in this concept.\n","\n","Here, in this first part, we will show how to train a tokenizer from scratch and how to use Masked Language Modeling technique to create a RoBERTa model. This personalized model will become the base model for our future encoder Decoder model.\n","\n","# Our Solution\n","For our experiment we are going to train from scratch a RoBERTa model, it will become the encoder and the decoder of a future model. But our domain is very specific, words and concepts about clothes, shapes, colors, … Therefore, we are interested in defining our own tokenizer created from our specific vocabulary, avoiding to include more common words from other domains or use cases which are irrelevant for our final purpose.\n","\n","*We can describe our training phase in three main steps*:\n","- Create and train a byte-level, **Byte-pair encoding tokenizer** with the same special tokens as RoBERTa\n","- Train a RoBERTa model from scratch using **Masked Language Modeling**, MLM.\n","- Warm start and **fine tune an encoder decoder model** based on our RoBERTa pretrained model.\n","\n","In this post we’ll demo how to train a “small” RoBERTa model (6 layers, 768 hidden size, 12 attention heads) – that’s the same number of layers & heads as DistilBERT – on a language from a clothing shop. And in a next notebook, we’ll then fine-tune the model on a downstream task of text generation.\n"]},{"cell_type":"markdown","metadata":{"id":"flij-vszUsQm"},"source":["# Loading the libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1666704240152,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"kD140sFjh0LQ","outputId":"1ddde541-2709-4ab9-f272-868ddd0963de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct 25 13:23:58 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    45W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# Check that we have a GPU\n","!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16109,"status":"ok","timestamp":1666704256700,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"HOk4iZ9YZvec","outputId":"ba8a9a79-cd68-49aa-8663-bcd34c25ed6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5195,"status":"ok","timestamp":1666704261891,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"LvSN2tEw9Azp","outputId":"5e580819-be54-461f-bb79-114cfa46d58b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n","\u001b[K     |████████████████████████████████| 441 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 83.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 88.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 91.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 89.3 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.9.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 74.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.6.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"]}],"source":["!pip install datasets "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mc6KQfWIUuZB","executionInfo":{"status":"ok","timestamp":1666704262405,"user_tz":-480,"elapsed":524,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","import tqdm\n","import math"]},{"cell_type":"markdown","metadata":{"id":"tvVMVDYjUaRt"},"source":["# Loading the datasets\n","\n","As we mentioned before, our dataset contains around 31.000 items, about clothes from an important retailer, including a long product description and a short product name, our target variable. First, we execute a exploratory data analysis and we can observe that the count of rows with outliers values is a small number. The count of words looks like a left skewed distribution, 75% of rows in the range 50–60 words and a maximum about 125 words. The target variable contains about 3 to 6 words."]},{"cell_type":"markdown","metadata":{"id":"5TwDqHbL9SY0"},"source":["Set the variables to the data folders:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"f2tjpFnyU-8T","executionInfo":{"status":"ok","timestamp":1666704262406,"user_tz":-480,"elapsed":6,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# #Set the path to the data folder, datafile and output folder and files\n","\n","# Version = 'v_1.5.2'\n","\n","# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n","\n","# # wikitext_folder = os.path.abspath(os.path.join(root_folder, '../dataset/wikitext'))\n","# # cc_news_folder = os.path.abspath(os.path.join(root_folder, '../dataset/cc_news'))\n","# model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n","# output_folder = os.path.abspath(os.path.join(root_folder, 'output'))\n","# # tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))\n","\n","# # train_filename = 'train'\n","# # test_filename = 'test'\n","# outputfile = 'wikitext_submission.csv'\n","\n","# # wikitext_trainfile_path = os.path.abspath(os.path.join(wikitext_folder,train_filename))\n","# # cc_news_trainfile_path = os.path.abspath(os.path.join(cc_news_folder,train_filename))\n","# # testfile_path = os.path.abspath(os.path.join(wikitext_folder,test_filename))\n","# outputfile_path = os.path.abspath(os.path.join(output_folder,outputfile))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"V9583qjTaVoI","executionInfo":{"status":"ok","timestamp":1666704262406,"user_tz":-480,"elapsed":6,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["def checkpath(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7DGAcLU_Ysto","executionInfo":{"status":"ok","timestamp":1666704262407,"user_tz":-480,"elapsed":7,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":[" # import dataset\n","\n","root_folder = '/content/drive/My Drive/07_research_main/lab_10'\n","\n","wikitext_folder = os.path.abspath(os.path.join(root_folder, 'dataset/wikitext'))\n","cc_news_folder = os.path.abspath(os.path.join(root_folder, 'dataset/cc_news'))\n","\n","train_filename = 'train'\n","test_filename = 'test'\n","\n","wikitext_trainfile_path = os.path.abspath(os.path.join(wikitext_folder,train_filename))\n","cc_news_trainfile_path = os.path.abspath(os.path.join(cc_news_folder,train_filename))\n","testfile_path = os.path.abspath(os.path.join(wikitext_folder,test_filename))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uGqB-U0bDifT","executionInfo":{"status":"ok","timestamp":1666704262790,"user_tz":-480,"elapsed":389,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":[" # model version\n","Version = 'M_v_6.0.0' # 06\n","\n","root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n","\n","model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n","checkpath(model_folder)\n","\n","output_folder = os.path.abspath(os.path.join(root_folder, 'output'))\n","\n","outputfile = 'wikitext_submission.csv'\n","\n","outputfile_path = os.path.abspath(os.path.join(output_folder,outputfile))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"udGV6EfxavCY","executionInfo":{"status":"ok","timestamp":1666704262790,"user_tz":-480,"elapsed":4,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["#  # last model version\n","# Version = 'M_v_4.1.2' # 04\n","\n","# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n","\n","# pre_model_folder = os.path.abspath(os.path.join(root_folder, 'model'))"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"K8ol3_URCad5","executionInfo":{"status":"ok","timestamp":1666704262791,"user_tz":-480,"elapsed":4,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["#  # tokenizer version\n","# Version = 'T_v_1.3.3'\n","\n","# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n","\n","# tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"DeaiAuJW3T1V","executionInfo":{"status":"ok","timestamp":1666704262791,"user_tz":-480,"elapsed":4,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["#  # dataset version\n","# Version = 'D_v_1.2.1'\n","\n","# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n","\n","# train_filename = 'train_dataset_list.csv'\n","# test_filename = 'test_dataset_list.csv'\n","\n","# train_file_path = os.path.abspath(os.path.join(root_folder,train_filename))\n","# test_file_path = os.path.abspath(os.path.join(root_folder,test_filename))"]},{"cell_type":"markdown","metadata":{"id":"Nx_diDArVIHa"},"source":["Load the train datafile with the product descriptions and names:"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"DCCbW4Wg88dt","executionInfo":{"status":"ok","timestamp":1666704263016,"user_tz":-480,"elapsed":229,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["from datasets import load_from_disk"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"IPoDiXbtQRN0","executionInfo":{"status":"ok","timestamp":1666704269922,"user_tz":-480,"elapsed":6910,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["wikitext_train_df = load_from_disk(wikitext_trainfile_path).to_pandas()\n","# wikitext_train_df.head()\n","# wikitext_train_df.info()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20574,"status":"ok","timestamp":1666704290493,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"ea22ZEHcQ8yy","outputId":"41205ce2-3cef-4b69-f136-0707d8b6a960"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         https://pointe-img.rbl.ms/simage/https%3A%2F%2...\n","1         https://pointe-img.rbl.ms/simage/https%3A%2F%2...\n","2         https://pointe-img.rbl.ms/simage/https%3A%2F%2...\n","3         https://pointe-img.rbl.ms/simage/https%3A%2F%2...\n","4         https://pointe-img.rbl.ms/simage/https%3A%2F%2...\n","                                ...                        \n","708236    https://res.cloudinary.com/jpress/image/fetch/...\n","708237    https://res.cloudinary.com/jpress/image/fetch/...\n","708238    http://KFMBFM.images.worldnow.com/images/15964...\n","708239    http://KFMBFM.images.worldnow.com/images/15965...\n","708240    http://KFMBFM.images.worldnow.com/images/15966...\n","Name: image_url, Length: 708241, dtype: object"]},"metadata":{},"execution_count":15}],"source":["cc_news_train_df = load_from_disk(cc_news_trainfile_path).to_pandas()\n","cc_news_train_df.pop(\"title\")\n","cc_news_train_df.pop(\"domain\")\n","cc_news_train_df.pop(\"date\")\n","cc_news_train_df.pop(\"description\")\n","cc_news_train_df.pop(\"url\")\n","cc_news_train_df.pop(\"image_url\")\n","# cc_news_train_df.head()\n","# cc_news_train_df.info()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1666704290494,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"zohUzj7PQ5xw","outputId":"324bce1c-7bfe-4d62-be85-e27f092d17e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2509591 entries, 0 to 2509590\n","Data columns (total 1 columns):\n"," #   Column  Dtype \n","---  ------  ----- \n"," 0   text    object\n","dtypes: object(1)\n","memory usage: 19.1+ MB\n"]}],"source":["# Load the train dataset\n","train_df = pd.concat([wikitext_train_df, cc_news_train_df], ignore_index=True)\n","# train_df.head()\n","train_df.info()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":832,"status":"ok","timestamp":1666704291303,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"eMlW2iAIikfM","outputId":"6cb3a66e-1037-4d67-af57-82c09853ba8e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text\n","0  \",\"size\":[970,250],\"partnerId\":\"AolHtb\"},{\"tar...\n","1   One of the main uses of weather radar is to b...\n","2  ST. CLOUD -- The Granite City Gearheads, a loc...\n","3                                                   \n","4   Plans were made to widen the highway to six l..."],"text/html":["\n","  <div id=\"df-19c30e5e-4c34-4d9c-ab2b-e5fec5cd5143\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\",\"size\":[970,250],\"partnerId\":\"AolHtb\"},{\"tar...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>One of the main uses of weather radar is to b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ST. CLOUD -- The Granite City Gearheads, a loc...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Plans were made to widen the highway to six l...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19c30e5e-4c34-4d9c-ab2b-e5fec5cd5143')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-19c30e5e-4c34-4d9c-ab2b-e5fec5cd5143 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-19c30e5e-4c34-4d9c-ab2b-e5fec5cd5143');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}],"source":["train_df = train_df.sample(frac=1).reset_index(drop=True)\n","train_df.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":546,"status":"ok","timestamp":1666704292214,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"MqxDq-LcVL0T","outputId":"684ac33e-5868-4612-a208-12a7eaadcd7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num Examples:  2509591\n","Null Values\n"," text    0\n","dtype: int64\n","Num Examples:  2509591\n"]}],"source":["# Show the count of rows\n","print('Num Examples: ',len(train_df))\n","print('Null Values\\n', train_df.isna().sum())\n","# Drop rows with Null values \n","train_df.dropna(inplace=True)\n","print('Num Examples: ',len(train_df))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666704292215,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"GlbRvlnkE8OU","outputId":"0227678b-6c93-468e-ba1f-8c360856e682"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text\n","0  \",\"size\":[970,250],\"partnerId\":\"AolHtb\"},{\"tar...\n","1   One of the main uses of weather radar is to b...\n","2  ST. CLOUD -- The Granite City Gearheads, a loc...\n","3                                                   \n","4   Plans were made to widen the highway to six l..."],"text/html":["\n","  <div id=\"df-1462dcd2-1514-48bd-8d76-ea3f3637efa4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\",\"size\":[970,250],\"partnerId\":\"AolHtb\"},{\"tar...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>One of the main uses of weather radar is to b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ST. CLOUD -- The Granite City Gearheads, a loc...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Plans were made to widen the highway to six l...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1462dcd2-1514-48bd-8d76-ea3f3637efa4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1462dcd2-1514-48bd-8d76-ea3f3637efa4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1462dcd2-1514-48bd-8d76-ea3f3637efa4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"AGjcMQ_J9yXu"},"source":["Then, we read the test dataset:"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":934,"status":"ok","timestamp":1666704293145,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"pbCZSLQxVYr-","outputId":"ae21ce07-8154-47fb-fabf-050216e469b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num Examples:  4358\n","Null Values\n"," text    0\n","dtype: int64\n"]}],"source":["# Load the test dataset \n","test_df = load_from_disk(testfile_path).to_pandas()\n","print('Num Examples: ',len(test_df))\n","print('Null Values\\n', test_df.isna().sum())\n","# there are no null values"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"lQX2J1_m7jlD","executionInfo":{"status":"ok","timestamp":1666704293146,"user_tz":-480,"elapsed":19,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# ###\n","# train_df = train_df.sample(frac=0.00001, random_state=0, axis=0)\n","# test_df = test_df.sample(frac=0.001, random_state=0, axis=0)\n","# train_df.info()"]},{"cell_type":"markdown","metadata":{"id":"W_Djave6qwUA"},"source":["# Build a Tokenizer\n"]},{"cell_type":"markdown","metadata":{"id":"mv3X5LvKVtAN"},"source":["## Create the dataset to train a tokenizer\n","\n","*To train a tokenizer we need to save our dataset in a bunch of text files*. We create a plain text file for every description value and we will split each sample using a newline character. We include both the train and test dataset:"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"FU9C8eNEc1jz","executionInfo":{"status":"ok","timestamp":1666704293147,"user_tz":-480,"elapsed":19,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# # Drop the files from the output dir\n","# txt_files_dir = \"./text_split\"\n","# !rm -rf {txt_files_dir}\n","# !mkdir {txt_files_dir}"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"3GW5loLTdtUy","executionInfo":{"status":"ok","timestamp":1666704293147,"user_tz":-480,"elapsed":19,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# # Store values in a dataframe column (Series object) to files, one file per record\n","# def column_to_files(column, prefix, txt_files_dir):\n","#     # The prefix is a unique ID to avoid to overwrite a text file\n","#     i=prefix\n","#     #For every value in the df, with just one column\n","#     for row in column.to_list():\n","#       # Create the filename using the prefix ID\n","#       file_name = os.path.join(txt_files_dir, str(i)+'.txt')\n","#       try:\n","#         # Create the file and write the column text to it\n","#         f = open(file_name, 'wb')\n","#         f.write(row.encode('utf-8'))\n","#         f.close()\n","#       except Exception as e:  #catch exceptions(for eg. empty rows)\n","#         print(row, e) \n","#       i+=1\n","#     # Return the last ID\n","#     return i\n"]},{"cell_type":"markdown","metadata":{"id":"jqC5EASdrd8a"},"source":["Include the training dataset to the main text file:"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"AurkxAD-Vx-M","executionInfo":{"status":"ok","timestamp":1666704293148,"user_tz":-480,"elapsed":19,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# data = train_df[\"text\"]\n","# # Removing the end of line character \\n\n","# data = data.replace(\"\\n\",\" \")\n","# # Set the ID to 0\n","# prefix=0\n","# # Create a file for every description value\n","# prefix = column_to_files(data, prefix, txt_files_dir)\n","# # Print the last ID\n","# print(prefix)"]},{"cell_type":"markdown","metadata":{"id":"KrJTp3dRrkCX"},"source":["Also include the test dataset to the text file:"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"ldqNgudjd540","executionInfo":{"status":"ok","timestamp":1666704293148,"user_tz":-480,"elapsed":19,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# data = test_df[\"text\"]\n","# # Removing the end of line character \\n\n","# data = data.replace(\"\\n\",\" \")\n","# print(len(data))\n","# # Create a file for every description value\n","# prefix = column_to_files(data, prefix, txt_files_dir)\n","# print(prefix)"]},{"cell_type":"markdown","metadata":{"id":"MPdhaKxTrxJx"},"source":["**Include the target variable for training** NOOOO¿?"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"7rxjGQJQox_y","executionInfo":{"status":"ok","timestamp":1666704293149,"user_tz":-480,"elapsed":20,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# data = train_df[\"text\"]\n","# data = data.replace(\"\\n\",\" \")\n","# print(len(data))\n","# prefix = column_to_files(data, prefix, txt_files_dir)\n","# print(prefix)"]},{"cell_type":"markdown","metadata":{"id":"G-kkz81OY6xH"},"source":["## Train the tokenizer\n","\n","The Stanford NLP group define the tokenization as:\n","\n","\"*Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation.*\"\n","\n","A tokenizer breaks a string of characters, usually sentences of text, into tokens, an integer representation of the token, usually by looking for whitespace (tabs, spaces, new lines). It usually splits a sentence into words but there are many options like subwords.\n","\n","We will use a **byte-level Byte-pair encoding tokenizer**, byte pair encoding (BPE) is a simple form of data compression in which the most common pair of consecutive bytes of data is replaced with a byte that does not occur within that data. The benefit of this method is that it will start building its vocabulary from an alphabet of single chars, so all words will be decomposable into tokens. We can avoid the presence of unknown (UNK) tokens.\n","\n","A great explanation on tokenizers can be found on the huggingface documentation, https://huggingface.co/transformers/tokenizer_summary.html."]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":43445,"status":"ok","timestamp":1666704336574,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"5duRggBRZKvP","outputId":"110e0dd6-7850-4817-eb4a-56ad281dce56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.9.2\n","Uninstalling tensorflow-2.9.2:\n","  Successfully uninstalled tensorflow-2.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-kuwnwc4t\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-kuwnwc4t\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (4.13.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (21.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (0.10.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0.dev0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.24.0.dev0) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.24.0.dev0) (3.9.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (2022.9.24)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.24.0.dev0-py3-none-any.whl size=5425469 sha256=2ede8787c37c84d50c0f48bca4b56daebe34b79d71df69fe54d62db71cd54968\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-t58tq38f/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.13.1 transformers-4.24.0.dev0\n","tokenizers                    0.13.1\n","transformers                  4.24.0.dev0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets==1.0.2\n","  Downloading datasets-1.0.2-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (4.64.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (2.23.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (0.3.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (1.3.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (3.8.0)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (6.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (1.25.11)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.2) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.15.0)\n","Installing collected packages: datasets\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.6.1\n","    Uninstalling datasets-2.6.1:\n","      Successfully uninstalled datasets-2.6.1\n","Successfully installed datasets-1.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["datasets"]}}},"metadata":{}}],"source":["# We won't need TensorFlow here\n","!pip uninstall -y tensorflow\n","# Install `transformers` from master\n","!pip install git+https://github.com/huggingface/transformers\n","# !pip install -q transformers==4.21.1\n","!pip list | grep -E 'transformers|tokenizers'\n","# transformers version at notebook update --- 2.11.0\n","# tokenizers version at notebook update --- 0.8.0rc1\n","!pip install datasets==1.0.2"]},{"cell_type":"markdown","metadata":{"id":"vYVIE1XcsV8_"},"source":["We choose to train a byte-level Byte-pair encoding tokenizer (the same as GPT-2), with the same special tokens as RoBERTa. Let’s pick its size to be 8,192 because our specific vocabulary is very limited and simple."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"QgdLhEQS4c5f","executionInfo":{"status":"ok","timestamp":1666704336577,"user_tz":-480,"elapsed":53,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# from pathlib import Path\n","\n","# from tokenizers import ByteLevelBPETokenizer\n","\n","# from tokenizers.processors import BertProcessing\n","\n","# import torch\n","# from torch.utils.data.dataset import Dataset"]},{"cell_type":"markdown","metadata":{"id":"CzKv-3nH66yq"},"source":["Now we can train our tokenizer on the text files containing our vocabulary, we need to specify the vocabulary size, the min frequency for a token to be included and the special tokens. We choose a vocab size of 8,192 and a min frequency of 2 (you can tune this value depending on your max vocabulary size). \n","\n","The special tokens depends on the model, for RoBERTa we include a short list: \n","- \\<s> or BOS, beginning Of Sentence\n","- \\</s> or EOS, End Of Sentence\n","- \\<pad> the padding token\n","- \\<unk> the unknown token\n","- \\<mask> the masking token."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"IMnymRDLe0hi","executionInfo":{"status":"ok","timestamp":1666704336578,"user_tz":-480,"elapsed":54,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# %%time \n","# paths = [str(x) for x in Path(\".\").glob(\"text_split/*.txt\")]\n","\n","# # Initialize a tokenizer\n","# tokenizer = ByteLevelBPETokenizer(lowercase=True)\n","\n","# # Customize training\n","# tokenizer.train(files=paths, vocab_size=50265, min_frequency=2,\n","#                 show_progress=True,\n","#                 special_tokens=[\n","#                                 \"<s>\",\n","#                                 \"<pad>\",\n","#                                 \"</s>\",\n","#                                 \"<unk>\",\n","#                                 \"<mask>\",\n","# ])"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"JBCOT9aI98fl","executionInfo":{"status":"ok","timestamp":1666704336580,"user_tz":-480,"elapsed":55,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# tokenizer"]},{"cell_type":"markdown","metadata":{"id":"6Ei7bqpRf1LH"},"source":["The count of samples is small and the tokenizer trains very fast. Now we can save the tokenizer to disk, later we will use it to train the language model:"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"EIS-irI0f32P","executionInfo":{"status":"ok","timestamp":1666704336581,"user_tz":-480,"elapsed":56,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# #Save the Tokenizer to disk\n","# tokenizer.save_model(tokenizer_folder)"]},{"cell_type":"markdown","metadata":{"id":"lOOfYSuQhSqT"},"source":["We now have both a `vocab.json`, which is a list of the most frequent tokens ranked by frequency and it is used to convert tokens to IDs, and a `merges.txt` file that maps texts to tokens.\n","\n","```json\n","{\n","\t\"<s>\": 0,\n","\t\"<pad>\": 1,\n","\t\"</s>\": 2,\n","\t\"<unk>\": 3,\n","\t\"<mask>\": 4,\n","\t\"!\": 5,\n","\t\"\\\"\": 6,\n","\t\"#\": 7,\n","\t\"$\": 8,\n","\t\"%\": 9,\n","\t\"&\": 10,\n","\t\"'\": 11,\n","\t\"(\": 12,\n","\t\")\": 13,\n","\t# ...\n","}\n","\n","# merges.txt\n","l a\n","Ġ k\n","o n\n","Ġ la\n","t a\n","Ġ e\n","Ġ d\n","Ġ p\n","# ...\n","```\n","\n","What is great is that our tokenizer is optimized for our very specific vocabulary. Compared to a generic tokenizer trained for English, more native words are represented by a single, unsplit token. \n","\n","Here’s  how you can use it in `tokenizers`, including handling the RoBERTa special tokens – of course, you’ll also be able to use it directly from `transformers`. We can instantiate our tokenizer using both files and test it with some text from our dataset.\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"tKVWB8WShT-z","executionInfo":{"status":"ok","timestamp":1666704336583,"user_tz":-480,"elapsed":58,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# # Create the tokenizer using vocab.json and mrege.txt files\n","# tokenizer = ByteLevelBPETokenizer(\n","#     os.path.abspath(os.path.join(tokenizer_folder,'vocab.json')),\n","#     os.path.abspath(os.path.join(tokenizer_folder,'merges.txt'))\n","# )"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"hO5M3vrAhcuj","executionInfo":{"status":"ok","timestamp":1666704336584,"user_tz":-480,"elapsed":59,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# # Prepare the tokenizer\n","# tokenizer._tokenizer.post_processor = BertProcessing(\n","#     (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","#     (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n","# )\n","# tokenizer.enable_truncation(max_length=512)"]},{"cell_type":"markdown","metadata":{"id":"9Z2IxmcK_eSf"},"source":["Let's show some examples:"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"E3Ye27nchfzq","executionInfo":{"status":"ok","timestamp":1666704336586,"user_tz":-480,"elapsed":60,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# tokenizer.encode(\"knit midi dress with vneckline straps.\")"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"X8ya5_7rhjKS","executionInfo":{"status":"ok","timestamp":1666704336588,"user_tz":-480,"elapsed":62,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# # Show the tokens created\n","# tokenizer.encode(\"knit midi dress with vneckline straps.\").tokens"]},{"cell_type":"markdown","metadata":{"id":"WQpUC_CDhnWW"},"source":["# Train a language model from scratch\n","\n","**Update:** This section follows along the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, using our new [`Trainer`](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py) directly. Feel free to pick the approach you like best.\n","\n","> We’ll train a RoBERTa-like model, which is a BERT-like with a couple of changes (check the [documentation](https://huggingface.co/transformers/model_doc/roberta.html) for more details). In summary: *It builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates* .\n","\n","As the model is BERT-like, we’ll train it on a task of **Masked language modeling**. It involves masking part of the input, about 10-20% of thre tokens, then learning a model to predict the missing tokens. MLM is often used within pretraining tasks, **to give models the opportunity to learn textual patterns from unlabeled data**. It can be fine tuned to a particular downstream task. The main benefit is that we do not need labeled data (hard to obtain), no text needs to be labeled by human labelers in order to predict the missing values.\n"]},{"cell_type":"markdown","metadata":{"id":"ylwOUseU3doR"},"source":["We define some global parameters:"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"V6VsZnOd636F","executionInfo":{"status":"ok","timestamp":1666704336589,"user_tz":-480,"elapsed":63,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["TRAIN_BATCH_SIZE = 80    # input batch size for training (default: 64)\n","VALID_BATCH_SIZE = 8    # input batch size for testing (default: 1000)\n","TRAIN_EPOCHS = 1        # number of epochs to train (default: 10)\n","LEARNING_RATE = 2e-4    # learning rate (default: 0.001)\n","WEIGHT_DECAY = 0.01\n","SEED = 42               # random seed (default: 42)\n","MAX_LEN = 128\n","SUMMARY_LEN = 7\n","BOOM = 4\n","SAVE_STEPS = 78420"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1853,"status":"ok","timestamp":1666704338379,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"VNZZs-r6iKAV","outputId":"bd4a21ff-195a-4174-e6bc-42967847080f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":37}],"source":["# Check that PyTorch sees it\n","import torch\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"u0qQzgrBi1OX"},"source":["##Define the model\n","\n","We are going to train the model from scratch, not from a pretrained one. We create a model configuration for our RoBERTa model setting the main parameters:\n","- Vocabulary size\n","- Attention heads\n","- Hidden layers\n","- etc,"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"LTXXutqeDzPi","executionInfo":{"status":"ok","timestamp":1666704338380,"user_tz":-480,"elapsed":38,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# from transformers import RobertaConfig\n","\n","# config = RobertaConfig.from_pretrained('roberta-large')\n","\n","# config.num_hidden_layers = 10\n","\n","# # config.vocab_size = 8192 ###50265"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"EeAgx8icaiza","executionInfo":{"status":"ok","timestamp":1666704338381,"user_tz":-480,"elapsed":39,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# print(config)"]},{"cell_type":"markdown","metadata":{"id":"6yNCw-3hFv9h"},"source":["Finally let's initialize our model using the configuration file. As we are training from scratch, we only initialize from a config that define the architecture of the model but *not restoring previously trained weights*. The weights will be randomly initialized. "]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1666704338382,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"t1RCnPn7CCur","outputId":"6950546a-8b7b-4b3a-ffc4-0eae51122d3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["transformers version: 4.24.0.dev0\n"]}],"source":["import transformers\n","print('transformers version: %s' %(transformers.__version__))"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"G7pBEVNV47nI","executionInfo":{"status":"ok","timestamp":1666704338943,"user_tz":-480,"elapsed":597,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["from transformers import RobertaForMaskedLM, RobertaModel\n","from transformers.models.roberta.modeling_roberta import RobertaLMHead, RobertaPreTrainedModel\n","from transformers.utils import (\n","    add_code_sample_docstrings,\n","    add_start_docstrings,\n","    add_start_docstrings_to_model_forward,\n","    logging,\n","    replace_return_docstrings,\n",")\n","from typing import List, Optional, Tuple, Union\n","from transformers.modeling_outputs import MaskedLMOutput\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","from torch import Tensor\n","logger = logging.get_logger(__name__)\n","\n","_CHECKPOINT_FOR_DOC = \"roberta-base\"\n","_CONFIG_FOR_DOC = \"RobertaConfig\"\n","_TOKENIZER_FOR_DOC = \"RobertaTokenizer\"\n","\n","ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n","    Args:\n","        input_ids (`torch.LongTensor` of shape `({0})`):\n","            Indices of input sequence tokens in the vocabulary.\n","            Indices can be obtained using [`RobertaTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n","            [`PreTrainedTokenizer.__call__`] for details.\n","            [What are input IDs?](../glossary#input-ids)\n","        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n","            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n","            - 1 for tokens that are **not masked**,\n","            - 0 for tokens that are **masked**.\n","            [What are attention masks?](../glossary#attention-mask)\n","        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n","            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n","            1]`:\n","            - 0 corresponds to a *sentence A* token,\n","            - 1 corresponds to a *sentence B* token.\n","            [What are token type IDs?](../glossary#token-type-ids)\n","        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n","            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n","            config.max_position_embeddings - 1]`.\n","            [What are position IDs?](../glossary#position-ids)\n","        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n","            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n","            - 1 indicates the head is **not masked**,\n","            - 0 indicates the head is **masked**.\n","        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n","            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n","            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n","            model's internal embedding lookup matrix.\n","        output_attentions (`bool`, *optional*):\n","            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n","            tensors for more detail.\n","        output_hidden_states (`bool`, *optional*):\n","            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n","            more detail.\n","        return_dict (`bool`, *optional*):\n","            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n","\"\"\""]},{"cell_type":"code","execution_count":42,"metadata":{"id":"aiFBn6U24-zF","executionInfo":{"status":"ok","timestamp":1666704338944,"user_tz":-480,"elapsed":51,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["class GELU(nn.Module):\n","    def forward(self, x):\n","        return x * torch.sigmoid(1.702 * x)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"Do63MmlK5HK-","executionInfo":{"status":"ok","timestamp":1666704338945,"user_tz":-480,"elapsed":49,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["class Boom_new(nn.Module):\n","     def __init__(self, in_features: int, out_features: int, dropout=0.1, shortcut: bool = True, device=None, dtype=None) -> None:\n","         factory_kwargs = {'device': device, 'dtype': dtype}\n","         super(Boom_new, self).__init__()\n","\n","         self.linear1 = nn.Linear(in_features, out_features)\n","         self.dropout = nn.Dropout(dropout) if dropout else None\n","         if not shortcut:\n","             self.linear2 = nn.Linear(out_features, in_features)\n","         self.shortcut = shortcut\n","         self.act = GELU()\n"," \n","     def forward(self, input: Tensor) -> Tensor:\n","         x = self.act(self.linear1(input))\n","         if self.dropout: x = self.dropout(x)\n","         if self.shortcut:\n","             ninp = input.shape[-1]\n","             x = torch.narrow(x, -1, 0, x.shape[-1] // ninp * ninp)\n","             x = x.view(*x.shape[:-1], x.shape[-1] // ninp, ninp)\n","             z = x.sum(dim=-2)\n","         else:\n","             z = self.linear2(x)\n"," \n","         return z"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"XvhosciFKGK_","executionInfo":{"status":"ok","timestamp":1666704338947,"user_tz":-480,"elapsed":50,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["class ModifiedRobertaForMaskedLM(RobertaPreTrainedModel):\n","    _keys_to_ignore_on_save = [r\"lm_head.decoder.weight\", r\"lm_head.decoder.bias\"]\n","    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"lm_head.decoder.weight\", r\"lm_head.decoder.bias\"]\n","    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        if config.is_decoder:\n","            logger.warning(\n","                \"If you want to use `RobertaForMaskedLM` make sure `config.is_decoder=False` for \"\n","                \"bi-directional self-attention.\"\n","            )\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        self.Boom = Boom_new(config.hidden_size, (config.hidden_size * BOOM))\n","        self.LINEAR = nn.Linear(config.hidden_size,config.hidden_size)\n","        self.lm_head = RobertaLMHead(config)\n","\n","        # The LM head weights require special treatment only when they are tied with the word embeddings\n","        self.update_keys_to_ignore(config, [\"lm_head.decoder.weight\"])\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def get_output_embeddings(self):\n","        return self.lm_head.decoder\n","\n","    def set_output_embeddings(self, new_embeddings):\n","        self.lm_head.decoder = new_embeddings\n","\n","    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n","    @add_code_sample_docstrings(\n","        processor_class=_TOKENIZER_FOR_DOC,\n","        checkpoint=_CHECKPOINT_FOR_DOC,\n","        output_type=MaskedLMOutput,\n","        config_class=_CONFIG_FOR_DOC,\n","        mask=\"<mask>\",\n","        expected_output=\"' Paris'\",\n","        expected_loss=0.1,\n","    )\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.LongTensor] = None,\n","        attention_mask: Optional[torch.FloatTensor] = None,\n","        token_type_ids: Optional[torch.LongTensor] = None,\n","        position_ids: Optional[torch.LongTensor] = None,\n","        head_mask: Optional[torch.FloatTensor] = None,\n","        inputs_embeds: Optional[torch.FloatTensor] = None,\n","        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n","        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple[torch.Tensor], MaskedLMOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n","            config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\n","            loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n","        kwargs (`Dict[str, any]`, optional, defaults to *{}*):\n","            Used to hide legacy arguments that have been deprecated.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            encoder_hidden_states=encoder_hidden_states,\n","            encoder_attention_mask=encoder_attention_mask,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        sequence_output = outputs[0]\n","        sequence_output = self.Boom(sequence_output)\n","        sequence_output = self.LINEAR(sequence_output)\n","        prediction_scores = self.lm_head(sequence_output)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (prediction_scores,) + outputs[2:]\n","            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n","\n","        return MaskedLMOutput(\n","            loss=masked_lm_loss,\n","            logits=prediction_scores,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"BzMqR-dzF4Ro","executionInfo":{"status":"ok","timestamp":1666704338949,"user_tz":-480,"elapsed":51,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# model = ModifiedRobertaForMaskedLM(config=config)\n","# print('Num parameters: ',model.num_parameters())"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["cd6ad41fbd8e4f4b8227923b80f17f8e","3a3b1f09c5f840d388a7c0cf8e6b780e","6872e1027f3649a194ed29964e2d6c71","6076afddbacb47b4857f8b8382029b32","15a4a36006a842cdbd5e693a932479c0","9da5046952ad44aeab0db1d887b8ea97","631ca02d0f0148f08d8fe4812c346157","1aa323aa48c64b30b2c86510f9645dd1","b23c2ea042904a5e8bef6a4abc3c8891","89c80273e17e423f9cee0f3ec5fd8b83","273fe0b1d79c479facdd9dc866d816d5"]},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1666704338951,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"wqH6c3Z6cSif","outputId":"7a323c4e-a366-4bbe-b7d5-90b235818814"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd6ad41fbd8e4f4b8227923b80f17f8e"}},"metadata":{}}],"source":["from transformers import RobertaConfig\n","\n","config = RobertaConfig.from_pretrained('roberta-large')\n","\n","# config.num_hidden_layers = 10\n","\n","# config.vocab_size = 8192 ###50265"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1666704338953,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"N0RECGOI44S9"},"outputs":[],"source":["# model = ModifiedRobertaForMaskedLM.from_pretrained(pre_model_folder)\n","# print('Num parameters: ',model.num_parameters())"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"pzXVThnOZ_Ti","executionInfo":{"status":"ok","timestamp":1666704368248,"user_tz":-480,"elapsed":29337,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}},"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["c4645b2bda554f63b62517a72061f01c","cd2464226a8c4849a12f085b40e328d1","76946f1729db401f9998f7ec2f902304","ad17beeed1994152bc730840cc7f8e73","ac4ee4da9fc0423bab18cbc3fadfc469","fb680875fa3647a2b9eaee548e0e15e3","98274de3ae5d4df79f7208933ffab26d","5440d72cdf494c57a1749fabba531e20","4e9f5f52e19e4bf7860c73810b860c25","e6025847c5da4135a65ad33026f8c0e0","aafe707e0cc3469887582205dbc2d686"]},"outputId":"3f233fef-999e-48f8-ecc9-179f40a9c47a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4645b2bda554f63b62517a72061f01c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of ModifiedRobertaForMaskedLM were not initialized from the model checkpoint at roberta-large and are newly initialized: ['LINEAR.bias', 'Boom.linear1.weight', 'LINEAR.weight', 'Boom.linear1.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Num parameters:  360660057\n"]}],"source":["# from transformers import RobertaForMaskedLM\n","\n","model = ModifiedRobertaForMaskedLM.from_pretrained('roberta-large', config=config)\n","print('Num parameters: ',model.num_parameters())"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1666704368249,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"gyOcTRapFq_V","outputId":"f63c46e2-3115-4d4a-e789-72339705b03b"},"outputs":[{"output_type":"stream","name":"stdout","text":["ModifiedRobertaForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (Boom): Boom_new(\n","    (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (act): GELU()\n","  )\n","  (LINEAR): Linear(in_features=1024, out_features=1024, bias=True)\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (decoder): Linear(in_features=1024, out_features=50265, bias=True)\n","  )\n",")\n"]}],"source":["print(model)"]},{"cell_type":"markdown","metadata":{"id":"yAwQ82JiE5pi"},"source":["Now let's recreate our tokenizer, using the tokenizer trained and saved in the previous step. We will use a `RoBERTaTokenizerFast` object and the `from_pretrained` method, to initialize our tokenizer."]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["f5b05448c7cd4083b24d205ce0dece39","f4d3fe3f09904911b808ee41fda5c0bb","ee09b08abe574ef2b52e9e59eaa863de","85dbc86be7a34db79f89acd16798292e","c48bac8f03d94a108ea66f515aca3274","be634c52c2d149f29a62bcbaf20ed24d","c02ef9e5f3bd4909ab082b9073332f8e","7e0eb396e6034ef0a43ed35f67001f53","ca8a6c1eddf8448b8f165d68f4f71ae4","320ef2ba0216483f96a7fc9c1c901d69","fc83d5f2402243c79363cb1c8d5705cd","9655b628e619442b9d9c44a66304c72f","53ce2d3015554e62a17336decbf9ea7e","746723148e164e019c7473c5a8bfb6c0","e9f8c7f2686c47aebf4972302ba1fc13","b4109d9bb90c4cfeb5975554137efd55","0101178233e54b68954ab56ae4903d80","728e706b1ea041669d84526011933e34","0c0fe872edca4fffbb7ed7c992d34f74","474a99ed27a3433db4d6e7f81304e916","ad6b4a6fe7b44c4caffc8f163e99f4f8","e32c8313e6ce436b93549e3a08ccf413"]},"executionInfo":{"elapsed":2235,"status":"ok","timestamp":1666704370449,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"4keFBUjQFOD1","outputId":"6e234c3a-3dc0-4be3-aca2-cf3bb3600de0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b05448c7cd4083b24d205ce0dece39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9655b628e619442b9d9c44a66304c72f"}},"metadata":{}}],"source":["from transformers import RobertaTokenizer\n","# from transformers import RobertaTokenizer\n","\n","# Create the tokenizer from a trained one\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-large', max_len=MAX_LEN)\n","# tokenizer = RobertaTokenizer.from_pretrained(tokenizer_folder, max_len=MAX_LEN)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1666704370449,"user":{"displayName":"野菜浅","userId":"15074908195438095604"},"user_tz":-480},"id":"RgXwwfgbG8WN","outputId":"6a1381b4-e23e-4623-d083-e4c9f9a5e72f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PreTrainedTokenizer(name_or_path='roberta-large', vocab_size=50265, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})"]},"metadata":{},"execution_count":51}],"source":["tokenizer"]},{"cell_type":"markdown","metadata":{"id":"jBtUHRMliOLM"},"source":["## Building the training Dataset\n","\n","We'll build a Pytorch dataset, subclassing the Dataset Class. The CustomDataset receives a Pandas Series with the `description` variable values and the tokenizer to encode those values. The Dataset returns a list of tokens for every product description in the Series.\n","\n","In order to evaluate the model during training, we will generate a train dataset for training and a evaluation dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"XBdFLR-dZnXs"},"source":["https://ryanong.co.uk/2020/06/11/day-163-how-to-build-a-language-model-from-scratch-implementation/"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"-RBzSqDcnoG6","executionInfo":{"status":"ok","timestamp":1666704370450,"user_tz":-480,"elapsed":23,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["from torch.utils.data.dataset import Dataset"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"idY_-O7z0rY4","executionInfo":{"status":"ok","timestamp":1666704370450,"user_tz":-480,"elapsed":22,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# get_train_dataset = pd.read_csv(train_file_path, dtype = 'Int64', keep_default_na = False)\n","# # get_train_dataset = get_train_dataset.sample(frac=1).reset_index(drop=True)\n","# get_train_dataset.head()"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"6Dn-V0syNNKd","executionInfo":{"status":"ok","timestamp":1666704370451,"user_tz":-480,"elapsed":23,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# ###\n","# get_train_dataset = get_train_dataset[0:250959]"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"AhtZVbbKNHh1","executionInfo":{"status":"ok","timestamp":1666704370451,"user_tz":-480,"elapsed":23,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# train_dataset_list_ = [[y for y in x if pd.notna(y)] for x in get_train_dataset.values.tolist()]"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"Y1MLItvREIEJ","executionInfo":{"status":"ok","timestamp":1666704370452,"user_tz":-480,"elapsed":24,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# get_test_dataset = pd.read_csv(test_file_path, dtype = 'Int64', keep_default_na = False)\n","# test_dataset_list_ = [[y for y in x if pd.notna(y)] for x in get_test_dataset.values.tolist()]"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"Z5Ausw4SN8H3","executionInfo":{"status":"ok","timestamp":1666704370453,"user_tz":-480,"elapsed":24,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# len(train_dataset_list_)"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"gpioQ3TQEYLw","executionInfo":{"status":"ok","timestamp":1666704370453,"user_tz":-480,"elapsed":24,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# print(test_dataset_list_)"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"WFMmfy_LDpRZ","executionInfo":{"status":"ok","timestamp":1666704370454,"user_tz":-480,"elapsed":25,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, df, tokenizer):\n","        # or use the RobertaTokenizer from `transformers` directly.\n","\n","        self.examples = []\n","        \n","        for example in df.values:\n","            x=tokenizer.encode_plus(example, max_length = MAX_LEN, truncation=True, padding=True)\n","            self.examples += [x.input_ids]\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, i):\n","        # We’ll pad at the batch level.\n","        return torch.tensor(self.examples[i])"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"IANvVtIfQLNA","executionInfo":{"status":"ok","timestamp":1666704370454,"user_tz":-480,"elapsed":25,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# class ModifiedCustomDataset(Dataset):\n","#     def __init__(self, df_list):\n","#         # or use the RobertaTokenizer from `transformers` directly.\n","\n","#         self.examples = df_list\n","\n","#     def __len__(self):\n","#         return len(self.examples)\n","\n","#     def __getitem__(self, i):\n","#         # We’ll pad at the batch level.\n","#         return torch.tensor(self.examples[i])"]},{"cell_type":"markdown","metadata":{"id":"Q4Ovn-MTm149"},"source":["Concat the training and test dataset, only with the description column."]},{"cell_type":"code","execution_count":61,"metadata":{"id":"0miQ7KOQ3eHp","executionInfo":{"status":"ok","timestamp":1666704370455,"user_tz":-480,"elapsed":25,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# Concatenate the train dataset and the test dataset for language modelling\n","#df=pd.concat([train_df['description'], test_df['description']], axis=0)\n","#print('Total: ',len(df), len(train_df), len(test_df))\n"]},{"cell_type":"markdown","metadata":{"id":"ACOfK4avA_qx"},"source":["Create the custom datasets, for training and evaluation:"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"5aTvI2sBDK5N","executionInfo":{"status":"ok","timestamp":1666707655026,"user_tz":-480,"elapsed":3284596,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# Create the train and evaluation dataset\n","train_dataset = CustomDataset(train_df['text'], tokenizer)\n","eval_dataset = CustomDataset(test_df['text'], tokenizer)"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"mHEC6fqwQgSi","executionInfo":{"status":"ok","timestamp":1666707655026,"user_tz":-480,"elapsed":8,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# # Create the train and evaluation dataset\n","# train_dataset = ModifiedCustomDataset(train_dataset_list_)\n","# eval_dataset = ModifiedCustomDataset(test_dataset_list_)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"oESyOrJAGplY","executionInfo":{"status":"ok","timestamp":1666707655026,"user_tz":-480,"elapsed":5,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# len(train_dataset.examples)"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"867UjcoBtWUz","executionInfo":{"status":"ok","timestamp":1666707655027,"user_tz":-480,"elapsed":5,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# print(eval_dataset.examples)"]},{"cell_type":"markdown","metadata":{"id":"Cm5cA1XUBkNB"},"source":["## Define the Data Collactor for masking our language"]},{"cell_type":"markdown","metadata":{"id":"hDLs73HcIHk5"},"source":["Like in the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, we need to define a data_collator.\n","\n","Once we have the dataset, a **Data Collator will helps us to mask our training texts**. This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on. Data collators are objects that will form a batch by using a list of dataset elements as input and may apply some processing like padding or random masking. The `DataCollatorForLanguageModeling` method allow us to set the probability with which to randomly mask tokens in the input."]},{"cell_type":"code","execution_count":66,"metadata":{"id":"zTgWPa9Dipk2","executionInfo":{"status":"ok","timestamp":1666707655439,"user_tz":-480,"elapsed":416,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","# Define the Data Collator\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")"]},{"cell_type":"markdown","metadata":{"id":"zZhOfZ-RByBr"},"source":["## Initialize and train our Trainer\n","\n","When we want to train a transformer model, the basic approach is to create a Trainer class that provides an API for feature-complete training and contains the basic training loop. First, we define the training arguments, there are many of them but the more relevant are\n","- `output_dir`, where the model artifacts will be saved\n","- `num_train_epochs`\n","- `per_device_train_batch_size`, the batch size\n","\n","\n"," and then the `Trainer` object is created with the arguments, the input dataset and the data collator defined:\n","\n"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpvnFFmZJD-N","outputId":"f7fb0876-1cad-4840-c95b-c6d0067465d4","executionInfo":{"status":"ok","timestamp":1666707659927,"user_tz":-480,"elapsed":4491,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model\n"]}],"source":["from transformers import Trainer, TrainingArguments\n","\n","print(model_folder)\n","# Define the training arguments\n","training_args = TrainingArguments(\n","    output_dir=model_folder,\n","    overwrite_output_dir=True,\n","    evaluation_strategy = 'epoch',\n","    num_train_epochs=TRAIN_EPOCHS,\n","    learning_rate=LEARNING_RATE,\n","    weight_decay=WEIGHT_DECAY,\n","    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n","    per_device_eval_batch_size=VALID_BATCH_SIZE,\n","    save_steps=SAVE_STEPS,\n","    #eval_steps=4096,\n","    save_total_limit=1,\n","    fp16 = False,\n","    # load_best_model_at_end = True,\n",")\n","# Create the trainer for our model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    #prediction_loss_only=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"o6sASa36Nf-N"},"source":["And now, we are ready to train our model "]},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"GxyfXuU1FEVN","executionInfo":{"status":"ok","timestamp":1666707659928,"user_tz":-480,"elapsed":23,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","execution_count":69,"metadata":{"id":"VmaHZXzmkNtJ","executionInfo":{"status":"ok","timestamp":1666752752671,"user_tz":-480,"elapsed":45092765,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}},"colab":{"base_uri":"https://localhost:8080/","height":491},"outputId":"4fddbc78-ef50-47c9-9608-deeb65b74d8a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 2509591\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 80\n","  Total train batch size (w. parallel, distributed & accumulation) = 80\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 31370\n","  Number of trainable parameters = 360660057\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='31370' max='31370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [31370/31370 12:31:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.622200</td>\n","      <td>1.557066</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 4358\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=31370, training_loss=2.124494476367001, metrics={'train_runtime': 45092.5829, 'train_samples_per_second': 55.654, 'train_steps_per_second': 0.696, 'total_flos': 5.949033318782723e+17, 'train_loss': 2.124494476367001, 'epoch': 1.0})"]},"metadata":{},"execution_count":69}],"source":["# Train the model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"GegoobjKwfu8"},"source":["As a result, we can watch how the loss is decreasing while training. We can evaluate our model on the validation set. The perplexity is high because we only have to make predictions for the masked tokens (which represent 15% of the total here)."]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"4lI4mgajKz70","executionInfo":{"status":"ok","timestamp":1666752778885,"user_tz":-480,"elapsed":26228,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}},"outputId":"24166591-13c8-40d9-d72a-957093bb29ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 4358\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='545' max='545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [545/545 00:26]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Perplexity: 4.62\n"]}],"source":["eval_results = trainer.evaluate()\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"_ZkooHz1-_2h"},"source":["## Save our final model and tokenizer to disk\n","\n","Save the model and tokenizer ina way that they can be restored for a future downstream task, our encoder decoder model"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDNgPls7_l13","executionInfo":{"status":"ok","timestamp":1666752801767,"user_tz":-480,"elapsed":22886,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}},"outputId":"e76b9847-65f4-4cb6-c5da-27f280c39198"},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model\n","Configuration saved in /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model/config.json\n","Model weights saved in /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model/pytorch_model.bin\n"]}],"source":["trainer.save_model(model_folder)"]},{"cell_type":"markdown","metadata":{"id":"d0caceCy_p1-"},"source":["# Checking the trained model using a Pipeline"]},{"cell_type":"markdown","metadata":{"id":"iIQJ8ND_AEhl"},"source":["Looking at the training and eval losses going down is not enough, we would like to apply our model to check if our language model is learning anything interesting. An easy way is via the FillMaskPipeline.\n","\n","Pipelines are simple wrappers around tokenizers and models. **We can use the 'fill-mask' pipeline** where we input a sequence containing a masked token (<mask>) and it returns a list of the most probable filled sequences, with their probabilities.\n"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ltXgXyCbAJLY","executionInfo":{"status":"error","timestamp":1666752806852,"user_tz":-480,"elapsed":5098,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}},"outputId":"447ba0c6-0562-4c4a-9eac-42316b0338a2"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model\",\n","  \"architectures\": [\n","    \"ModifiedRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model\",\n","  \"architectures\": [\n","    \"ModifiedRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model/pytorch_model.bin\n","Some weights of the model checkpoint at /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model were not used when initializing RobertaForMaskedLM: ['LINEAR.weight', 'LINEAR.bias', 'Boom.linear1.weight', 'Boom.linear1.bias']\n","- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of RobertaForMaskedLM were initialized from the model checkpoint at /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file /content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model\",\n","  \"architectures\": [\n","    \"ModifiedRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-bfd48c9087fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             tokenizer = AutoTokenizer.from_pretrained(\n\u001b[0;32m--> 795\u001b[0;31m                 \u001b[0mtokenizer_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m             )\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m             raise EnvironmentError(\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m                 \u001b[0;34mf\"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/drive/My Drive/07_research_main/lab_10/M_v_6.0.0/model' is the correct path to a directory containing all relevant files for a RobertaTokenizerFast tokenizer."]}],"source":["from transformers import pipeline\n","\n","fill_mask = pipeline(\n","    \"fill-mask\",\n","    model=model_folder,\n","    tokenizer=model_folder\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIvgZ3S6AO0z","executionInfo":{"status":"aborted","timestamp":1666752806853,"user_tz":-480,"elapsed":4,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# knit midi dress with vneckline\n","# =>\n","fill_mask(\"midi <mask> with vneckline.\")"]},{"cell_type":"markdown","metadata":{"id":"i0qCyyhNAWZi"},"source":["Ok, simple syntax/grammar works. Let’s try a slightly more interesting prompt:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZ9HSQxAAbme","executionInfo":{"status":"aborted","timestamp":1666752806854,"user_tz":-480,"elapsed":5,"user":{"displayName":"野菜浅","userId":"15074908195438095604"}}},"outputs":[],"source":["# The test text: Round neck sweater with long sleeves\n","fill_mask(\"Round neck sweater with <mask> sleeves.\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"https://github.com/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb","timestamp":1612196531906}],"machine_shape":"hm"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cd6ad41fbd8e4f4b8227923b80f17f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a3b1f09c5f840d388a7c0cf8e6b780e","IPY_MODEL_6872e1027f3649a194ed29964e2d6c71","IPY_MODEL_6076afddbacb47b4857f8b8382029b32"],"layout":"IPY_MODEL_15a4a36006a842cdbd5e693a932479c0"}},"3a3b1f09c5f840d388a7c0cf8e6b780e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9da5046952ad44aeab0db1d887b8ea97","placeholder":"​","style":"IPY_MODEL_631ca02d0f0148f08d8fe4812c346157","value":"Downloading: 100%"}},"6872e1027f3649a194ed29964e2d6c71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa323aa48c64b30b2c86510f9645dd1","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b23c2ea042904a5e8bef6a4abc3c8891","value":482}},"6076afddbacb47b4857f8b8382029b32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89c80273e17e423f9cee0f3ec5fd8b83","placeholder":"​","style":"IPY_MODEL_273fe0b1d79c479facdd9dc866d816d5","value":" 482/482 [00:00&lt;00:00, 19.1kB/s]"}},"15a4a36006a842cdbd5e693a932479c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9da5046952ad44aeab0db1d887b8ea97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"631ca02d0f0148f08d8fe4812c346157":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aa323aa48c64b30b2c86510f9645dd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b23c2ea042904a5e8bef6a4abc3c8891":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89c80273e17e423f9cee0f3ec5fd8b83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"273fe0b1d79c479facdd9dc866d816d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4645b2bda554f63b62517a72061f01c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd2464226a8c4849a12f085b40e328d1","IPY_MODEL_76946f1729db401f9998f7ec2f902304","IPY_MODEL_ad17beeed1994152bc730840cc7f8e73"],"layout":"IPY_MODEL_ac4ee4da9fc0423bab18cbc3fadfc469"}},"cd2464226a8c4849a12f085b40e328d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb680875fa3647a2b9eaee548e0e15e3","placeholder":"​","style":"IPY_MODEL_98274de3ae5d4df79f7208933ffab26d","value":"Downloading: 100%"}},"76946f1729db401f9998f7ec2f902304":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5440d72cdf494c57a1749fabba531e20","max":1425941629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e9f5f52e19e4bf7860c73810b860c25","value":1425941629}},"ad17beeed1994152bc730840cc7f8e73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6025847c5da4135a65ad33026f8c0e0","placeholder":"​","style":"IPY_MODEL_aafe707e0cc3469887582205dbc2d686","value":" 1.43G/1.43G [00:24&lt;00:00, 61.4MB/s]"}},"ac4ee4da9fc0423bab18cbc3fadfc469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb680875fa3647a2b9eaee548e0e15e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98274de3ae5d4df79f7208933ffab26d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5440d72cdf494c57a1749fabba531e20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9f5f52e19e4bf7860c73810b860c25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6025847c5da4135a65ad33026f8c0e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aafe707e0cc3469887582205dbc2d686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5b05448c7cd4083b24d205ce0dece39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4d3fe3f09904911b808ee41fda5c0bb","IPY_MODEL_ee09b08abe574ef2b52e9e59eaa863de","IPY_MODEL_85dbc86be7a34db79f89acd16798292e"],"layout":"IPY_MODEL_c48bac8f03d94a108ea66f515aca3274"}},"f4d3fe3f09904911b808ee41fda5c0bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be634c52c2d149f29a62bcbaf20ed24d","placeholder":"​","style":"IPY_MODEL_c02ef9e5f3bd4909ab082b9073332f8e","value":"Downloading: 100%"}},"ee09b08abe574ef2b52e9e59eaa863de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e0eb396e6034ef0a43ed35f67001f53","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca8a6c1eddf8448b8f165d68f4f71ae4","value":898823}},"85dbc86be7a34db79f89acd16798292e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_320ef2ba0216483f96a7fc9c1c901d69","placeholder":"​","style":"IPY_MODEL_fc83d5f2402243c79363cb1c8d5705cd","value":" 899k/899k [00:00&lt;00:00, 1.78MB/s]"}},"c48bac8f03d94a108ea66f515aca3274":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be634c52c2d149f29a62bcbaf20ed24d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c02ef9e5f3bd4909ab082b9073332f8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e0eb396e6034ef0a43ed35f67001f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca8a6c1eddf8448b8f165d68f4f71ae4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"320ef2ba0216483f96a7fc9c1c901d69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc83d5f2402243c79363cb1c8d5705cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9655b628e619442b9d9c44a66304c72f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53ce2d3015554e62a17336decbf9ea7e","IPY_MODEL_746723148e164e019c7473c5a8bfb6c0","IPY_MODEL_e9f8c7f2686c47aebf4972302ba1fc13"],"layout":"IPY_MODEL_b4109d9bb90c4cfeb5975554137efd55"}},"53ce2d3015554e62a17336decbf9ea7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0101178233e54b68954ab56ae4903d80","placeholder":"​","style":"IPY_MODEL_728e706b1ea041669d84526011933e34","value":"Downloading: 100%"}},"746723148e164e019c7473c5a8bfb6c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c0fe872edca4fffbb7ed7c992d34f74","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_474a99ed27a3433db4d6e7f81304e916","value":456318}},"e9f8c7f2686c47aebf4972302ba1fc13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad6b4a6fe7b44c4caffc8f163e99f4f8","placeholder":"​","style":"IPY_MODEL_e32c8313e6ce436b93549e3a08ccf413","value":" 456k/456k [00:00&lt;00:00, 1.72MB/s]"}},"b4109d9bb90c4cfeb5975554137efd55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0101178233e54b68954ab56ae4903d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"728e706b1ea041669d84526011933e34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c0fe872edca4fffbb7ed7c992d34f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"474a99ed27a3433db4d6e7f81304e916":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad6b4a6fe7b44c4caffc8f163e99f4f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32c8313e6ce436b93549e3a08ccf413":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}