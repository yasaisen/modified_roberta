{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_v1.0_2306210257_D_SST5_B_128_M_boomberta\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'SST5'\n",
    "# DATASET = 'SST2'\n",
    "BSZ = 128\n",
    "# EPOCH = 8\n",
    "# MODEL = 'bert'\n",
    "# MODEL = 'roberta'\n",
    "# MODEL = 'xlnet'\n",
    "# MODEL = 'distilbert'\n",
    "MODEL = 'boomberta'\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(ROOT_PATH, 'finetune_dataset/')\n",
    "VERSION = 'v1.0'\n",
    "START_TIME = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "load_model_from = os.path.join(ROOT_PATH, 'results_2306210218')\n",
    "\n",
    "KOKONOTEST = 'test_' + VERSION + '_' + START_TIME + '_D_' + DATASET + '_B_' + str(BSZ) + '_M_' + MODEL\n",
    "print(KOKONOTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 21 02:57:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 30%   29C    P8    28W / 200W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (23.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-mjhtez8z\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git': 'git' while executing command git version\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: fastai==1.0.58 in /opt/conda/lib/python3.7/site-packages (1.0.58)\n",
      "Requirement already satisfied: bottleneck in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.3.7)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (4.9.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.4.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.8.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.18.1)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (7.352.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (20.9)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (9.5.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (5.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.22.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.9.0+cu111)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.5.3)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (0.10.0+cu111)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.65.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.11.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (45.2.0.post20200210)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->fastai==1.0.58) (2.4.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2020.4.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->fastai==1.0.58) (2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai==1.0.58) (2019.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fastai==1.0.58) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.18.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (9.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.7/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mtokenizers                  0.13.3\n",
      "transformers                4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q transformers==4.28.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install fastai==1.0.58\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install SentencePiece\n",
    "    \n",
    "!pip list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version: 1.0.58\n",
      "transformers version: 4.28.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version: %s' %(fastai.__version__))\n",
    "print('transformers version: %s' %(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "# from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "# from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "# from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "# from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu vars\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True # speed up with gpu\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449287,
     "status": "ok",
     "timestamp": 1681898134125,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YPh_dtQJJhej",
    "outputId": "36283b7b-0e31-41ea-8815-1eba40f7d2fb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681898192514,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZEvggolFoRbH"
   },
   "outputs": [],
   "source": [
    "def checkpath(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "K8ol3_URCad5"
   },
   "outputs": [],
   "source": [
    "#  # tokenizer version\n",
    "# Version = 'T_v_1.3.3'\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "# tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "fgSOFnkTEMwv"
   },
   "outputs": [],
   "source": [
    "#  # model version\n",
    "# Version = 'M_v_8.0.0'\n",
    "# root_folder = os.path.abspath(os.path.join(ROOT_PATH, Version))\n",
    "# model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "# checkpath(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_CLASSES = {\n",
    "#     'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "#     'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "#     'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "#     'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "#     'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1681898193371,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6ZSnPW0GPA9V"
   },
   "outputs": [],
   "source": [
    "# Data selection\n",
    "\n",
    "if DATASET == 'SST5':\n",
    "    dataset = 'SST5'\n",
    "    DATA_ROOT = Path(os.path.join(DATA_PATH, 'kge_sentiment_analysis'))\n",
    "    train_cols = 'Phrase'\n",
    "    label_cols = 'Sentiment'\n",
    "    classification_head = 5\n",
    "elif DATASET == 'SST2':\n",
    "    dataset = 'SST2'\n",
    "    DATA_ROOT = Path(os.path.join(DATA_PATH, 'IMDB_MovieReviews'))\n",
    "    train_cols = 'review'\n",
    "    label_cols = 'sentiment'\n",
    "    classification_head = 2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# lr = 1e-5\n",
    "bsz = BSZ\n",
    "# epoch = EPOCH\n",
    "\n",
    "# model_name = 'bsz2048_DEM-RoBERTa.pkl'\n",
    "\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "\n",
    "# Model selection\n",
    "\n",
    "# if MODEL == 'bert':\n",
    "#     model_type = 'bert'\n",
    "#     pretrained_model_name='bert-base-uncased'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'roberta':\n",
    "#     model_type = 'roberta'\n",
    "#     pretrained_model_name = 'roberta-large'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'xlnet':\n",
    "#     model_type = 'xlnet'\n",
    "#     pretrained_model_name = 'xlnet-base-cased'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'distilbert':\n",
    "#     model_type = 'distilbert'\n",
    "#     pretrained_model_name = 'distilbert-base-uncased'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'edm-roberta':\n",
    "#     model_type = 'roberta'\n",
    "#     pretrained_model_name = 'roberta-large'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name#tokenizer_folder\n",
    "#     EDM = True\n",
    "\n",
    "# model_type = 'xlm'\n",
    "# pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "# pretrained_tokenizer_name = pretrained_model_name\n",
    "# EDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "tokenizer_class, config_class = RobertaTokenizer, RobertaConfig\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1681898194705,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YI1PkOgsK7Vc"
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST5'):\n",
    "  train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
    "  test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "vckhJ1W1BMKO"
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST2'):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  df = pd.read_csv(DATA_ROOT / 'IMDB_Dataset.csv.zip')\n",
    "  df['Sentiment'] = df['sentiment'].replace(['negative', 'positive'], [0, 1])\n",
    "  train, test = train_test_split(df, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "m9pUQJP2Bgyy",
    "outputId": "7d961fd5-bfc6-4820-8d1b-5c8cf9f62bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ9ZzGHlPPo0"
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZSBBSBpZPODx"
   },
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type='bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.model_max_length\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] + [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUnibZpXdnVF"
   },
   "source": [
    "- bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "\n",
    "- distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- xlnet:      padding + tokens + [SEP] + [CLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "qfSwieon8K-N"
   },
   "outputs": [],
   "source": [
    "# # from transformers import RobertaTokenizerFast\n",
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "# MAX_LEN = 128\n",
    "# # Create the tokenizer from a trained one\n",
    "# # transformer_tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)\n",
    "# transformer_tokenizer = RobertaTokenizer.from_pretrained(tokenizer_folder)#, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9f9ee57980f64607aed63201e44d2263",
      "0d1764eea96f42b59b0613a32675d84c",
      "af7c57c570614472b160423724a07590",
      "e388830b59ba4f9d837ea6cdb9c698e7",
      "a46848278e9a45bdbf87f4513a5da72a",
      "ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "4f06c58c7d7f4db499237ce58193f37c",
      "d14ec50a29224593a87a902c5a23d581",
      "7f018262d1a047109366e216f9e83e64",
      "5e4d7c27ceab4bf5bd780770c6b829fb",
      "10c337408ee34116ab68750ca4016873",
      "332a2f4786154442b5296395129c2e71",
      "28c07e0b489a4929926d1002df24b091",
      "016e9d4951dc4ffaa116b68651b5a5e9",
      "38edf987d8fc4ce58ec72c4ed0e4ed67",
      "c12a0a03c11641d996cedcb2554837e7",
      "ef60fa55102d4902b9ddbcc45b6090ab",
      "8532ee00cdbe476796eaec8355396cea",
      "82ac39008291438abe8a0cdec6d0b48e",
      "5f0efcec51584512801c27a3cd6955c1",
      "1ff839855735448bafa7c923e3c82058",
      "c99275e215d44398809e6d5accd8f6b4",
      "132793e6053c41a5a775a7b4d3dc190c",
      "870b2aaafdab485c9c84d37ca50e3751",
      "18192a8ad1094e05bb8679cdc82b0015",
      "19dd2d607cc7428093d7974a3dc630c5",
      "7628994d5e6f4802a9a7edb25a3d3da9",
      "66ab18b60f5e4294b4309d3fd293e7a4",
      "c5dfa7b8af9448b1b4cb3b10812a9102",
      "4931528732d14b7da8a4bc12fc66acd3",
      "800850935d4d4d41973e053ff7e9be7d",
      "65077ad08d2a4d869053cf49875ac04c",
      "1f23acd2e5414a2493bc041d17d35d65"
     ]
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1681898196569,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zZGIeSCFXoGz",
    "outputId": "42421471-3daf-48c5-a1c2-ea3f120450a4"
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name)\n",
    "transformer_tokenizer.model_max_length = 128#512\n",
    "\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "dk4SteMRFhG7",
    "outputId": "57d6ca64-5e8a-442e-943f-51588c4c7633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='roberta-large', vocab_size=50265, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umdWd40_dyqq"
   },
   "source": [
    "#### Custom Numericallizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "LbYVAu1ocCsm"
   },
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Jmxwz5k3HY"
   },
   "source": [
    "#### Custom Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5CPXNWsQk0f8"
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuI3ked5pzdC"
   },
   "source": [
    "#### Settings up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QxhRoqhxpx3x"
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681898196928,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "KV95r6jY6UC5",
    "outputId": "35d5d19d-1024-4736-91e3-70924e008d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "# print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 52010,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "F_l7LDgGgYNG",
    "outputId": "bab52ad6-db61-4eb0-de43-045a7850c000"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols=train_cols, processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= label_cols)\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bsz, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "W6S_eJ6DhLgy"
   },
   "outputs": [],
   "source": [
    "# print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "# print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "# print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "# databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1681898248935,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "i-rzhHnki7Vb"
   },
   "outputs": [],
   "source": [
    "# print('[CLS] id: ', transformer_tokenizer.cls_token_id)\n",
    "# print('[SEP] id: ', transformer_tokenizer.sep_token_id)\n",
    "# print('[PAD] id: ', pad_idx)\n",
    "# test_one_batch = databunch.one_batch()[0]\n",
    "# print('Batch shape: ', test_one_batch.shape)\n",
    "# print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import roBerta + Boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "# from ...activations import ACT2FN, gelu\n",
    "from transformers.activations import ACT2FN, gelu\n",
    "# from ...modeling_outputs import (\n",
    "#     BaseModelOutputWithPastAndCrossAttentions,\n",
    "#     BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "#     CausalLMOutputWithCrossAttentions,\n",
    "#     MaskedLMOutput,\n",
    "#     MultipleChoiceModelOutput,\n",
    "#     QuestionAnsweringModelOutput,\n",
    "#     SequenceClassifierOutput,\n",
    "#     TokenClassifierOutput,\n",
    "# )\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "# from ...modeling_utils import PreTrainedModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "# from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "# from ...utils import (\n",
    "#     add_code_sample_docstrings,\n",
    "#     add_start_docstrings,\n",
    "#     add_start_docstrings_to_model_forward,\n",
    "#     logging,\n",
    "#     replace_return_docstrings,\n",
    "# )\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "# from .configuration_roberta import RobertaConfig\n",
    "from transformers.models.roberta.configuration_roberta import RobertaConfig\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"roberta-base\"\n",
    "_CONFIG_FOR_DOC = \"RobertaConfig\"\n",
    "\n",
    "ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"roberta-base\",\n",
    "    \"roberta-large\",\n",
    "    \"roberta-large-mnli\",\n",
    "    \"distilroberta-base\",\n",
    "    \"roberta-base-openai-detector\",\n",
    "    \"roberta-large-openai-detector\",\n",
    "    # See all RoBERTa models at https://huggingface.co/models?filter=roberta\n",
    "]\n",
    "\n",
    "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\n",
    "\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            This parameter can only be used when the model is initialized with `type_vocab_size` parameter with value\n",
    "            >= 2. All the value in this tensor should be always < type_vocab_size.\n",
    "\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaAttention, \n",
    "    RobertaPreTrainedModel, \n",
    "    RobertaPooler, \n",
    "    RobertaEmbeddings, \n",
    "    RobertaClassificationHead\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boom_Layer(nn.Module):\n",
    "     def __init__(self, in_features: int, out_features: int, dropout=0.1, shortcut: bool = True, device=None, dtype=None) -> None:\n",
    "         factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "         super(Boom_Layer, self).__init__()\n",
    "\n",
    "         self.linear1 = nn.Linear(in_features, out_features)\n",
    "         self.dropout = nn.Dropout(dropout) if dropout else None\n",
    "         if not shortcut:\n",
    "             self.linear2 = nn.Linear(out_features, in_features)\n",
    "         self.shortcut = shortcut\n",
    "         self.act = GELU()\n",
    " \n",
    "     def forward(self, input: Tensor) -> Tensor:\n",
    "         x = self.act(self.linear1(input))\n",
    "         if self.dropout: x = self.dropout(x)\n",
    "         if self.shortcut:\n",
    "             ninp = input.shape[-1]\n",
    "             x = torch.narrow(x, -1, 0, x.shape[-1] // ninp * ninp)\n",
    "             x = x.view(*x.shape[:-1], x.shape[-1] // ninp, ninp)\n",
    "             z = x.sum(dim=-2)\n",
    "         else:\n",
    "             z = self.linear2(x)\n",
    " \n",
    "         return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaIntermediateAndBoom(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # self.dense_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        # if isinstance(config.hidden_act, str):\n",
    "        #     self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        # else:\n",
    "        #     self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "        # self.dense_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "\n",
    "        self.boom = Boom_Layer(config.hidden_size, config.intermediate_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        # hidden_states = self.dense_1(input_tensor)\n",
    "        # hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "\n",
    "        # hidden_states = self.dense_2(hidden_states)\n",
    "\n",
    "        hidden_states = self.boom(input_tensor)\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = RobertaAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        self.add_cross_attention = config.add_cross_attention\n",
    "        if self.add_cross_attention:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
    "            self.crossattention = RobertaAttention(config, position_embedding_type=\"absolute\")\n",
    "        # self.intermediate = RobertaIntermediate(config)#####\n",
    "        # self.output = RobertaOutput(config)#####\n",
    "        \n",
    "        self.intermediateandboom = RobertaIntermediateAndBoom(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "\n",
    "        # if decoder, the last output is tuple of self-attn cache\n",
    "        if self.is_decoder:\n",
    "            outputs = self_attention_outputs[1:-1]\n",
    "            present_key_value = self_attention_outputs[-1]\n",
    "        else:\n",
    "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        cross_attn_present_key_value = None\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"\n",
    "                    \" by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "\n",
    "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
    "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output,\n",
    "                attention_mask,\n",
    "                head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                cross_attn_past_key_value,\n",
    "                output_attentions,\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
    "\n",
    "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
    "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
    "            present_key_value = present_key_value + cross_attn_present_key_value\n",
    "\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "        # if decoder, return the attn key/values as the last output\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (present_key_value,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        # print(attention_output.shape)\n",
    "        # intermediate_output = self.intermediate(attention_output)\n",
    "        # print(intermediate_output.shape)\n",
    "        # layer_output = self.output(intermediate_output, attention_output)\n",
    "        # print(layer_output.shape)\n",
    "\n",
    "        layer_output = self.intermediateandboom(attention_output)\n",
    "\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([ModifiedRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "        next_decoder_cache = () if use_cache else None\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                if use_cache:\n",
    "                    logger.warning(\n",
    "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                    )\n",
    "                    use_cache = False\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    past_key_value,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache += (layer_outputs[-1],)\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    next_decoder_cache,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_decoder_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaModel(RobertaPreTrainedModel):\n",
    "    \"\"\"\n",
    "\n",
    "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
    "    cross-attention is added between the self-attention layers, following the architecture described in *Attention is\n",
    "    all you need*_ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\n",
    "    Kaiser and Illia Polosukhin.\n",
    "\n",
    "    To behave as an decoder the model needs to be initialized with the `is_decoder` argument of the configuration set\n",
    "    to `True`. To be used in a Seq2Seq model, the model needs to initialized with both `is_decoder` argument and\n",
    "    `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n",
    "\n",
    "    .. _*Attention is all you need*: https://arxiv.org/abs/1706.03762\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.__init__ with Bert->Roberta\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = RobertaEmbeddings(config)\n",
    "        self.encoder = ModifiedRobertaEncoder(config)\n",
    "\n",
    "        self.pooler = RobertaPooler(config) if add_pooling_layer else None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.forward\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if self.config.is_decoder:\n",
    "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        else:\n",
    "            use_cache = False\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # past_key_values_length\n",
    "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            past_key_values_length=past_key_values_length,\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values=encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.roberta = ModifiedRobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=\"'optimism'\",\n",
    "        expected_loss=0.08,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "WZtevDMIjiBr"
   },
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type())\n",
    "        logits = self.transformer(input_ids, attention_mask = attention_mask)[0]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5ePMI5LllI2s",
    "outputId": "7253e07b-58de-4951-8d6d-6ea222f438ea"
   },
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = classification_head\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if load_model_from is not None:\n",
    "#     model = ModifiedRobertaForSequenceClassification.from_pretrained(load_model_from, config=config)\n",
    "# else:\n",
    "#     model = ModifiedRobertaForSequenceClassification.from_pretrained(pretrained_model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing ModifiedRobertaForSequenceClassification: ['roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.21.output.dense.bias']\n",
      "- This IS expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ModifiedRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.encoder.layer.11.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.2.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.21.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.11.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.1.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.19.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.22.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.9.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.22.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.10.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.20.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.16.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.1.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.8.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.18.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.12.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.1.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.13.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.4.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.2.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.23.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.3.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.12.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.9.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.0.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.2.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.5.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.19.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.14.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.7.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.18.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.11.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.9.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.21.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.5.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.9.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.6.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.3.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.12.intermediateandboom.boom.linear1.weight', 'classifier.dense.weight', 'roberta.encoder.layer.15.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.13.intermediateandboom.LayerNorm.weight', 'classifier.out_proj.weight', 'roberta.encoder.layer.21.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.6.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.15.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.18.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.8.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.4.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.23.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.8.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.10.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.14.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.4.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.16.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.1.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.7.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.0.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.20.intermediateandboom.LayerNorm.weight', 'classifier.dense.bias', 'roberta.encoder.layer.5.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.17.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.17.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.15.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.7.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.6.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.16.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.0.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.18.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.12.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.17.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.19.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.4.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.22.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.15.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.17.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.2.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.14.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.8.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.3.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.5.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.23.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.13.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.20.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.10.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.7.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.3.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.10.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.20.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.14.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.11.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.0.intermediateandboom.LayerNorm.bias', 'classifier.out_proj.bias', 'roberta.encoder.layer.22.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.13.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.23.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.19.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.21.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.6.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.16.intermediateandboom.boom.linear1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedRobertaForSequenceClassification.from_pretrained(pretrained_model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.roberta.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(len(model.roberta.encoder.layer)):\n",
    "    for param in model.roberta.encoder.layer[i].attention.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "42032dc8a67d4f6cae837fd6c381fa38",
      "844024c43a194e08a1951bdb90c3d20a",
      "9114752678be4ec2a52116ac2c4ac632",
      "20be103a8b6e4c05a5dc25015cfd358d",
      "591a0f885fa94b4aba32a13f567864a2",
      "96e86f098f5f442ea05e1aed9309bb2f",
      "3d59f5ebbe854243b3543b89c3e55c50",
      "e2a72c584dca4d618ebfb185cc23b9fc",
      "633267e43eba4060bebdc1d043c0f155",
      "5ba466b3677542d290e5edc913bbf915",
      "918d275243764415b4aacd122ede250c"
     ]
    },
    "executionInfo": {
     "elapsed": 10946,
     "status": "ok",
     "timestamp": 1681898259865,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zfuO_xApoAxv",
    "outputId": "2a3cbf79-2910-4416-b575-eab83a6ec744"
   },
   "outputs": [],
   "source": [
    "custom_transformer_model = CustomTransformerModel(transformer_model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHODnf4pcgu"
   },
   "source": [
    "# Define Learner, Optimizer, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 5515,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "nPc6oee7paNw"
   },
   "outputs": [],
   "source": [
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model,\n",
    "                  opt_func = CustomAdamW,\n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (140454 items)\n",
       "x: TextList\n",
       "<s> ĠA Ġseries Ġof Ġesc ap ades Ġdemonstrating Ġthe Ġad age Ġthat Ġwhat Ġis Ġgood Ġfor Ġthe Ġgoose </s>,<s> ĠA Ġseries </s>,<s> ĠA </s>,<s> Ġseries </s>,<s> Ġof Ġesc ap ades Ġdemonstrating Ġthe Ġad age Ġthat Ġwhat Ġis Ġgood Ġfor Ġthe Ġgoose </s>\n",
       "y: CategoryList\n",
       "2,2,2,2,2\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (15606 items)\n",
       "x: TextList\n",
       "<s> Ġ' s Ġas Ġsorry </s>,<s> ĠRomantic Ġcomedy Ġand ĠDog me Ġ95 Ġfilmmaking Ġmay Ġseem Ġodd Ġbed fell ows Ġ, Ġbut Ġthey Ġturn Ġout Ġto Ġbe Ġdelight fully Ġcompatible Ġhere </s>,<s> Ġof Ġthese Ġdays </s>,<s> Ġfl inch Ġfrom Ġits Ġunsettling Ġprog nosis </s>,<s> Ġare Ġclinically Ġdepressed </s>\n",
       "y: CategoryList\n",
       "2,4,2,2,1\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (66292 items)\n",
       "x: TextList\n",
       "<s> Ġ15 60 61 Ġ85 45 ĠAn Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine Ġeffort Ġ. </s>,<s> Ġ15 60 62 Ġ85 45 ĠAn Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine Ġeffort </s>,<s> Ġ15 60 63 Ġ85 45 ĠAn </s>,<s> Ġ15 60 64 Ġ85 45 Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine Ġeffort </s>,<s> Ġ15 60 65 Ġ85 45 Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine </s>\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=CustomTransformerModel(\n",
       "  (transformer): ModifiedRobertaForSequenceClassification(\n",
       "    (roberta): ModifiedRobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): ModifiedRobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (4): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (5): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (6): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (7): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (8): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (9): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (10): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (11): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (12): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (13): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (14): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (15): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (16): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (17): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (18): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (19): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (20): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (21): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (22): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (23): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9f2f493f80>, <function error_rate at 0x7f9eb5dc20e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[ShowGraph\n",
       "learn: ...], layer_groups=[Sequential(\n",
       "  (0): Embedding(50265, 1024, padding_idx=1)\n",
       "  (1): Embedding(514, 1024, padding_idx=1)\n",
       "  (2): Embedding(1, 1024)\n",
       "  (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       "  (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (8): Dropout(p=0.1, inplace=False)\n",
       "  (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (11): Dropout(p=0.1, inplace=False)\n",
       "  (12): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (13): Dropout(p=0.1, inplace=False)\n",
       "  (14): GELU()\n",
       "  (15): Dropout(p=0.1, inplace=False)\n",
       "  (16): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (17): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (18): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (19): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (20): Dropout(p=0.1, inplace=False)\n",
       "  (21): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (22): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (23): Dropout(p=0.1, inplace=False)\n",
       "  (24): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (25): Dropout(p=0.1, inplace=False)\n",
       "  (26): GELU()\n",
       "  (27): Dropout(p=0.1, inplace=False)\n",
       "  (28): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (29): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (30): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (31): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (32): Dropout(p=0.1, inplace=False)\n",
       "  (33): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (34): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (35): Dropout(p=0.1, inplace=False)\n",
       "  (36): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (37): Dropout(p=0.1, inplace=False)\n",
       "  (38): GELU()\n",
       "  (39): Dropout(p=0.1, inplace=False)\n",
       "  (40): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (41): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (42): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (43): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (44): Dropout(p=0.1, inplace=False)\n",
       "  (45): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (46): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (47): Dropout(p=0.1, inplace=False)\n",
       "  (48): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (49): Dropout(p=0.1, inplace=False)\n",
       "  (50): GELU()\n",
       "  (51): Dropout(p=0.1, inplace=False)\n",
       "  (52): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (53): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (54): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (55): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (56): Dropout(p=0.1, inplace=False)\n",
       "  (57): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (58): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (59): Dropout(p=0.1, inplace=False)\n",
       "  (60): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (61): Dropout(p=0.1, inplace=False)\n",
       "  (62): GELU()\n",
       "  (63): Dropout(p=0.1, inplace=False)\n",
       "  (64): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (65): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (66): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (67): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (68): Dropout(p=0.1, inplace=False)\n",
       "  (69): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (70): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (71): Dropout(p=0.1, inplace=False)\n",
       "  (72): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (73): Dropout(p=0.1, inplace=False)\n",
       "  (74): GELU()\n",
       "  (75): Dropout(p=0.1, inplace=False)\n",
       "  (76): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (77): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (78): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (79): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (80): Dropout(p=0.1, inplace=False)\n",
       "  (81): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (82): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (83): Dropout(p=0.1, inplace=False)\n",
       "  (84): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (85): Dropout(p=0.1, inplace=False)\n",
       "  (86): GELU()\n",
       "  (87): Dropout(p=0.1, inplace=False)\n",
       "  (88): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (89): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (90): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (91): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (92): Dropout(p=0.1, inplace=False)\n",
       "  (93): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (94): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (95): Dropout(p=0.1, inplace=False)\n",
       "  (96): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (97): Dropout(p=0.1, inplace=False)\n",
       "  (98): GELU()\n",
       "  (99): Dropout(p=0.1, inplace=False)\n",
       "  (100): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (101): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (102): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (103): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (104): Dropout(p=0.1, inplace=False)\n",
       "  (105): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (106): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (107): Dropout(p=0.1, inplace=False)\n",
       "  (108): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (109): Dropout(p=0.1, inplace=False)\n",
       "  (110): GELU()\n",
       "  (111): Dropout(p=0.1, inplace=False)\n",
       "  (112): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (113): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (114): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (115): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (116): Dropout(p=0.1, inplace=False)\n",
       "  (117): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (118): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (119): Dropout(p=0.1, inplace=False)\n",
       "  (120): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (121): Dropout(p=0.1, inplace=False)\n",
       "  (122): GELU()\n",
       "  (123): Dropout(p=0.1, inplace=False)\n",
       "  (124): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (125): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (126): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (127): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (128): Dropout(p=0.1, inplace=False)\n",
       "  (129): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (130): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (131): Dropout(p=0.1, inplace=False)\n",
       "  (132): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (133): Dropout(p=0.1, inplace=False)\n",
       "  (134): GELU()\n",
       "  (135): Dropout(p=0.1, inplace=False)\n",
       "  (136): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (137): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (138): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (139): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (140): Dropout(p=0.1, inplace=False)\n",
       "  (141): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (142): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (143): Dropout(p=0.1, inplace=False)\n",
       "  (144): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (145): Dropout(p=0.1, inplace=False)\n",
       "  (146): GELU()\n",
       "  (147): Dropout(p=0.1, inplace=False)\n",
       "  (148): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (149): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (150): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (151): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (152): Dropout(p=0.1, inplace=False)\n",
       "  (153): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (154): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (155): Dropout(p=0.1, inplace=False)\n",
       "  (156): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (157): Dropout(p=0.1, inplace=False)\n",
       "  (158): GELU()\n",
       "  (159): Dropout(p=0.1, inplace=False)\n",
       "  (160): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (161): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (162): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (163): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (164): Dropout(p=0.1, inplace=False)\n",
       "  (165): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (166): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (167): Dropout(p=0.1, inplace=False)\n",
       "  (168): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (169): Dropout(p=0.1, inplace=False)\n",
       "  (170): GELU()\n",
       "  (171): Dropout(p=0.1, inplace=False)\n",
       "  (172): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (173): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (174): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (175): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (176): Dropout(p=0.1, inplace=False)\n",
       "  (177): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (178): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (179): Dropout(p=0.1, inplace=False)\n",
       "  (180): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (181): Dropout(p=0.1, inplace=False)\n",
       "  (182): GELU()\n",
       "  (183): Dropout(p=0.1, inplace=False)\n",
       "  (184): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (185): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (186): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (187): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (188): Dropout(p=0.1, inplace=False)\n",
       "  (189): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (190): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (191): Dropout(p=0.1, inplace=False)\n",
       "  (192): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (193): Dropout(p=0.1, inplace=False)\n",
       "  (194): GELU()\n",
       "  (195): Dropout(p=0.1, inplace=False)\n",
       "  (196): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (197): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (198): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (199): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (200): Dropout(p=0.1, inplace=False)\n",
       "  (201): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (202): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (203): Dropout(p=0.1, inplace=False)\n",
       "  (204): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (205): Dropout(p=0.1, inplace=False)\n",
       "  (206): GELU()\n",
       "  (207): Dropout(p=0.1, inplace=False)\n",
       "  (208): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (209): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (210): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (211): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (212): Dropout(p=0.1, inplace=False)\n",
       "  (213): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (214): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (215): Dropout(p=0.1, inplace=False)\n",
       "  (216): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (217): Dropout(p=0.1, inplace=False)\n",
       "  (218): GELU()\n",
       "  (219): Dropout(p=0.1, inplace=False)\n",
       "  (220): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (221): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (222): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (223): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (224): Dropout(p=0.1, inplace=False)\n",
       "  (225): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (226): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (227): Dropout(p=0.1, inplace=False)\n",
       "  (228): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (229): Dropout(p=0.1, inplace=False)\n",
       "  (230): GELU()\n",
       "  (231): Dropout(p=0.1, inplace=False)\n",
       "  (232): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (233): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (234): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (235): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (236): Dropout(p=0.1, inplace=False)\n",
       "  (237): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (238): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (239): Dropout(p=0.1, inplace=False)\n",
       "  (240): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (241): Dropout(p=0.1, inplace=False)\n",
       "  (242): GELU()\n",
       "  (243): Dropout(p=0.1, inplace=False)\n",
       "  (244): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (245): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (246): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (247): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (248): Dropout(p=0.1, inplace=False)\n",
       "  (249): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (250): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (251): Dropout(p=0.1, inplace=False)\n",
       "  (252): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (253): Dropout(p=0.1, inplace=False)\n",
       "  (254): GELU()\n",
       "  (255): Dropout(p=0.1, inplace=False)\n",
       "  (256): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (257): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (258): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (259): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (260): Dropout(p=0.1, inplace=False)\n",
       "  (261): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (262): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (263): Dropout(p=0.1, inplace=False)\n",
       "  (264): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (265): Dropout(p=0.1, inplace=False)\n",
       "  (266): GELU()\n",
       "  (267): Dropout(p=0.1, inplace=False)\n",
       "  (268): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (269): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (270): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (271): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (272): Dropout(p=0.1, inplace=False)\n",
       "  (273): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (274): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (275): Dropout(p=0.1, inplace=False)\n",
       "  (276): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (277): Dropout(p=0.1, inplace=False)\n",
       "  (278): GELU()\n",
       "  (279): Dropout(p=0.1, inplace=False)\n",
       "  (280): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (281): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (282): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (283): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (284): Dropout(p=0.1, inplace=False)\n",
       "  (285): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (286): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (287): Dropout(p=0.1, inplace=False)\n",
       "  (288): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (289): Dropout(p=0.1, inplace=False)\n",
       "  (290): GELU()\n",
       "  (291): Dropout(p=0.1, inplace=False)\n",
       "  (292): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (293): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (294): Dropout(p=0.1, inplace=False)\n",
       "  (295): Linear(in_features=1024, out_features=5, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load(load_model_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "jz3GnOgnqiw6",
    "outputId": "bf0fb0d7-e49a-4bc9-a163-0f1f6742146a"
   },
   "outputs": [],
   "source": [
    "# print(learner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7315,
     "status": "ok",
     "timestamp": 1681898272676,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "tmfkOBh08lY_",
    "outputId": "c1174a30-f221-463e-b791-10a91d94db61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [79, 1024]           51,471,360 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           526,336    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           1,024      False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [1024]               1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1024]               0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  5,125      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 254,676,997\n",
       "Total trainable params: 101,865,477\n",
       "Total non-trainable params: 152,811,520\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QAnyjWTTDNuu"
   },
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "executionInfo": {
     "elapsed": 31875,
     "status": "ok",
     "timestamp": 1681898304549,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "B9zNGbD-U4RK",
    "outputId": "82ac4952-314e-4ff4-e784-d778f44030e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='66' class='' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.02% [66/1097 00:20&lt;05:19 2.5467]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 7.59E-07\n",
      "Min loss divided by 10: 3.02E-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "HLHDaxYcDUUK",
    "outputId": "dbd29885-e573-40d0-d251-e340667692b3"
   },
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(20, max_lr=1e-6, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.659940</td>\n",
       "      <td>0.884203</td>\n",
       "      <td>0.647507</td>\n",
       "      <td>0.352493</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(epochs=1, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "m6PBVCNobiXf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(epochs=110, lr=1e-6)\n",
    "# time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "# learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "# torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.recorder.plot_losses()\n",
    "# learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/110 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='391' class='' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      35.64% [391/1097 01:27&lt;02:37 0.6593]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt4oKggTDX57"
   },
   "outputs": [],
   "source": [
    "learner.predict('This movie is the worst one so far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7xjC8rrGWZK"
   },
   "outputs": [],
   "source": [
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHQy4layD63X"
   },
   "source": [
    "## Export Learner (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OTgPawjDrVp"
   },
   "outputs": [],
   "source": [
    "# learner.export(model_name)\n",
    "# !mv ./export.pkl /content/drive/My\\ Drive/LAB/kge_sentiment_analysis\n",
    "# !mv /content/drive/My\\ Drive/LAB/kge_sentiment_analysis/export.pkl /content/drive/My\\ Drive/LAB/bsz2048_DEM-RoBERTa.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQvEKBH_Eq7V"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/My Drive/LAB/'\n",
    "# export_learner = load_learner(path, file = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMQr88C2FAO0"
   },
   "outputs": [],
   "source": [
    "# export_learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txW64dH8FPkI"
   },
   "source": [
    "## Creating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CL7otQdLFRUX"
   },
   "outputs": [],
   "source": [
    "# def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "#     preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "#     sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "#     reverse_sampler = np.argsort(sampler)\n",
    "#     return preds[reverse_sampler, :]\n",
    "\n",
    "# test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dP6IBczGZRD"
   },
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv(DATA_ROOT / 'sampleSubmission.csv')\n",
    "# sample_submission['Sentiment'] = np.argmax(test_preds, axis = 1)\n",
    "# sample_submission.to_csv('prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBkUrEZpG13m"
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFGWNvhPG39j"
   },
   "outputs": [],
   "source": [
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CfueTuqG6v0"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# def create_download_link(title = 'Download CSV file', filename = 'data.csv'):\n",
    "#     html = '<a href=(filename)->(title)</a>'\n",
    "#     html = html.format(title=title, filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# create_download_link(filename='prediciton.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "10ceIJFxiecuBcRtznBcInn3Q8OBPR-rG",
     "timestamp": 1659685428876
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016e9d4951dc4ffaa116b68651b5a5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ac39008291438abe8a0cdec6d0b48e",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f0efcec51584512801c27a3cd6955c1",
      "value": 456318
     }
    },
    "0d1764eea96f42b59b0613a32675d84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_4f06c58c7d7f4db499237ce58193f37c",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "10c337408ee34116ab68750ca4016873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "132793e6053c41a5a775a7b4d3dc190c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_870b2aaafdab485c9c84d37ca50e3751",
       "IPY_MODEL_18192a8ad1094e05bb8679cdc82b0015",
       "IPY_MODEL_19dd2d607cc7428093d7974a3dc630c5"
      ],
      "layout": "IPY_MODEL_7628994d5e6f4802a9a7edb25a3d3da9"
     }
    },
    "18192a8ad1094e05bb8679cdc82b0015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4931528732d14b7da8a4bc12fc66acd3",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_800850935d4d4d41973e053ff7e9be7d",
      "value": 482
     }
    },
    "19dd2d607cc7428093d7974a3dc630c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65077ad08d2a4d869053cf49875ac04c",
      "placeholder": "​",
      "style": "IPY_MODEL_1f23acd2e5414a2493bc041d17d35d65",
      "value": " 482/482 [00:00&lt;00:00, 20.6kB/s]"
     }
    },
    "1f23acd2e5414a2493bc041d17d35d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff839855735448bafa7c923e3c82058": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20be103a8b6e4c05a5dc25015cfd358d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ba466b3677542d290e5edc913bbf915",
      "placeholder": "​",
      "style": "IPY_MODEL_918d275243764415b4aacd122ede250c",
      "value": " 1.43G/1.43G [00:05&lt;00:00, 257MB/s]"
     }
    },
    "28c07e0b489a4929926d1002df24b091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef60fa55102d4902b9ddbcc45b6090ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8532ee00cdbe476796eaec8355396cea",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "332a2f4786154442b5296395129c2e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28c07e0b489a4929926d1002df24b091",
       "IPY_MODEL_016e9d4951dc4ffaa116b68651b5a5e9",
       "IPY_MODEL_38edf987d8fc4ce58ec72c4ed0e4ed67"
      ],
      "layout": "IPY_MODEL_c12a0a03c11641d996cedcb2554837e7"
     }
    },
    "38edf987d8fc4ce58ec72c4ed0e4ed67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ff839855735448bafa7c923e3c82058",
      "placeholder": "​",
      "style": "IPY_MODEL_c99275e215d44398809e6d5accd8f6b4",
      "value": " 456k/456k [00:00&lt;00:00, 3.75MB/s]"
     }
    },
    "3d59f5ebbe854243b3543b89c3e55c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42032dc8a67d4f6cae837fd6c381fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_844024c43a194e08a1951bdb90c3d20a",
       "IPY_MODEL_9114752678be4ec2a52116ac2c4ac632",
       "IPY_MODEL_20be103a8b6e4c05a5dc25015cfd358d"
      ],
      "layout": "IPY_MODEL_591a0f885fa94b4aba32a13f567864a2"
     }
    },
    "4931528732d14b7da8a4bc12fc66acd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f06c58c7d7f4db499237ce58193f37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "591a0f885fa94b4aba32a13f567864a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba466b3677542d290e5edc913bbf915": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e4d7c27ceab4bf5bd780770c6b829fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f0efcec51584512801c27a3cd6955c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "633267e43eba4060bebdc1d043c0f155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65077ad08d2a4d869053cf49875ac04c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66ab18b60f5e4294b4309d3fd293e7a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7628994d5e6f4802a9a7edb25a3d3da9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f018262d1a047109366e216f9e83e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "800850935d4d4d41973e053ff7e9be7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82ac39008291438abe8a0cdec6d0b48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844024c43a194e08a1951bdb90c3d20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96e86f098f5f442ea05e1aed9309bb2f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d59f5ebbe854243b3543b89c3e55c50",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "8532ee00cdbe476796eaec8355396cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "870b2aaafdab485c9c84d37ca50e3751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66ab18b60f5e4294b4309d3fd293e7a4",
      "placeholder": "​",
      "style": "IPY_MODEL_c5dfa7b8af9448b1b4cb3b10812a9102",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "9114752678be4ec2a52116ac2c4ac632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2a72c584dca4d618ebfb185cc23b9fc",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_633267e43eba4060bebdc1d043c0f155",
      "value": 1425941629
     }
    },
    "918d275243764415b4aacd122ede250c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96e86f098f5f442ea05e1aed9309bb2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f9ee57980f64607aed63201e44d2263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d1764eea96f42b59b0613a32675d84c",
       "IPY_MODEL_af7c57c570614472b160423724a07590",
       "IPY_MODEL_e388830b59ba4f9d837ea6cdb9c698e7"
      ],
      "layout": "IPY_MODEL_a46848278e9a45bdbf87f4513a5da72a"
     }
    },
    "a46848278e9a45bdbf87f4513a5da72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7c57c570614472b160423724a07590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d14ec50a29224593a87a902c5a23d581",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f018262d1a047109366e216f9e83e64",
      "value": 898823
     }
    },
    "c12a0a03c11641d996cedcb2554837e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5dfa7b8af9448b1b4cb3b10812a9102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c99275e215d44398809e6d5accd8f6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d14ec50a29224593a87a902c5a23d581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2a72c584dca4d618ebfb185cc23b9fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e388830b59ba4f9d837ea6cdb9c698e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e4d7c27ceab4bf5bd780770c6b829fb",
      "placeholder": "​",
      "style": "IPY_MODEL_10c337408ee34116ab68750ca4016873",
      "value": " 899k/899k [00:00&lt;00:00, 3.27MB/s]"
     }
    },
    "ea8af2f6e8c44a7ab9457f15c6c13ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef60fa55102d4902b9ddbcc45b6090ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
