{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_v1.1_2306210326_D_SST5_B_128_M_boomberta\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'SST5'\n",
    "# DATASET = 'SST2'\n",
    "BSZ = 128\n",
    "# EPOCH = 8\n",
    "# MODEL = 'bert'\n",
    "# MODEL = 'roberta'\n",
    "# MODEL = 'xlnet'\n",
    "# MODEL = 'distilbert'\n",
    "MODEL = 'boomberta'\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(ROOT_PATH, 'finetune_dataset/')\n",
    "VERSION = 'v1.1'\n",
    "START_TIME = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "load_model_from = os.path.join(ROOT_PATH, 'test_v1.0_2306210257_D_SST5_B_128_M_boomberta_2306210304')\n",
    "\n",
    "KOKONOTEST = 'test_' + VERSION + '_' + START_TIME + '_D_' + DATASET + '_B_' + str(BSZ) + '_M_' + MODEL\n",
    "print(KOKONOTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 21 03:26:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 35%   52C    P8    30W / 200W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (23.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-mu9incoi\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git': 'git' while executing command git version\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: fastai==1.0.58 in /opt/conda/lib/python3.7/site-packages (1.0.58)\n",
      "Requirement already satisfied: bottleneck in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.3.7)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (4.9.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.4.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.8.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.18.1)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (7.352.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (20.9)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (9.5.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (5.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.22.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.9.0+cu111)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.5.3)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (0.10.0+cu111)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.65.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.11.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (45.2.0.post20200210)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->fastai==1.0.58) (2.4.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2020.4.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->fastai==1.0.58) (2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai==1.0.58) (2019.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fastai==1.0.58) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.18.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (9.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.7/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mtokenizers                  0.13.3\n",
      "transformers                4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q transformers==4.28.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install fastai==1.0.58\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install SentencePiece\n",
    "    \n",
    "!pip list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version: 1.0.58\n",
      "transformers version: 4.28.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version: %s' %(fastai.__version__))\n",
    "print('transformers version: %s' %(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "# from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "# from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "# from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "# from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu vars\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True # speed up with gpu\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449287,
     "status": "ok",
     "timestamp": 1681898134125,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YPh_dtQJJhej",
    "outputId": "36283b7b-0e31-41ea-8815-1eba40f7d2fb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681898192514,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZEvggolFoRbH"
   },
   "outputs": [],
   "source": [
    "def checkpath(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "K8ol3_URCad5"
   },
   "outputs": [],
   "source": [
    "#  # tokenizer version\n",
    "# Version = 'T_v_1.3.3'\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "# tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "fgSOFnkTEMwv"
   },
   "outputs": [],
   "source": [
    "#  # model version\n",
    "# Version = 'M_v_8.0.0'\n",
    "# root_folder = os.path.abspath(os.path.join(ROOT_PATH, Version))\n",
    "# model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "# checkpath(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_CLASSES = {\n",
    "#     'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "#     'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "#     'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "#     'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "#     'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1681898193371,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6ZSnPW0GPA9V"
   },
   "outputs": [],
   "source": [
    "# Data selection\n",
    "\n",
    "if DATASET == 'SST5':\n",
    "    dataset = 'SST5'\n",
    "    DATA_ROOT = Path(os.path.join(DATA_PATH, 'kge_sentiment_analysis'))\n",
    "    train_cols = 'Phrase'\n",
    "    label_cols = 'Sentiment'\n",
    "    classification_head = 5\n",
    "elif DATASET == 'SST2':\n",
    "    dataset = 'SST2'\n",
    "    DATA_ROOT = Path(os.path.join(DATA_PATH, 'IMDB_MovieReviews'))\n",
    "    train_cols = 'review'\n",
    "    label_cols = 'sentiment'\n",
    "    classification_head = 2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# lr = 1e-5\n",
    "bsz = BSZ\n",
    "# epoch = EPOCH\n",
    "\n",
    "# model_name = 'bsz2048_DEM-RoBERTa.pkl'\n",
    "\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "\n",
    "# Model selection\n",
    "\n",
    "# if MODEL == 'bert':\n",
    "#     model_type = 'bert'\n",
    "#     pretrained_model_name='bert-base-uncased'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'roberta':\n",
    "#     model_type = 'roberta'\n",
    "#     pretrained_model_name = 'roberta-large'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'xlnet':\n",
    "#     model_type = 'xlnet'\n",
    "#     pretrained_model_name = 'xlnet-base-cased'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'distilbert':\n",
    "#     model_type = 'distilbert'\n",
    "#     pretrained_model_name = 'distilbert-base-uncased'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name\n",
    "#     EDM = False\n",
    "# elif MODEL == 'edm-roberta':\n",
    "#     model_type = 'roberta'\n",
    "#     pretrained_model_name = 'roberta-large'\n",
    "#     pretrained_tokenizer_name = pretrained_model_name#tokenizer_folder\n",
    "#     EDM = True\n",
    "\n",
    "# model_type = 'xlm'\n",
    "# pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "# pretrained_tokenizer_name = pretrained_model_name\n",
    "# EDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "tokenizer_class, config_class = RobertaTokenizer, RobertaConfig\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1681898194705,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YI1PkOgsK7Vc"
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST5'):\n",
    "  train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
    "  test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "vckhJ1W1BMKO"
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST2'):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  df = pd.read_csv(DATA_ROOT / 'IMDB_Dataset.csv.zip')\n",
    "  df['Sentiment'] = df['sentiment'].replace(['negative', 'positive'], [0, 1])\n",
    "  train, test = train_test_split(df, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "m9pUQJP2Bgyy",
    "outputId": "7d961fd5-bfc6-4820-8d1b-5c8cf9f62bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ9ZzGHlPPo0"
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZSBBSBpZPODx"
   },
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type='bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.model_max_length\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] + [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUnibZpXdnVF"
   },
   "source": [
    "- bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "\n",
    "- distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- xlnet:      padding + tokens + [SEP] + [CLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "qfSwieon8K-N"
   },
   "outputs": [],
   "source": [
    "# # from transformers import RobertaTokenizerFast\n",
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "# MAX_LEN = 128\n",
    "# # Create the tokenizer from a trained one\n",
    "# # transformer_tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)\n",
    "# transformer_tokenizer = RobertaTokenizer.from_pretrained(tokenizer_folder)#, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9f9ee57980f64607aed63201e44d2263",
      "0d1764eea96f42b59b0613a32675d84c",
      "af7c57c570614472b160423724a07590",
      "e388830b59ba4f9d837ea6cdb9c698e7",
      "a46848278e9a45bdbf87f4513a5da72a",
      "ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "4f06c58c7d7f4db499237ce58193f37c",
      "d14ec50a29224593a87a902c5a23d581",
      "7f018262d1a047109366e216f9e83e64",
      "5e4d7c27ceab4bf5bd780770c6b829fb",
      "10c337408ee34116ab68750ca4016873",
      "332a2f4786154442b5296395129c2e71",
      "28c07e0b489a4929926d1002df24b091",
      "016e9d4951dc4ffaa116b68651b5a5e9",
      "38edf987d8fc4ce58ec72c4ed0e4ed67",
      "c12a0a03c11641d996cedcb2554837e7",
      "ef60fa55102d4902b9ddbcc45b6090ab",
      "8532ee00cdbe476796eaec8355396cea",
      "82ac39008291438abe8a0cdec6d0b48e",
      "5f0efcec51584512801c27a3cd6955c1",
      "1ff839855735448bafa7c923e3c82058",
      "c99275e215d44398809e6d5accd8f6b4",
      "132793e6053c41a5a775a7b4d3dc190c",
      "870b2aaafdab485c9c84d37ca50e3751",
      "18192a8ad1094e05bb8679cdc82b0015",
      "19dd2d607cc7428093d7974a3dc630c5",
      "7628994d5e6f4802a9a7edb25a3d3da9",
      "66ab18b60f5e4294b4309d3fd293e7a4",
      "c5dfa7b8af9448b1b4cb3b10812a9102",
      "4931528732d14b7da8a4bc12fc66acd3",
      "800850935d4d4d41973e053ff7e9be7d",
      "65077ad08d2a4d869053cf49875ac04c",
      "1f23acd2e5414a2493bc041d17d35d65"
     ]
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1681898196569,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zZGIeSCFXoGz",
    "outputId": "42421471-3daf-48c5-a1c2-ea3f120450a4"
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name)\n",
    "transformer_tokenizer.model_max_length = 128#512\n",
    "\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "dk4SteMRFhG7",
    "outputId": "57d6ca64-5e8a-442e-943f-51588c4c7633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='roberta-large', vocab_size=50265, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umdWd40_dyqq"
   },
   "source": [
    "#### Custom Numericallizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "LbYVAu1ocCsm"
   },
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Jmxwz5k3HY"
   },
   "source": [
    "#### Custom Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5CPXNWsQk0f8"
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuI3ked5pzdC"
   },
   "source": [
    "#### Settings up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QxhRoqhxpx3x"
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681898196928,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "KV95r6jY6UC5",
    "outputId": "35d5d19d-1024-4736-91e3-70924e008d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "# print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 52010,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "F_l7LDgGgYNG",
    "outputId": "bab52ad6-db61-4eb0-de43-045a7850c000"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols=train_cols, processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= label_cols)\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bsz, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "W6S_eJ6DhLgy"
   },
   "outputs": [],
   "source": [
    "# print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "# print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "# print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "# databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1681898248935,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "i-rzhHnki7Vb"
   },
   "outputs": [],
   "source": [
    "# print('[CLS] id: ', transformer_tokenizer.cls_token_id)\n",
    "# print('[SEP] id: ', transformer_tokenizer.sep_token_id)\n",
    "# print('[PAD] id: ', pad_idx)\n",
    "# test_one_batch = databunch.one_batch()[0]\n",
    "# print('Batch shape: ', test_one_batch.shape)\n",
    "# print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import roBerta + Boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "# from ...activations import ACT2FN, gelu\n",
    "from transformers.activations import ACT2FN, gelu\n",
    "# from ...modeling_outputs import (\n",
    "#     BaseModelOutputWithPastAndCrossAttentions,\n",
    "#     BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "#     CausalLMOutputWithCrossAttentions,\n",
    "#     MaskedLMOutput,\n",
    "#     MultipleChoiceModelOutput,\n",
    "#     QuestionAnsweringModelOutput,\n",
    "#     SequenceClassifierOutput,\n",
    "#     TokenClassifierOutput,\n",
    "# )\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "# from ...modeling_utils import PreTrainedModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "# from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "# from ...utils import (\n",
    "#     add_code_sample_docstrings,\n",
    "#     add_start_docstrings,\n",
    "#     add_start_docstrings_to_model_forward,\n",
    "#     logging,\n",
    "#     replace_return_docstrings,\n",
    "# )\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "# from .configuration_roberta import RobertaConfig\n",
    "from transformers.models.roberta.configuration_roberta import RobertaConfig\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"roberta-base\"\n",
    "_CONFIG_FOR_DOC = \"RobertaConfig\"\n",
    "\n",
    "ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"roberta-base\",\n",
    "    \"roberta-large\",\n",
    "    \"roberta-large-mnli\",\n",
    "    \"distilroberta-base\",\n",
    "    \"roberta-base-openai-detector\",\n",
    "    \"roberta-large-openai-detector\",\n",
    "    # See all RoBERTa models at https://huggingface.co/models?filter=roberta\n",
    "]\n",
    "\n",
    "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\n",
    "\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            This parameter can only be used when the model is initialized with `type_vocab_size` parameter with value\n",
    "            >= 2. All the value in this tensor should be always < type_vocab_size.\n",
    "\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaAttention, \n",
    "    RobertaPreTrainedModel, \n",
    "    RobertaPooler, \n",
    "    RobertaEmbeddings, \n",
    "    RobertaClassificationHead\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boom_Layer(nn.Module):\n",
    "     def __init__(self, in_features: int, out_features: int, dropout=0.1, shortcut: bool = True, device=None, dtype=None) -> None:\n",
    "         factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "         super(Boom_Layer, self).__init__()\n",
    "\n",
    "         self.linear1 = nn.Linear(in_features, out_features)\n",
    "         self.dropout = nn.Dropout(dropout) if dropout else None\n",
    "         if not shortcut:\n",
    "             self.linear2 = nn.Linear(out_features, in_features)\n",
    "         self.shortcut = shortcut\n",
    "         self.act = GELU()\n",
    " \n",
    "     def forward(self, input: Tensor) -> Tensor:\n",
    "         x = self.act(self.linear1(input))\n",
    "         if self.dropout: x = self.dropout(x)\n",
    "         if self.shortcut:\n",
    "             ninp = input.shape[-1]\n",
    "             x = torch.narrow(x, -1, 0, x.shape[-1] // ninp * ninp)\n",
    "             x = x.view(*x.shape[:-1], x.shape[-1] // ninp, ninp)\n",
    "             z = x.sum(dim=-2)\n",
    "         else:\n",
    "             z = self.linear2(x)\n",
    " \n",
    "         return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaIntermediateAndBoom(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # self.dense_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        # if isinstance(config.hidden_act, str):\n",
    "        #     self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        # else:\n",
    "        #     self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "        # self.dense_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "\n",
    "        self.boom = Boom_Layer(config.hidden_size, config.intermediate_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        # hidden_states = self.dense_1(input_tensor)\n",
    "        # hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "\n",
    "        # hidden_states = self.dense_2(hidden_states)\n",
    "\n",
    "        hidden_states = self.boom(input_tensor)\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = RobertaAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        self.add_cross_attention = config.add_cross_attention\n",
    "        if self.add_cross_attention:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
    "            self.crossattention = RobertaAttention(config, position_embedding_type=\"absolute\")\n",
    "        # self.intermediate = RobertaIntermediate(config)#####\n",
    "        # self.output = RobertaOutput(config)#####\n",
    "        \n",
    "        self.intermediateandboom = RobertaIntermediateAndBoom(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "\n",
    "        # if decoder, the last output is tuple of self-attn cache\n",
    "        if self.is_decoder:\n",
    "            outputs = self_attention_outputs[1:-1]\n",
    "            present_key_value = self_attention_outputs[-1]\n",
    "        else:\n",
    "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        cross_attn_present_key_value = None\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"\n",
    "                    \" by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "\n",
    "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
    "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output,\n",
    "                attention_mask,\n",
    "                head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                cross_attn_past_key_value,\n",
    "                output_attentions,\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
    "\n",
    "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
    "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
    "            present_key_value = present_key_value + cross_attn_present_key_value\n",
    "\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "        # if decoder, return the attn key/values as the last output\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (present_key_value,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        # print(attention_output.shape)\n",
    "        # intermediate_output = self.intermediate(attention_output)\n",
    "        # print(intermediate_output.shape)\n",
    "        # layer_output = self.output(intermediate_output, attention_output)\n",
    "        # print(layer_output.shape)\n",
    "\n",
    "        layer_output = self.intermediateandboom(attention_output)\n",
    "\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([ModifiedRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "        next_decoder_cache = () if use_cache else None\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                if use_cache:\n",
    "                    logger.warning(\n",
    "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                    )\n",
    "                    use_cache = False\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    past_key_value,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache += (layer_outputs[-1],)\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    next_decoder_cache,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_decoder_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaModel(RobertaPreTrainedModel):\n",
    "    \"\"\"\n",
    "\n",
    "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
    "    cross-attention is added between the self-attention layers, following the architecture described in *Attention is\n",
    "    all you need*_ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\n",
    "    Kaiser and Illia Polosukhin.\n",
    "\n",
    "    To behave as an decoder the model needs to be initialized with the `is_decoder` argument of the configuration set\n",
    "    to `True`. To be used in a Seq2Seq model, the model needs to initialized with both `is_decoder` argument and\n",
    "    `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n",
    "\n",
    "    .. _*Attention is all you need*: https://arxiv.org/abs/1706.03762\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.__init__ with Bert->Roberta\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = RobertaEmbeddings(config)\n",
    "        self.encoder = ModifiedRobertaEncoder(config)\n",
    "\n",
    "        self.pooler = RobertaPooler(config) if add_pooling_layer else None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.forward\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if self.config.is_decoder:\n",
    "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        else:\n",
    "            use_cache = False\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # past_key_values_length\n",
    "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            past_key_values_length=past_key_values_length,\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values=encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.roberta = ModifiedRobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=\"'optimism'\",\n",
    "        expected_loss=0.08,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "WZtevDMIjiBr"
   },
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type())\n",
    "        logits = self.transformer(input_ids, attention_mask = attention_mask)[0]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5ePMI5LllI2s",
    "outputId": "7253e07b-58de-4951-8d6d-6ea222f438ea"
   },
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = classification_head\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if load_model_from is not None:\n",
    "#     model = ModifiedRobertaForSequenceClassification.from_pretrained(load_model_from, config=config)\n",
    "# else:\n",
    "#     model = ModifiedRobertaForSequenceClassification.from_pretrained(pretrained_model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing ModifiedRobertaForSequenceClassification: ['roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.22.output.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ModifiedRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.encoder.layer.21.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.18.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.17.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.7.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.18.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.12.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.18.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.19.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.4.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.21.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.13.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.23.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.10.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.14.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.11.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.5.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.6.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.3.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.6.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.2.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.23.intermediateandboom.LayerNorm.bias', 'classifier.dense.bias', 'roberta.encoder.layer.16.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.1.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.6.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.7.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.20.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.5.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.9.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.13.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.22.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.22.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.11.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.16.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.10.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.7.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.21.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.9.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.0.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.3.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.10.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.8.intermediateandboom.boom.linear1.weight', 'classifier.dense.weight', 'roberta.encoder.layer.23.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.9.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.19.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.13.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.1.intermediateandboom.LayerNorm.weight', 'classifier.out_proj.weight', 'roberta.encoder.layer.19.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.17.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.2.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.8.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.6.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.12.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.3.intermediateandboom.boom.linear1.bias', 'classifier.out_proj.bias', 'roberta.encoder.layer.0.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.17.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.23.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.2.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.5.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.16.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.15.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.8.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.4.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.20.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.11.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.22.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.3.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.2.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.5.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.15.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.14.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.12.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.4.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.14.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.14.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.15.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.7.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.17.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.1.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.21.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.18.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.0.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.20.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.1.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.4.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.19.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.10.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.15.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.12.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.9.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.22.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.20.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.8.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.11.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.0.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.16.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.13.intermediateandboom.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedRobertaForSequenceClassification.from_pretrained(pretrained_model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.roberta.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(len(model.roberta.encoder.layer)):\n",
    "    for param in model.roberta.encoder.layer[i].attention.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "42032dc8a67d4f6cae837fd6c381fa38",
      "844024c43a194e08a1951bdb90c3d20a",
      "9114752678be4ec2a52116ac2c4ac632",
      "20be103a8b6e4c05a5dc25015cfd358d",
      "591a0f885fa94b4aba32a13f567864a2",
      "96e86f098f5f442ea05e1aed9309bb2f",
      "3d59f5ebbe854243b3543b89c3e55c50",
      "e2a72c584dca4d618ebfb185cc23b9fc",
      "633267e43eba4060bebdc1d043c0f155",
      "5ba466b3677542d290e5edc913bbf915",
      "918d275243764415b4aacd122ede250c"
     ]
    },
    "executionInfo": {
     "elapsed": 10946,
     "status": "ok",
     "timestamp": 1681898259865,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zfuO_xApoAxv",
    "outputId": "2a3cbf79-2910-4416-b575-eab83a6ec744"
   },
   "outputs": [],
   "source": [
    "custom_transformer_model = CustomTransformerModel(transformer_model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHODnf4pcgu"
   },
   "source": [
    "# Define Learner, Optimizer, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.callback import SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 5515,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "nPc6oee7paNw"
   },
   "outputs": [],
   "source": [
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model,\n",
    "                  opt_func = CustomAdamW,\n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.callbacks.append(SaveModelCallback(learner, monitor='valid_loss', mode='min'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (140454 items)\n",
       "x: TextList\n",
       "<s> ĠA Ġseries Ġof Ġesc ap ades Ġdemonstrating Ġthe Ġad age Ġthat Ġwhat Ġis Ġgood Ġfor Ġthe Ġgoose </s>,<s> ĠA Ġseries </s>,<s> ĠA </s>,<s> Ġseries </s>,<s> Ġof Ġesc ap ades Ġdemonstrating Ġthe Ġad age Ġthat Ġwhat Ġis Ġgood Ġfor Ġthe Ġgoose </s>\n",
       "y: CategoryList\n",
       "2,2,2,2,2\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (15606 items)\n",
       "x: TextList\n",
       "<s> Ġ' s Ġas Ġsorry </s>,<s> ĠRomantic Ġcomedy Ġand ĠDog me Ġ95 Ġfilmmaking Ġmay Ġseem Ġodd Ġbed fell ows Ġ, Ġbut Ġthey Ġturn Ġout Ġto Ġbe Ġdelight fully Ġcompatible Ġhere </s>,<s> Ġof Ġthese Ġdays </s>,<s> Ġfl inch Ġfrom Ġits Ġunsettling Ġprog nosis </s>,<s> Ġare Ġclinically Ġdepressed </s>\n",
       "y: CategoryList\n",
       "2,4,2,2,1\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (66292 items)\n",
       "x: TextList\n",
       "<s> Ġ15 60 61 Ġ85 45 ĠAn Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine Ġeffort Ġ. </s>,<s> Ġ15 60 62 Ġ85 45 ĠAn Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine Ġeffort </s>,<s> Ġ15 60 63 Ġ85 45 ĠAn </s>,<s> Ġ15 60 64 Ġ85 45 Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine Ġeffort </s>,<s> Ġ15 60 65 Ġ85 45 Ġintermitt ently Ġpleasing Ġbut Ġmostly Ġroutine </s>\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=CustomTransformerModel(\n",
       "  (transformer): ModifiedRobertaForSequenceClassification(\n",
       "    (roberta): ModifiedRobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): ModifiedRobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (3): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (4): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (5): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (6): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (7): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (8): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (9): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (10): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (11): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (12): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (13): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (14): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (15): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (16): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (17): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (18): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (19): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (20): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (21): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (22): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (23): ModifiedRobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
       "              (boom): Boom_Layer(\n",
       "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): GELU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa70abe8f80>, <function error_rate at 0x7fa6915160e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[ShowGraph\n",
       "learn: ...], layer_groups=[Sequential(\n",
       "  (0): Embedding(50265, 1024, padding_idx=1)\n",
       "  (1): Embedding(514, 1024, padding_idx=1)\n",
       "  (2): Embedding(1, 1024)\n",
       "  (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       "  (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (8): Dropout(p=0.1, inplace=False)\n",
       "  (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (11): Dropout(p=0.1, inplace=False)\n",
       "  (12): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (13): Dropout(p=0.1, inplace=False)\n",
       "  (14): GELU()\n",
       "  (15): Dropout(p=0.1, inplace=False)\n",
       "  (16): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (17): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (18): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (19): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (20): Dropout(p=0.1, inplace=False)\n",
       "  (21): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (22): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (23): Dropout(p=0.1, inplace=False)\n",
       "  (24): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (25): Dropout(p=0.1, inplace=False)\n",
       "  (26): GELU()\n",
       "  (27): Dropout(p=0.1, inplace=False)\n",
       "  (28): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (29): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (30): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (31): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (32): Dropout(p=0.1, inplace=False)\n",
       "  (33): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (34): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (35): Dropout(p=0.1, inplace=False)\n",
       "  (36): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (37): Dropout(p=0.1, inplace=False)\n",
       "  (38): GELU()\n",
       "  (39): Dropout(p=0.1, inplace=False)\n",
       "  (40): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (41): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (42): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (43): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (44): Dropout(p=0.1, inplace=False)\n",
       "  (45): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (46): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (47): Dropout(p=0.1, inplace=False)\n",
       "  (48): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (49): Dropout(p=0.1, inplace=False)\n",
       "  (50): GELU()\n",
       "  (51): Dropout(p=0.1, inplace=False)\n",
       "  (52): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (53): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (54): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (55): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (56): Dropout(p=0.1, inplace=False)\n",
       "  (57): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (58): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (59): Dropout(p=0.1, inplace=False)\n",
       "  (60): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (61): Dropout(p=0.1, inplace=False)\n",
       "  (62): GELU()\n",
       "  (63): Dropout(p=0.1, inplace=False)\n",
       "  (64): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (65): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (66): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (67): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (68): Dropout(p=0.1, inplace=False)\n",
       "  (69): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (70): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (71): Dropout(p=0.1, inplace=False)\n",
       "  (72): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (73): Dropout(p=0.1, inplace=False)\n",
       "  (74): GELU()\n",
       "  (75): Dropout(p=0.1, inplace=False)\n",
       "  (76): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (77): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (78): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (79): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (80): Dropout(p=0.1, inplace=False)\n",
       "  (81): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (82): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (83): Dropout(p=0.1, inplace=False)\n",
       "  (84): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (85): Dropout(p=0.1, inplace=False)\n",
       "  (86): GELU()\n",
       "  (87): Dropout(p=0.1, inplace=False)\n",
       "  (88): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (89): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (90): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (91): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (92): Dropout(p=0.1, inplace=False)\n",
       "  (93): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (94): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (95): Dropout(p=0.1, inplace=False)\n",
       "  (96): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (97): Dropout(p=0.1, inplace=False)\n",
       "  (98): GELU()\n",
       "  (99): Dropout(p=0.1, inplace=False)\n",
       "  (100): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (101): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (102): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (103): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (104): Dropout(p=0.1, inplace=False)\n",
       "  (105): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (106): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (107): Dropout(p=0.1, inplace=False)\n",
       "  (108): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (109): Dropout(p=0.1, inplace=False)\n",
       "  (110): GELU()\n",
       "  (111): Dropout(p=0.1, inplace=False)\n",
       "  (112): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (113): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (114): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (115): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (116): Dropout(p=0.1, inplace=False)\n",
       "  (117): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (118): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (119): Dropout(p=0.1, inplace=False)\n",
       "  (120): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (121): Dropout(p=0.1, inplace=False)\n",
       "  (122): GELU()\n",
       "  (123): Dropout(p=0.1, inplace=False)\n",
       "  (124): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (125): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (126): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (127): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (128): Dropout(p=0.1, inplace=False)\n",
       "  (129): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (130): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (131): Dropout(p=0.1, inplace=False)\n",
       "  (132): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (133): Dropout(p=0.1, inplace=False)\n",
       "  (134): GELU()\n",
       "  (135): Dropout(p=0.1, inplace=False)\n",
       "  (136): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (137): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (138): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (139): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (140): Dropout(p=0.1, inplace=False)\n",
       "  (141): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (142): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (143): Dropout(p=0.1, inplace=False)\n",
       "  (144): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (145): Dropout(p=0.1, inplace=False)\n",
       "  (146): GELU()\n",
       "  (147): Dropout(p=0.1, inplace=False)\n",
       "  (148): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (149): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (150): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (151): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (152): Dropout(p=0.1, inplace=False)\n",
       "  (153): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (154): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (155): Dropout(p=0.1, inplace=False)\n",
       "  (156): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (157): Dropout(p=0.1, inplace=False)\n",
       "  (158): GELU()\n",
       "  (159): Dropout(p=0.1, inplace=False)\n",
       "  (160): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (161): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (162): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (163): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (164): Dropout(p=0.1, inplace=False)\n",
       "  (165): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (166): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (167): Dropout(p=0.1, inplace=False)\n",
       "  (168): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (169): Dropout(p=0.1, inplace=False)\n",
       "  (170): GELU()\n",
       "  (171): Dropout(p=0.1, inplace=False)\n",
       "  (172): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (173): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (174): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (175): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (176): Dropout(p=0.1, inplace=False)\n",
       "  (177): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (178): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (179): Dropout(p=0.1, inplace=False)\n",
       "  (180): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (181): Dropout(p=0.1, inplace=False)\n",
       "  (182): GELU()\n",
       "  (183): Dropout(p=0.1, inplace=False)\n",
       "  (184): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (185): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (186): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (187): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (188): Dropout(p=0.1, inplace=False)\n",
       "  (189): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (190): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (191): Dropout(p=0.1, inplace=False)\n",
       "  (192): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (193): Dropout(p=0.1, inplace=False)\n",
       "  (194): GELU()\n",
       "  (195): Dropout(p=0.1, inplace=False)\n",
       "  (196): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (197): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (198): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (199): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (200): Dropout(p=0.1, inplace=False)\n",
       "  (201): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (202): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (203): Dropout(p=0.1, inplace=False)\n",
       "  (204): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (205): Dropout(p=0.1, inplace=False)\n",
       "  (206): GELU()\n",
       "  (207): Dropout(p=0.1, inplace=False)\n",
       "  (208): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (209): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (210): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (211): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (212): Dropout(p=0.1, inplace=False)\n",
       "  (213): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (214): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (215): Dropout(p=0.1, inplace=False)\n",
       "  (216): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (217): Dropout(p=0.1, inplace=False)\n",
       "  (218): GELU()\n",
       "  (219): Dropout(p=0.1, inplace=False)\n",
       "  (220): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (221): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (222): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (223): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (224): Dropout(p=0.1, inplace=False)\n",
       "  (225): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (226): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (227): Dropout(p=0.1, inplace=False)\n",
       "  (228): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (229): Dropout(p=0.1, inplace=False)\n",
       "  (230): GELU()\n",
       "  (231): Dropout(p=0.1, inplace=False)\n",
       "  (232): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (233): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (234): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (235): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (236): Dropout(p=0.1, inplace=False)\n",
       "  (237): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (238): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (239): Dropout(p=0.1, inplace=False)\n",
       "  (240): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (241): Dropout(p=0.1, inplace=False)\n",
       "  (242): GELU()\n",
       "  (243): Dropout(p=0.1, inplace=False)\n",
       "  (244): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (245): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (246): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (247): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (248): Dropout(p=0.1, inplace=False)\n",
       "  (249): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (250): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (251): Dropout(p=0.1, inplace=False)\n",
       "  (252): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (253): Dropout(p=0.1, inplace=False)\n",
       "  (254): GELU()\n",
       "  (255): Dropout(p=0.1, inplace=False)\n",
       "  (256): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (257): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (258): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (259): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (260): Dropout(p=0.1, inplace=False)\n",
       "  (261): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (262): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (263): Dropout(p=0.1, inplace=False)\n",
       "  (264): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (265): Dropout(p=0.1, inplace=False)\n",
       "  (266): GELU()\n",
       "  (267): Dropout(p=0.1, inplace=False)\n",
       "  (268): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (269): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (270): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (271): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (272): Dropout(p=0.1, inplace=False)\n",
       "  (273): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (274): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (275): Dropout(p=0.1, inplace=False)\n",
       "  (276): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (277): Dropout(p=0.1, inplace=False)\n",
       "  (278): GELU()\n",
       "  (279): Dropout(p=0.1, inplace=False)\n",
       "  (280): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (281): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (282): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (283): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (284): Dropout(p=0.1, inplace=False)\n",
       "  (285): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (286): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (287): Dropout(p=0.1, inplace=False)\n",
       "  (288): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (289): Dropout(p=0.1, inplace=False)\n",
       "  (290): GELU()\n",
       "  (291): Dropout(p=0.1, inplace=False)\n",
       "  (292): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (293): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (294): Dropout(p=0.1, inplace=False)\n",
       "  (295): Linear(in_features=1024, out_features=5, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load(load_model_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "jz3GnOgnqiw6",
    "outputId": "bf0fb0d7-e49a-4bc9-a163-0f1f6742146a"
   },
   "outputs": [],
   "source": [
    "# print(learner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7315,
     "status": "ok",
     "timestamp": 1681898272676,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "tmfkOBh08lY_",
    "outputId": "c1174a30-f221-463e-b791-10a91d94db61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [79, 1024]           51,471,360 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           526,336    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           1,024      False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [1024]               1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1024]               0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  5,125      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 254,676,997\n",
       "Total trainable params: 101,865,477\n",
       "Total non-trainable params: 152,811,520\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QAnyjWTTDNuu"
   },
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "executionInfo": {
     "elapsed": 31875,
     "status": "ok",
     "timestamp": 1681898304549,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "B9zNGbD-U4RK",
    "outputId": "82ac4952-314e-4ff4-e784-d778f44030e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='66' class='' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.02% [66/1097 00:19&lt;05:04 2.6000]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 7.59E-07\n",
      "Min loss divided by 10: 3.02E-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "HLHDaxYcDUUK",
    "outputId": "dbd29885-e573-40d0-d251-e340667692b3"
   },
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(20, max_lr=1e-6, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.645212</td>\n",
       "      <td>0.901225</td>\n",
       "      <td>0.645329</td>\n",
       "      <td>0.354671</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(epochs=1, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "m6PBVCNobiXf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(epochs=110, lr=1e-6)\n",
    "# time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "# learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "# torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.recorder.plot_losses()\n",
    "# learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='10' class='' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      9.09% [10/110 40:51&lt;6:48:37]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.673061</td>\n",
       "      <td>0.882518</td>\n",
       "      <td>0.648404</td>\n",
       "      <td>0.351596</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.664471</td>\n",
       "      <td>0.851772</td>\n",
       "      <td>0.661156</td>\n",
       "      <td>0.338844</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.623274</td>\n",
       "      <td>0.861984</td>\n",
       "      <td>0.656478</td>\n",
       "      <td>0.343522</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630995</td>\n",
       "      <td>0.870679</td>\n",
       "      <td>0.656478</td>\n",
       "      <td>0.343522</td>\n",
       "      <td>04:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.619215</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.653018</td>\n",
       "      <td>0.346982</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.665388</td>\n",
       "      <td>0.889591</td>\n",
       "      <td>0.650070</td>\n",
       "      <td>0.349930</td>\n",
       "      <td>04:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.653563</td>\n",
       "      <td>0.863111</td>\n",
       "      <td>0.659170</td>\n",
       "      <td>0.340830</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.663617</td>\n",
       "      <td>0.904848</td>\n",
       "      <td>0.642830</td>\n",
       "      <td>0.357170</td>\n",
       "      <td>04:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.649840</td>\n",
       "      <td>0.868115</td>\n",
       "      <td>0.653274</td>\n",
       "      <td>0.346726</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.669626</td>\n",
       "      <td>0.873384</td>\n",
       "      <td>0.651929</td>\n",
       "      <td>0.348071</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='926' class='' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      84.41% [926/1097 03:26&lt;00:38 0.6681]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "time = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "learner.save(os.path.join(ROOT_PATH, KOKONOTEST + '_' + time))\n",
    "torch.save({'state_dict': learner.model.state_dict(), 'model': learner.model}, os.path.join(ROOT_PATH, KOKONOTEST + '_' + time + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt4oKggTDX57"
   },
   "outputs": [],
   "source": [
    "learner.predict('This movie is the worst one so far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7xjC8rrGWZK"
   },
   "outputs": [],
   "source": [
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHQy4layD63X"
   },
   "source": [
    "## Export Learner (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OTgPawjDrVp"
   },
   "outputs": [],
   "source": [
    "# learner.export(model_name)\n",
    "# !mv ./export.pkl /content/drive/My\\ Drive/LAB/kge_sentiment_analysis\n",
    "# !mv /content/drive/My\\ Drive/LAB/kge_sentiment_analysis/export.pkl /content/drive/My\\ Drive/LAB/bsz2048_DEM-RoBERTa.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQvEKBH_Eq7V"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/My Drive/LAB/'\n",
    "# export_learner = load_learner(path, file = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMQr88C2FAO0"
   },
   "outputs": [],
   "source": [
    "# export_learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txW64dH8FPkI"
   },
   "source": [
    "## Creating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CL7otQdLFRUX"
   },
   "outputs": [],
   "source": [
    "# def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "#     preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "#     sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "#     reverse_sampler = np.argsort(sampler)\n",
    "#     return preds[reverse_sampler, :]\n",
    "\n",
    "# test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dP6IBczGZRD"
   },
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv(DATA_ROOT / 'sampleSubmission.csv')\n",
    "# sample_submission['Sentiment'] = np.argmax(test_preds, axis = 1)\n",
    "# sample_submission.to_csv('prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBkUrEZpG13m"
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFGWNvhPG39j"
   },
   "outputs": [],
   "source": [
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CfueTuqG6v0"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# def create_download_link(title = 'Download CSV file', filename = 'data.csv'):\n",
    "#     html = '<a href=(filename)->(title)</a>'\n",
    "#     html = html.format(title=title, filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# create_download_link(filename='prediciton.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "10ceIJFxiecuBcRtznBcInn3Q8OBPR-rG",
     "timestamp": 1659685428876
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016e9d4951dc4ffaa116b68651b5a5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ac39008291438abe8a0cdec6d0b48e",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f0efcec51584512801c27a3cd6955c1",
      "value": 456318
     }
    },
    "0d1764eea96f42b59b0613a32675d84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_4f06c58c7d7f4db499237ce58193f37c",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "10c337408ee34116ab68750ca4016873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "132793e6053c41a5a775a7b4d3dc190c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_870b2aaafdab485c9c84d37ca50e3751",
       "IPY_MODEL_18192a8ad1094e05bb8679cdc82b0015",
       "IPY_MODEL_19dd2d607cc7428093d7974a3dc630c5"
      ],
      "layout": "IPY_MODEL_7628994d5e6f4802a9a7edb25a3d3da9"
     }
    },
    "18192a8ad1094e05bb8679cdc82b0015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4931528732d14b7da8a4bc12fc66acd3",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_800850935d4d4d41973e053ff7e9be7d",
      "value": 482
     }
    },
    "19dd2d607cc7428093d7974a3dc630c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65077ad08d2a4d869053cf49875ac04c",
      "placeholder": "​",
      "style": "IPY_MODEL_1f23acd2e5414a2493bc041d17d35d65",
      "value": " 482/482 [00:00&lt;00:00, 20.6kB/s]"
     }
    },
    "1f23acd2e5414a2493bc041d17d35d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff839855735448bafa7c923e3c82058": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20be103a8b6e4c05a5dc25015cfd358d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ba466b3677542d290e5edc913bbf915",
      "placeholder": "​",
      "style": "IPY_MODEL_918d275243764415b4aacd122ede250c",
      "value": " 1.43G/1.43G [00:05&lt;00:00, 257MB/s]"
     }
    },
    "28c07e0b489a4929926d1002df24b091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef60fa55102d4902b9ddbcc45b6090ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8532ee00cdbe476796eaec8355396cea",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "332a2f4786154442b5296395129c2e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28c07e0b489a4929926d1002df24b091",
       "IPY_MODEL_016e9d4951dc4ffaa116b68651b5a5e9",
       "IPY_MODEL_38edf987d8fc4ce58ec72c4ed0e4ed67"
      ],
      "layout": "IPY_MODEL_c12a0a03c11641d996cedcb2554837e7"
     }
    },
    "38edf987d8fc4ce58ec72c4ed0e4ed67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ff839855735448bafa7c923e3c82058",
      "placeholder": "​",
      "style": "IPY_MODEL_c99275e215d44398809e6d5accd8f6b4",
      "value": " 456k/456k [00:00&lt;00:00, 3.75MB/s]"
     }
    },
    "3d59f5ebbe854243b3543b89c3e55c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42032dc8a67d4f6cae837fd6c381fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_844024c43a194e08a1951bdb90c3d20a",
       "IPY_MODEL_9114752678be4ec2a52116ac2c4ac632",
       "IPY_MODEL_20be103a8b6e4c05a5dc25015cfd358d"
      ],
      "layout": "IPY_MODEL_591a0f885fa94b4aba32a13f567864a2"
     }
    },
    "4931528732d14b7da8a4bc12fc66acd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f06c58c7d7f4db499237ce58193f37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "591a0f885fa94b4aba32a13f567864a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba466b3677542d290e5edc913bbf915": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e4d7c27ceab4bf5bd780770c6b829fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f0efcec51584512801c27a3cd6955c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "633267e43eba4060bebdc1d043c0f155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65077ad08d2a4d869053cf49875ac04c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66ab18b60f5e4294b4309d3fd293e7a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7628994d5e6f4802a9a7edb25a3d3da9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f018262d1a047109366e216f9e83e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "800850935d4d4d41973e053ff7e9be7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82ac39008291438abe8a0cdec6d0b48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844024c43a194e08a1951bdb90c3d20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96e86f098f5f442ea05e1aed9309bb2f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d59f5ebbe854243b3543b89c3e55c50",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "8532ee00cdbe476796eaec8355396cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "870b2aaafdab485c9c84d37ca50e3751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66ab18b60f5e4294b4309d3fd293e7a4",
      "placeholder": "​",
      "style": "IPY_MODEL_c5dfa7b8af9448b1b4cb3b10812a9102",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "9114752678be4ec2a52116ac2c4ac632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2a72c584dca4d618ebfb185cc23b9fc",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_633267e43eba4060bebdc1d043c0f155",
      "value": 1425941629
     }
    },
    "918d275243764415b4aacd122ede250c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96e86f098f5f442ea05e1aed9309bb2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f9ee57980f64607aed63201e44d2263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d1764eea96f42b59b0613a32675d84c",
       "IPY_MODEL_af7c57c570614472b160423724a07590",
       "IPY_MODEL_e388830b59ba4f9d837ea6cdb9c698e7"
      ],
      "layout": "IPY_MODEL_a46848278e9a45bdbf87f4513a5da72a"
     }
    },
    "a46848278e9a45bdbf87f4513a5da72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7c57c570614472b160423724a07590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d14ec50a29224593a87a902c5a23d581",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f018262d1a047109366e216f9e83e64",
      "value": 898823
     }
    },
    "c12a0a03c11641d996cedcb2554837e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5dfa7b8af9448b1b4cb3b10812a9102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c99275e215d44398809e6d5accd8f6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d14ec50a29224593a87a902c5a23d581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2a72c584dca4d618ebfb185cc23b9fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e388830b59ba4f9d837ea6cdb9c698e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e4d7c27ceab4bf5bd780770c6b829fb",
      "placeholder": "​",
      "style": "IPY_MODEL_10c337408ee34116ab68750ca4016873",
      "value": " 899k/899k [00:00&lt;00:00, 3.27MB/s]"
     }
    },
    "ea8af2f6e8c44a7ab9457f15c6c13ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef60fa55102d4902b9ddbcc45b6090ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
