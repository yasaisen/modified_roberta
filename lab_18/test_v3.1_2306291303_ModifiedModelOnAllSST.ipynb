{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'SST5'\n",
    "# DATASET = 'SST2'\n",
    "BSZ = 128\n",
    "EPOCH = 8\n",
    "# MODEL = 'bert'\n",
    "# MODEL = 'roberta'\n",
    "# MODEL = 'xlnet'\n",
    "# MODEL = 'distilbert'\n",
    "MODEL = 'edm-roberta'\n",
    "\n",
    "KOKONOTEST = 'D_' + DATASET + '_M_' + MODEL + '_B_' + str(BSZ) + '_E_' + str(EPOCH)\n",
    "print(KOKONOTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 19 14:36:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 35%   55C    P8    31W / 200W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (23.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-hjhy1l_b\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git': 'git' while executing command git version\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: fastai==1.0.58 in /opt/conda/lib/python3.7/site-packages (1.0.58)\n",
      "Requirement already satisfied: bottleneck in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.3.7)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (4.9.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.4.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.8.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.18.1)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (7.352.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (20.9)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (9.5.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (5.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (2.22.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (1.9.0+cu111)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (3.5.3)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from fastai==1.0.58) (0.10.0+cu111)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.65.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (2.11.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (45.2.0.post20200210)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18->fastai==1.0.58) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->fastai==1.0.58) (2.4.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai==1.0.58) (2020.4.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->fastai==1.0.58) (2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->fastai==1.0.58) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai==1.0.58) (2019.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->fastai==1.0.58) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.0.18->fastai==1.0.58) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=2.0.18->fastai==1.0.58) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.18.1)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (9.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.7/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mtokenizers                  0.13.3\n",
      "transformers                4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q transformers==4.28.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install fastai==1.0.58\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install SentencePiece\n",
    "    \n",
    "!pip list | grep -E 'transformers|tokenizers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version: 1.0.58\n",
      "transformers version: 4.28.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version: %s' %(fastai.__version__))\n",
    "print('transformers version: %s' %(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu vars\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True # speed up with gpu\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449287,
     "status": "ok",
     "timestamp": 1681898134125,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YPh_dtQJJhej",
    "outputId": "36283b7b-0e31-41ea-8815-1eba40f7d2fb"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home/temp_230612'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681898192514,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZEvggolFoRbH"
   },
   "outputs": [],
   "source": [
    "def checkpath(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681898192514,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "RbdAfW1vHmbn"
   },
   "outputs": [],
   "source": [
    "# for dirname, _, filenames in os.walk('/content/drive/My Drive/LAB/kge_sentiment_anlysis'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "K8ol3_URCad5"
   },
   "outputs": [],
   "source": [
    "#  # tokenizer version\n",
    "# Version = 'T_v_1.3.3'\n",
    "\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "\n",
    "# tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681898193038,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "fgSOFnkTEMwv"
   },
   "outputs": [],
   "source": [
    " # model version\n",
    "Version = 'M_v_8.0.0'\n",
    "\n",
    "root_folder = os.path.abspath(os.path.join(ROOT_PATH, Version))\n",
    "\n",
    "model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "checkpath(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1681898193371,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6ZSnPW0GPA9V"
   },
   "outputs": [],
   "source": [
    "# Data selection\n",
    "\n",
    "if DATASET == 'SST5':\n",
    "    dataset = 'SST5'\n",
    "    DATA_ROOT = Path(os.path.join(ROOT_PATH, 'finetune_dataset/kge_sentiment_analysis'))\n",
    "    train_cols = 'Phrase'\n",
    "    label_cols = 'Sentiment'\n",
    "    classification_head = 5\n",
    "elif DATASET == 'SST2':\n",
    "    dataset = 'SST2'\n",
    "    DATA_ROOT = Path(os.path.join(ROOT_PATH, 'finetune_dataset/IMDB_MovieReviews'))\n",
    "    train_cols = 'review'\n",
    "    label_cols = 'sentiment'\n",
    "    classification_head = 2\n",
    "\n",
    "\n",
    "# Parameters\n",
    "\n",
    "lr = 1e-5\n",
    "bsz = BSZ\n",
    "epoch = EPOCH\n",
    "\n",
    "# model_name = 'bsz2048_DEM-RoBERTa.pkl'\n",
    "\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "BOOM = 4\n",
    "\n",
    "# Model selection\n",
    "\n",
    "if MODEL == 'bert':\n",
    "    model_type = 'bert'\n",
    "    pretrained_model_name='bert-base-uncased'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'roberta':\n",
    "    model_type = 'roberta'\n",
    "    pretrained_model_name = 'roberta-large'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'xlnet':\n",
    "    model_type = 'xlnet'\n",
    "    pretrained_model_name = 'xlnet-base-cased'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'distilbert':\n",
    "    model_type = 'distilbert'\n",
    "    pretrained_model_name = 'distilbert-base-uncased'\n",
    "    pretrained_tokenizer_name = pretrained_model_name\n",
    "    EDM = False\n",
    "elif MODEL == 'edm-roberta':\n",
    "    model_type = 'roberta'\n",
    "    pretrained_model_name = 'roberta-large'\n",
    "    pretrained_tokenizer_name = pretrained_model_name#tokenizer_folder\n",
    "    EDM = True\n",
    "\n",
    "# model_type = 'xlm'\n",
    "# pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "# pretrained_tokenizer_name = pretrained_model_name\n",
    "# EDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1681898194705,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YI1PkOgsK7Vc"
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST5'):\n",
    "  train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
    "  test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "vckhJ1W1BMKO"
   },
   "outputs": [],
   "source": [
    "if(dataset == 'SST2'):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  df = pd.read_csv(DATA_ROOT / 'IMDB_Dataset.csv.zip')\n",
    "  df['Sentiment'] = df['sentiment'].replace(['negative', 'positive'], [0, 1])\n",
    "  train, test = train_test_split(df, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195089,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "m9pUQJP2Bgyy",
    "outputId": "7d961fd5-bfc6-4820-8d1b-5c8cf9f62bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ9ZzGHlPPo0"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ZSBBSBpZPODx"
   },
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type='bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.model_max_length\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] + [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUnibZpXdnVF"
   },
   "source": [
    "- bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "\n",
    "- distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "- xlnet:      padding + tokens + [SEP] + [CLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681898195091,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "qfSwieon8K-N"
   },
   "outputs": [],
   "source": [
    "# # from transformers import RobertaTokenizerFast\n",
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "# MAX_LEN = 128\n",
    "# # Create the tokenizer from a trained one\n",
    "# # transformer_tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)\n",
    "# transformer_tokenizer = RobertaTokenizer.from_pretrained(tokenizer_folder)#, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9f9ee57980f64607aed63201e44d2263",
      "0d1764eea96f42b59b0613a32675d84c",
      "af7c57c570614472b160423724a07590",
      "e388830b59ba4f9d837ea6cdb9c698e7",
      "a46848278e9a45bdbf87f4513a5da72a",
      "ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "4f06c58c7d7f4db499237ce58193f37c",
      "d14ec50a29224593a87a902c5a23d581",
      "7f018262d1a047109366e216f9e83e64",
      "5e4d7c27ceab4bf5bd780770c6b829fb",
      "10c337408ee34116ab68750ca4016873",
      "332a2f4786154442b5296395129c2e71",
      "28c07e0b489a4929926d1002df24b091",
      "016e9d4951dc4ffaa116b68651b5a5e9",
      "38edf987d8fc4ce58ec72c4ed0e4ed67",
      "c12a0a03c11641d996cedcb2554837e7",
      "ef60fa55102d4902b9ddbcc45b6090ab",
      "8532ee00cdbe476796eaec8355396cea",
      "82ac39008291438abe8a0cdec6d0b48e",
      "5f0efcec51584512801c27a3cd6955c1",
      "1ff839855735448bafa7c923e3c82058",
      "c99275e215d44398809e6d5accd8f6b4",
      "132793e6053c41a5a775a7b4d3dc190c",
      "870b2aaafdab485c9c84d37ca50e3751",
      "18192a8ad1094e05bb8679cdc82b0015",
      "19dd2d607cc7428093d7974a3dc630c5",
      "7628994d5e6f4802a9a7edb25a3d3da9",
      "66ab18b60f5e4294b4309d3fd293e7a4",
      "c5dfa7b8af9448b1b4cb3b10812a9102",
      "4931528732d14b7da8a4bc12fc66acd3",
      "800850935d4d4d41973e053ff7e9be7d",
      "65077ad08d2a4d869053cf49875ac04c",
      "1f23acd2e5414a2493bc041d17d35d65"
     ]
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1681898196569,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zZGIeSCFXoGz",
    "outputId": "42421471-3daf-48c5-a1c2-ea3f120450a4"
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_tokenizer_name)\n",
    "transformer_tokenizer.model_max_length = 128#512\n",
    "\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "dk4SteMRFhG7",
    "outputId": "57d6ca64-5e8a-442e-943f-51588c4c7633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='roberta-large', vocab_size=50265, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umdWd40_dyqq"
   },
   "source": [
    "#### Custom Numericallizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898196570,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "LbYVAu1ocCsm"
   },
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Jmxwz5k3HY"
   },
   "source": [
    "#### Custom Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5CPXNWsQk0f8"
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuI3ked5pzdC"
   },
   "source": [
    "#### Settings up the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681898196927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QxhRoqhxpx3x"
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681898196928,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "KV95r6jY6UC5",
    "outputId": "35d5d19d-1024-4736-91e3-70924e008d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "# print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 52010,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "F_l7LDgGgYNG",
    "outputId": "bab52ad6-db61-4eb0-de43-045a7850c000"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols=train_cols, processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= label_cols)\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bsz, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1681898248932,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "W6S_eJ6DhLgy"
   },
   "outputs": [],
   "source": [
    "# print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "# print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "# print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "# databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1681898248935,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "i-rzhHnki7Vb"
   },
   "outputs": [],
   "source": [
    "# print('[CLS] id: ', transformer_tokenizer.cls_token_id)\n",
    "# print('[SEP] id: ', transformer_tokenizer.sep_token_id)\n",
    "# print('[PAD] id: ', pad_idx)\n",
    "# test_one_batch = databunch.one_batch()[0]\n",
    "# print('Batch shape: ', test_one_batch.shape)\n",
    "# print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import roBerta + Boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "# from ...activations import ACT2FN, gelu\n",
    "from transformers.activations import ACT2FN, gelu\n",
    "# from ...modeling_outputs import (\n",
    "#     BaseModelOutputWithPastAndCrossAttentions,\n",
    "#     BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "#     CausalLMOutputWithCrossAttentions,\n",
    "#     MaskedLMOutput,\n",
    "#     MultipleChoiceModelOutput,\n",
    "#     QuestionAnsweringModelOutput,\n",
    "#     SequenceClassifierOutput,\n",
    "#     TokenClassifierOutput,\n",
    "# )\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "# from ...modeling_utils import PreTrainedModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "# from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "# from ...utils import (\n",
    "#     add_code_sample_docstrings,\n",
    "#     add_start_docstrings,\n",
    "#     add_start_docstrings_to_model_forward,\n",
    "#     logging,\n",
    "#     replace_return_docstrings,\n",
    "# )\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "# from .configuration_roberta import RobertaConfig\n",
    "from transformers.models.roberta.configuration_roberta import RobertaConfig\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"roberta-base\"\n",
    "_CONFIG_FOR_DOC = \"RobertaConfig\"\n",
    "\n",
    "ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"roberta-base\",\n",
    "    \"roberta-large\",\n",
    "    \"roberta-large-mnli\",\n",
    "    \"distilroberta-base\",\n",
    "    \"roberta-base-openai-detector\",\n",
    "    \"roberta-large-openai-detector\",\n",
    "    # See all RoBERTa models at https://huggingface.co/models?filter=roberta\n",
    "]\n",
    "\n",
    "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\n",
    "\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            This parameter can only be used when the model is initialized with `type_vocab_size` parameter with value\n",
    "            >= 2. All the value in this tensor should be always < type_vocab_size.\n",
    "\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaAttention, \n",
    "    RobertaPreTrainedModel, \n",
    "    RobertaPooler, \n",
    "    RobertaEmbeddings, \n",
    "    RobertaClassificationHead\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boom_crop(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int) -> None:\n",
    "        super(Boom_crop, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        ninp = self.out_features\n",
    "        output = torch.narrow(input, -1, 0, input.shape[-1] // ninp * ninp)\n",
    "        output = output.view(*output.shape[:-1], output.shape[-1] // ninp, ninp)\n",
    "        output = output.sum(dim=-2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boom_Layer(nn.Module):\n",
    "    def __init__(self, in_features: int, mid_features: int, dropout=0.1) -> None:\n",
    "        super(Boom_Layer, self).__init__()\n",
    "\n",
    "        self.boom_crop = Boom_crop(in_features, mid_features)\n",
    "\n",
    "        self.up_linear = nn.Linear(mid_features, in_features)\n",
    "        self.act = GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "\n",
    "        output = self.boom_crop(input)\n",
    "        output = self.up_linear(output)\n",
    "        output += input\n",
    "        output = self.act(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaIntermediateAndBoom(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # self.dense_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        # if isinstance(config.hidden_act, str):\n",
    "        #     self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        # else:\n",
    "        #     self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "        # self.dense_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "\n",
    "        self.boom = Boom_Layer(config.hidden_size, config.intermediate_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        # hidden_states = self.dense_1(input_tensor)\n",
    "        # hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "\n",
    "        # hidden_states = self.dense_2(hidden_states)\n",
    "\n",
    "        hidden_states = self.boom(input_tensor)\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = RobertaAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        self.add_cross_attention = config.add_cross_attention\n",
    "        if self.add_cross_attention:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
    "            self.crossattention = RobertaAttention(config, position_embedding_type=\"absolute\")\n",
    "        # self.intermediate = RobertaIntermediate(config)#####\n",
    "        # self.output = RobertaOutput(config)#####\n",
    "        \n",
    "        self.intermediateandboom = RobertaIntermediateAndBoom(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "\n",
    "        # if decoder, the last output is tuple of self-attn cache\n",
    "        if self.is_decoder:\n",
    "            outputs = self_attention_outputs[1:-1]\n",
    "            present_key_value = self_attention_outputs[-1]\n",
    "        else:\n",
    "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        cross_attn_present_key_value = None\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"\n",
    "                    \" by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "\n",
    "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
    "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output,\n",
    "                attention_mask,\n",
    "                head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                cross_attn_past_key_value,\n",
    "                output_attentions,\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
    "\n",
    "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
    "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
    "            present_key_value = present_key_value + cross_attn_present_key_value\n",
    "\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "        # if decoder, return the attn key/values as the last output\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (present_key_value,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        # print(attention_output.shape)\n",
    "        # intermediate_output = self.intermediate(attention_output)\n",
    "        # print(intermediate_output.shape)\n",
    "        # layer_output = self.output(intermediate_output, attention_output)\n",
    "        # print(layer_output.shape)\n",
    "\n",
    "        layer_output = self.intermediateandboom(attention_output)\n",
    "\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([ModifiedRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "        next_decoder_cache = () if use_cache else None\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                if use_cache:\n",
    "                    logger.warning(\n",
    "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                    )\n",
    "                    use_cache = False\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    past_key_value,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache += (layer_outputs[-1],)\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    next_decoder_cache,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_decoder_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaModel(RobertaPreTrainedModel):\n",
    "    \"\"\"\n",
    "\n",
    "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
    "    cross-attention is added between the self-attention layers, following the architecture described in *Attention is\n",
    "    all you need*_ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\n",
    "    Kaiser and Illia Polosukhin.\n",
    "\n",
    "    To behave as an decoder the model needs to be initialized with the `is_decoder` argument of the configuration set\n",
    "    to `True`. To be used in a Seq2Seq model, the model needs to initialized with both `is_decoder` argument and\n",
    "    `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n",
    "\n",
    "    .. _*Attention is all you need*: https://arxiv.org/abs/1706.03762\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.__init__ with Bert->Roberta\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = RobertaEmbeddings(config)\n",
    "        self.encoder = ModifiedRobertaEncoder(config)\n",
    "\n",
    "        self.pooler = RobertaPooler(config) if add_pooling_layer else None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.forward\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if self.config.is_decoder:\n",
    "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        else:\n",
    "            use_cache = False\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # past_key_values_length\n",
    "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            past_key_values_length=past_key_values_length,\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values=encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.roberta = ModifiedRobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=\"'optimism'\",\n",
    "        expected_loss=0.08,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5ePMI5LllI2s",
    "outputId": "7253e07b-58de-4951-8d6d-6ea222f438ea"
   },
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = classification_head\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1681898248939,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "WZtevDMIjiBr"
   },
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type())\n",
    "        logits = self.transformer(input_ids, attention_mask = attention_mask)[0]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing ModifiedRobertaForSequenceClassification: ['roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'lm_head.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.17.output.dense.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight']\n",
      "- This IS expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ModifiedRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ModifiedRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.encoder.layer.0.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.11.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.20.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.22.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.1.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.4.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.13.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.12.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.15.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.12.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.23.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.1.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.15.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.2.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.17.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.17.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.19.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.22.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.21.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.2.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.15.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.5.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.23.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.6.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.10.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.0.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.11.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.21.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.7.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.12.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.14.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.20.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.13.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.9.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.5.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.8.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.13.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.3.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.19.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.18.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.16.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.2.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.7.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.4.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.0.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.22.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.2.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.4.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.3.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.4.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.21.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.23.intermediateandboom.LayerNorm.weight', 'classifier.out_proj.bias', 'roberta.encoder.layer.7.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.6.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.7.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.19.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.16.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.8.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.17.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.21.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.0.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.11.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.14.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.9.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.18.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.18.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.9.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.10.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.17.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.3.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.10.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.10.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.1.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.8.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.1.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.5.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.15.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.8.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.13.intermediateandboom.boom.linear1.bias', 'classifier.out_proj.weight', 'roberta.encoder.layer.9.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.11.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.19.intermediateandboom.LayerNorm.weight', 'classifier.dense.weight', 'roberta.encoder.layer.16.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.20.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.14.intermediateandboom.LayerNorm.weight', 'roberta.encoder.layer.3.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.6.intermediateandboom.LayerNorm.bias', 'roberta.encoder.layer.6.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.23.intermediateandboom.boom.linear1.weight', 'classifier.dense.bias', 'roberta.encoder.layer.20.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.5.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.12.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.22.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.16.intermediateandboom.boom.linear1.weight', 'roberta.encoder.layer.14.intermediateandboom.boom.linear1.bias', 'roberta.encoder.layer.18.intermediateandboom.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedRobertaForSequenceClassification.from_pretrained(\"roberta-large\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.roberta.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(len(model.roberta.encoder.layer)):\n",
    "    for param in model.roberta.encoder.layer[i].attention.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "42032dc8a67d4f6cae837fd6c381fa38",
      "844024c43a194e08a1951bdb90c3d20a",
      "9114752678be4ec2a52116ac2c4ac632",
      "20be103a8b6e4c05a5dc25015cfd358d",
      "591a0f885fa94b4aba32a13f567864a2",
      "96e86f098f5f442ea05e1aed9309bb2f",
      "3d59f5ebbe854243b3543b89c3e55c50",
      "e2a72c584dca4d618ebfb185cc23b9fc",
      "633267e43eba4060bebdc1d043c0f155",
      "5ba466b3677542d290e5edc913bbf915",
      "918d275243764415b4aacd122ede250c"
     ]
    },
    "executionInfo": {
     "elapsed": 10946,
     "status": "ok",
     "timestamp": 1681898259865,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zfuO_xApoAxv",
    "outputId": "2a3cbf79-2910-4416-b575-eab83a6ec744"
   },
   "outputs": [],
   "source": [
    "custom_transformer_model = CustomTransformerModel(transformer_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681898259865,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "N_FwWBBCqakA"
   },
   "outputs": [],
   "source": [
    "# transformer_model = RobertaForSequenceClassification.from_pretrained(model_folder, config=config)\n",
    "\n",
    "# custom_transformer_model = CustomTransformerModel(transformer_model=transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHODnf4pcgu"
   },
   "source": [
    "### Learner: Optimizer & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 5515,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "nPc6oee7paNw"
   },
   "outputs": [],
   "source": [
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, custom_transformer_model,\n",
    "                  opt_func = CustomAdamW,\n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681898265370,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "jz3GnOgnqiw6",
    "outputId": "bf0fb0d7-e49a-4bc9-a163-0f1f6742146a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): ModifiedRobertaForSequenceClassification(\n",
      "    (roberta): ModifiedRobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): ModifiedRobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (2): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (4): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (5): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (6): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (7): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (8): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (9): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (10): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (11): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (12): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (13): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (14): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (15): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (16): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (17): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (18): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (19): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (20): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (21): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (22): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (23): ModifiedRobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediateandboom): RobertaIntermediateAndBoom(\n",
      "              (boom): Boom_Layer(\n",
      "                (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELU()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z90uvKUHql9t"
   },
   "source": [
    "#### Discriminative Fine-tuning and Gradual unfreezing (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7315,
     "status": "ok",
     "timestamp": 1681898272676,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "tmfkOBh08lY_",
    "outputId": "c1174a30-f221-463e-b791-10a91d94db61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [79, 1024]           51,471,360 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           526,336    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 1024]           1,024      False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "Dropout              [16, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 1024]           1,049,600  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 4096]           4,198,400  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "GELU                 [79, 4096]           0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 1024]           0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 1024]           2,048      True      \n",
       "______________________________________________________________________\n",
       "Linear               [1024]               1,049,600  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1024]               0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  5,125      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 254,676,997\n",
       "Total trainable params: 101,865,477\n",
       "Total non-trainable params: 152,811,520\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QAnyjWTTDNuu"
   },
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681898272677,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YSvBSD6VuCIL"
   },
   "outputs": [],
   "source": [
    "# learner.fit(epochs=epoch, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "executionInfo": {
     "elapsed": 31875,
     "status": "ok",
     "timestamp": 1681898304549,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "B9zNGbD-U4RK",
    "outputId": "82ac4952-314e-4ff4-e784-d778f44030e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='68' class='' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.20% [68/1097 00:19&lt;04:52 4.1769]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 8.32E-06\n",
      "Min loss divided by 10: 3.02E-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_end=10, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "HLHDaxYcDUUK",
    "outputId": "dbd29885-e573-40d0-d251-e340667692b3"
   },
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(20, max_lr=1e-6, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(1, max_lr=lr, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(1, max_lr=lr, moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.273920</td>\n",
       "      <td>1.827401</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.270185</td>\n",
       "      <td>1.709528</td>\n",
       "      <td>0.179803</td>\n",
       "      <td>0.820197</td>\n",
       "      <td>04:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.254244</td>\n",
       "      <td>1.636182</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.158866</td>\n",
       "      <td>1.622757</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.210116</td>\n",
       "      <td>1.608252</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.166190</td>\n",
       "      <td>1.581574</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.252347</td>\n",
       "      <td>1.611894</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.222821</td>\n",
       "      <td>1.589905</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.255711</td>\n",
       "      <td>1.617590</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.228167</td>\n",
       "      <td>1.546841</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.251918</td>\n",
       "      <td>1.614877</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.239475</td>\n",
       "      <td>1.625970</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.236805</td>\n",
       "      <td>1.613480</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.255707</td>\n",
       "      <td>1.621655</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.220118</td>\n",
       "      <td>1.611099</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.237667</td>\n",
       "      <td>1.666551</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.236737</td>\n",
       "      <td>1.653894</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.209639</td>\n",
       "      <td>1.657038</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.283857</td>\n",
       "      <td>1.691276</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.198800</td>\n",
       "      <td>1.664216</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.235995</td>\n",
       "      <td>1.639873</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.232793</td>\n",
       "      <td>1.656960</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.242403</td>\n",
       "      <td>1.680596</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.213093</td>\n",
       "      <td>1.653937</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.249551</td>\n",
       "      <td>1.710611</td>\n",
       "      <td>0.212739</td>\n",
       "      <td>0.787261</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.230756</td>\n",
       "      <td>1.764236</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.213664</td>\n",
       "      <td>1.691030</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.243285</td>\n",
       "      <td>1.742153</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.213372</td>\n",
       "      <td>1.799059</td>\n",
       "      <td>0.210560</td>\n",
       "      <td>0.789440</td>\n",
       "      <td>03:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.230152</td>\n",
       "      <td>1.803901</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.240509</td>\n",
       "      <td>1.811856</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.221658</td>\n",
       "      <td>1.775495</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.213786</td>\n",
       "      <td>1.822137</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.235815</td>\n",
       "      <td>1.801052</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.181876</td>\n",
       "      <td>1.872420</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.820133</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.260939</td>\n",
       "      <td>1.789881</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.267429</td>\n",
       "      <td>1.800654</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.265462</td>\n",
       "      <td>1.855075</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.211974</td>\n",
       "      <td>1.825469</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.248257</td>\n",
       "      <td>1.943243</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.230670</td>\n",
       "      <td>1.921627</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.225621</td>\n",
       "      <td>1.926349</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.223568</td>\n",
       "      <td>1.911806</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.265653</td>\n",
       "      <td>1.969108</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.208512</td>\n",
       "      <td>1.870040</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.218116</td>\n",
       "      <td>2.023471</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.232394</td>\n",
       "      <td>1.941653</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.234209</td>\n",
       "      <td>1.901652</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.216963</td>\n",
       "      <td>1.899878</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.234712</td>\n",
       "      <td>1.897867</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.231632</td>\n",
       "      <td>1.846071</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.202517</td>\n",
       "      <td>1.941337</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.247641</td>\n",
       "      <td>1.961957</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.244796</td>\n",
       "      <td>1.943698</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.205209</td>\n",
       "      <td>1.917946</td>\n",
       "      <td>0.206523</td>\n",
       "      <td>0.793477</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.238540</td>\n",
       "      <td>1.964959</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.248301</td>\n",
       "      <td>2.030814</td>\n",
       "      <td>0.048956</td>\n",
       "      <td>0.951044</td>\n",
       "      <td>04:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>2.096974</td>\n",
       "      <td>0.047930</td>\n",
       "      <td>0.952070</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.220754</td>\n",
       "      <td>2.047324</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.221848</td>\n",
       "      <td>1.980729</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.273744</td>\n",
       "      <td>1.966476</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.251848</td>\n",
       "      <td>1.961530</td>\n",
       "      <td>0.210496</td>\n",
       "      <td>0.789504</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.237418</td>\n",
       "      <td>1.998574</td>\n",
       "      <td>0.054915</td>\n",
       "      <td>0.945085</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.198117</td>\n",
       "      <td>1.975028</td>\n",
       "      <td>0.208510</td>\n",
       "      <td>0.791490</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.200872</td>\n",
       "      <td>1.918216</td>\n",
       "      <td>0.209663</td>\n",
       "      <td>0.790337</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.250635</td>\n",
       "      <td>1.824598</td>\n",
       "      <td>0.207805</td>\n",
       "      <td>0.792195</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.217559</td>\n",
       "      <td>1.849723</td>\n",
       "      <td>0.207484</td>\n",
       "      <td>0.792516</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.214913</td>\n",
       "      <td>1.786196</td>\n",
       "      <td>0.215558</td>\n",
       "      <td>0.784442</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.188068</td>\n",
       "      <td>1.736705</td>\n",
       "      <td>0.237409</td>\n",
       "      <td>0.762591</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.187996</td>\n",
       "      <td>1.766912</td>\n",
       "      <td>0.235743</td>\n",
       "      <td>0.764257</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.251078</td>\n",
       "      <td>1.686500</td>\n",
       "      <td>0.258683</td>\n",
       "      <td>0.741317</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.169579</td>\n",
       "      <td>1.637472</td>\n",
       "      <td>0.280725</td>\n",
       "      <td>0.719275</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.248841</td>\n",
       "      <td>1.613415</td>\n",
       "      <td>0.290337</td>\n",
       "      <td>0.709663</td>\n",
       "      <td>03:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.202264</td>\n",
       "      <td>1.507842</td>\n",
       "      <td>0.330834</td>\n",
       "      <td>0.669166</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.166778</td>\n",
       "      <td>1.452489</td>\n",
       "      <td>0.353966</td>\n",
       "      <td>0.646034</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.173379</td>\n",
       "      <td>1.424772</td>\n",
       "      <td>0.363386</td>\n",
       "      <td>0.636614</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.178623</td>\n",
       "      <td>1.454994</td>\n",
       "      <td>0.333077</td>\n",
       "      <td>0.666923</td>\n",
       "      <td>04:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.197982</td>\n",
       "      <td>1.407525</td>\n",
       "      <td>0.361207</td>\n",
       "      <td>0.638793</td>\n",
       "      <td>03:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.172121</td>\n",
       "      <td>1.358149</td>\n",
       "      <td>0.384980</td>\n",
       "      <td>0.615020</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.122759</td>\n",
       "      <td>1.388055</td>\n",
       "      <td>0.369601</td>\n",
       "      <td>0.630399</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.128634</td>\n",
       "      <td>1.412784</td>\n",
       "      <td>0.369986</td>\n",
       "      <td>0.630014</td>\n",
       "      <td>04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.185954</td>\n",
       "      <td>1.379426</td>\n",
       "      <td>0.383058</td>\n",
       "      <td>0.616942</td>\n",
       "      <td>03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.154477</td>\n",
       "      <td>1.381949</td>\n",
       "      <td>0.384275</td>\n",
       "      <td>0.615725</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.170033</td>\n",
       "      <td>1.364777</td>\n",
       "      <td>0.391965</td>\n",
       "      <td>0.608035</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.106313</td>\n",
       "      <td>1.360954</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.612713</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.158907</td>\n",
       "      <td>1.360449</td>\n",
       "      <td>0.386646</td>\n",
       "      <td>0.613354</td>\n",
       "      <td>03:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.156131</td>\n",
       "      <td>1.377888</td>\n",
       "      <td>0.361976</td>\n",
       "      <td>0.638024</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.174437</td>\n",
       "      <td>1.359318</td>\n",
       "      <td>0.370114</td>\n",
       "      <td>0.629886</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.112190</td>\n",
       "      <td>1.344128</td>\n",
       "      <td>0.379021</td>\n",
       "      <td>0.620979</td>\n",
       "      <td>03:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.106919</td>\n",
       "      <td>1.340482</td>\n",
       "      <td>0.374407</td>\n",
       "      <td>0.625593</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.128996</td>\n",
       "      <td>1.357313</td>\n",
       "      <td>0.372293</td>\n",
       "      <td>0.627707</td>\n",
       "      <td>04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.124691</td>\n",
       "      <td>1.345059</td>\n",
       "      <td>0.366654</td>\n",
       "      <td>0.633346</td>\n",
       "      <td>03:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.089049</td>\n",
       "      <td>1.363433</td>\n",
       "      <td>0.368192</td>\n",
       "      <td>0.631808</td>\n",
       "      <td>04:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.094190</td>\n",
       "      <td>1.368270</td>\n",
       "      <td>0.353518</td>\n",
       "      <td>0.646482</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.090983</td>\n",
       "      <td>1.367153</td>\n",
       "      <td>0.345957</td>\n",
       "      <td>0.654043</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.164716</td>\n",
       "      <td>1.367939</td>\n",
       "      <td>0.356786</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>03:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.098977</td>\n",
       "      <td>1.380687</td>\n",
       "      <td>0.351724</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.140181</td>\n",
       "      <td>1.380803</td>\n",
       "      <td>0.359349</td>\n",
       "      <td>0.640651</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.100649</td>\n",
       "      <td>1.431914</td>\n",
       "      <td>0.337242</td>\n",
       "      <td>0.662758</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>1.431327</td>\n",
       "      <td>0.343009</td>\n",
       "      <td>0.656991</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.090856</td>\n",
       "      <td>1.466898</td>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.669358</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1.090404</td>\n",
       "      <td>1.467423</td>\n",
       "      <td>0.327630</td>\n",
       "      <td>0.672370</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.098188</td>\n",
       "      <td>1.454391</td>\n",
       "      <td>0.349289</td>\n",
       "      <td>0.650711</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>1.082301</td>\n",
       "      <td>1.437003</td>\n",
       "      <td>0.354607</td>\n",
       "      <td>0.645393</td>\n",
       "      <td>04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.053661</td>\n",
       "      <td>1.455385</td>\n",
       "      <td>0.347751</td>\n",
       "      <td>0.652249</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.007620</td>\n",
       "      <td>1.342269</td>\n",
       "      <td>0.396706</td>\n",
       "      <td>0.603294</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.012429</td>\n",
       "      <td>1.372628</td>\n",
       "      <td>0.393951</td>\n",
       "      <td>0.606049</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>1.040478</td>\n",
       "      <td>1.327966</td>\n",
       "      <td>0.402409</td>\n",
       "      <td>0.597591</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.061019</td>\n",
       "      <td>1.442229</td>\n",
       "      <td>0.348520</td>\n",
       "      <td>0.651480</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>1.043267</td>\n",
       "      <td>1.302061</td>\n",
       "      <td>0.432141</td>\n",
       "      <td>0.567859</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(epochs=20, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(epochs=20, lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "mt4oKggTDX57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.4233, 0.4169, 0.0896, 0.0572, 0.0130]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict('This movie is the worst one so far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "m6PBVCNobiXf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "advFmtFNQsa9"
   },
   "outputs": [],
   "source": [
    "learner.save(os.path.join(ROOT_PATH, 'results', KOKONOTEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='34' class='' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      30.91% [34/110 2:17:30&lt;5:07:22]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.038580</td>\n",
       "      <td>1.349942</td>\n",
       "      <td>0.406510</td>\n",
       "      <td>0.593490</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>1.298832</td>\n",
       "      <td>0.414520</td>\n",
       "      <td>0.585480</td>\n",
       "      <td>04:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.026793</td>\n",
       "      <td>1.364797</td>\n",
       "      <td>0.376330</td>\n",
       "      <td>0.623670</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.011238</td>\n",
       "      <td>1.334035</td>\n",
       "      <td>0.399205</td>\n",
       "      <td>0.600795</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.995303</td>\n",
       "      <td>1.280376</td>\n",
       "      <td>0.432974</td>\n",
       "      <td>0.567025</td>\n",
       "      <td>04:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.998017</td>\n",
       "      <td>1.277942</td>\n",
       "      <td>0.424324</td>\n",
       "      <td>0.575676</td>\n",
       "      <td>04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.066208</td>\n",
       "      <td>1.334186</td>\n",
       "      <td>0.404972</td>\n",
       "      <td>0.595028</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.003868</td>\n",
       "      <td>1.306472</td>\n",
       "      <td>0.418237</td>\n",
       "      <td>0.581763</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.053569</td>\n",
       "      <td>1.258031</td>\n",
       "      <td>0.431244</td>\n",
       "      <td>0.568756</td>\n",
       "      <td>04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.978157</td>\n",
       "      <td>1.274110</td>\n",
       "      <td>0.435025</td>\n",
       "      <td>0.564975</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.001735</td>\n",
       "      <td>1.293910</td>\n",
       "      <td>0.428233</td>\n",
       "      <td>0.571767</td>\n",
       "      <td>04:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.025520</td>\n",
       "      <td>1.236786</td>\n",
       "      <td>0.447969</td>\n",
       "      <td>0.552031</td>\n",
       "      <td>04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.308849</td>\n",
       "      <td>0.438806</td>\n",
       "      <td>0.561194</td>\n",
       "      <td>03:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.990178</td>\n",
       "      <td>1.320120</td>\n",
       "      <td>0.429130</td>\n",
       "      <td>0.570870</td>\n",
       "      <td>04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.011526</td>\n",
       "      <td>1.284982</td>\n",
       "      <td>0.439126</td>\n",
       "      <td>0.560874</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.982797</td>\n",
       "      <td>1.242300</td>\n",
       "      <td>0.451621</td>\n",
       "      <td>0.548379</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.012423</td>\n",
       "      <td>1.254023</td>\n",
       "      <td>0.453928</td>\n",
       "      <td>0.546072</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.002069</td>\n",
       "      <td>1.221283</td>\n",
       "      <td>0.465975</td>\n",
       "      <td>0.534025</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.000816</td>\n",
       "      <td>1.209605</td>\n",
       "      <td>0.471485</td>\n",
       "      <td>0.528515</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.971585</td>\n",
       "      <td>1.225328</td>\n",
       "      <td>0.466872</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.012409</td>\n",
       "      <td>1.225720</td>\n",
       "      <td>0.462322</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.956886</td>\n",
       "      <td>1.178626</td>\n",
       "      <td>0.486223</td>\n",
       "      <td>0.513777</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.005511</td>\n",
       "      <td>1.186787</td>\n",
       "      <td>0.480648</td>\n",
       "      <td>0.519352</td>\n",
       "      <td>03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.989012</td>\n",
       "      <td>1.220460</td>\n",
       "      <td>0.479751</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.971743</td>\n",
       "      <td>1.212008</td>\n",
       "      <td>0.474048</td>\n",
       "      <td>0.525952</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>1.185051</td>\n",
       "      <td>0.480584</td>\n",
       "      <td>0.519416</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.932547</td>\n",
       "      <td>1.175487</td>\n",
       "      <td>0.490837</td>\n",
       "      <td>0.509163</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.927271</td>\n",
       "      <td>1.164682</td>\n",
       "      <td>0.495963</td>\n",
       "      <td>0.504037</td>\n",
       "      <td>04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.946130</td>\n",
       "      <td>1.171970</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>0.508010</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.985613</td>\n",
       "      <td>1.158863</td>\n",
       "      <td>0.491670</td>\n",
       "      <td>0.508330</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.994544</td>\n",
       "      <td>1.191354</td>\n",
       "      <td>0.485518</td>\n",
       "      <td>0.514482</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.950478</td>\n",
       "      <td>1.164949</td>\n",
       "      <td>0.484045</td>\n",
       "      <td>0.515955</td>\n",
       "      <td>04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.925143</td>\n",
       "      <td>1.128533</td>\n",
       "      <td>0.499487</td>\n",
       "      <td>0.500513</td>\n",
       "      <td>03:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.933158</td>\n",
       "      <td>1.151859</td>\n",
       "      <td>0.493977</td>\n",
       "      <td>0.506023</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='972' class='' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      88.61% [972/1097 03:32&lt;00:27 0.9458]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlIElEQVR4nO3dd3wVVf7/8deHkBB6RyABAQUEIQJGQEFFsYC6dkUsa9vFXlZ/rlH3i2X97lq+u7quNda1oYgNBcEVQVcpElZAOhEpAelFkBo4vz9mmNwkN+QGbkku7+fjkQczZ86d+Rwm3A9zzswZc84hIiICUC3RAYiISOWhpCAiIgElBRERCSgpiIhIQElBREQCSgoiIhJIWFIwsyGJOnY8JHP7krltkNztS+a2QXK3L15tS+SVQtKePF8yty+Z2wbJ3b5kbhskd/uSPimIiEglY4l6ojmlVj3XvXOHhBw7HtasWUPTpk0THUZMJHPbILnbl8xtg+Ru3962TZs2ba1zLmaNrB6rHZcnrUFz8vLyEnV4EZEqycyWxHL/6j4SEZGAkoKIiASUFEREJFDumIKZvQKcBax2znXZR71jgEnAJc65EdELUUTEs2vXLgoKCti+fXuiQ4m59PR0MjMzSU1NjetxIxlofg14Gni9rApmlgI8CnwenbBEREorKCigbt26tGnTBjNLdDgx45xj3bp1FBQU0LZt27geu9zuI+fc18D6cqrdArwPrI5GUCIi4Wzfvp3GjRsndUIAMDMaN26ckCuiAx5TMLMM4DzguQMPR0Rk35I9IeyVqHZGY6D5SeBu59ye8iqa2RAzyzOzPL0GVERkvzTZ+z3q/0R1+otoJIVs4B0zWwxcCDxrZueGq+icy3XOZTvnsg+WbC8iyWPjxo08++yzFf7cGWecwcaNG6MVxtq936P+T260dgxRSArOubbOuTbOuTbACOBG59xHB7pfEZHKpqykUFhYuM/PjR49mgYNGsQoquiK5JbUYUA/vEuWAuB+IBXAOfd8TKMTEalEcnJy+PHHH+nWrRupqamkp6fTsGFD5s2bx4IFCzj33HNZtmwZ27dv57bbbmPIEK9np02bNuTl5bFlyxYGDhxI3759mThxIhkZGXz88cfUrFkzwS0rUm5ScM4NjnRnzrmrDiiaUEsnw1ePwYUvQ82GUdutiCSHBz+ZzZwVv0R1n51b1uP+3xxZ5vZHHnmEWbNmMX36dCZMmMCZZ57JrFmzgttGX3nlFRo1asS2bds45phjuOCCC2jcuHGxfSxcuJBhw4bx4osvcvHFF/P+++9z+eWXR7UdB6LyPtE89WX4cRyMvS/RkYiIhNWzZ89izxE89dRTHHXUUfTu3Ztly5axcOHCUp9p27Yt3bp1A+Doo49m8eLFcYo2MgmbJTUwbzTMGwXnPlNUtnsXLBwLNerB9LfgyPOg/amJi1FEKp19/Y8+XmrXrh0sT5gwgS+++IJJkyZRq1Yt+vXrF/Y5gxo1agTLKSkpbNu2LS6xRirxVwq/LIfpb8KK74vKlkyE7ZvgrCegaScYeau3LiKSQHXr1mXz5s1ht23atImGDRtSq1Yt5s2bx+TJk+McXXQkPil0vQiq14RprxWVzR8N1dOh40DvCmLLysi6kTYsAT3/ICIx0rhxY/r06UOXLl246667im0bMGAAhYWFdOrUiZycHHr37p2gKA9Mwt68VrNlB7dtxQJv5aMbYc7HcOc8SKsDT2bBIZ3h0ne97f++H759Em6YCIeUccm48At46wI47WE47pa4tEFE4mvu3Ll06tQp0WHETbj2mtk051x2rI6Z+CsFgKOvgp1bYNb7sGoWbFoKHc8o2n7crVAtFb5/q+x9fP+G9+cXD8LyadGLbdsG2L3ve5BFRJJF5UgKmcdAs85eF9K80YB5XUd71W7src981xuELmnbRpj/GWQNgrrNYcQ1Bz4GsXU9jLkXHm8Pn9x2YPsSEakiKkdSMPOuFlZ8D1Nf9JJEnWbF63S/HLauhQVjS39+7kjYvQN6XgcXvAQbl8Ent+//+MK01+CpbjD5WWja0RsIL9D7pEUk+VWOpACQdbE3uPzrGjjizNLbD+sPdZp7t6iWNONdaHw4ZPSA1r3hpHth9gewYEzF49iyxksozTrD9d/ANWO84372R9hT7px/IiJVWuVJCjUbes8jQPikkFIdjhrkXSlsCXltw8alsOQbr+to7yR7fW6HehkwpZxZODYuLf1F/+M4wMGAR6B5F6hRF055wBunmPnufjZORKRqqDxJAaD//XBeLjRpH357t8vB7S7+5fzDe96fWRcXlaVUh+xrYNEEWDM//L6mvgRPdoVJTxcvz/8CajeF5llFZVmDICMbvrgfdoS/R1lEJBlUrqRQr4V3NVCWph0gsyf89w34ZQXs2e11HbU+Fhq2KV63x5WQkuZ9+Zc06VkYdSdYNfj+zaKxhz27IX8cHH4KVAv5q6lWDQY+CltWwTdPHmgrReQgUadOHQBWrFjBhRdeGLZOv379yMurPGOWlSspRKLHFbB2Pvy9EzzczFvOCpNI6jT1uqOmDyv+v/tvnoCx90Cn33hdRGvnw8qZ3rYV02Hbei8plJSZDZ3PhSkveHc7iYhEqGXLlowYMSLRYUSk6iWFbpfBFR/CmX/3nl/oeZ33VHQ4PYfAzs0w4x3YtR1G3gJfPABdLoALX/U+V606zBzu1c//AjBod1L4/R1/p7e/qS/GomUiUsnl5OTwzDNF87Q98MADPPzww/Tv358ePXrQtWtXPv7441KfW7x4MV26dAFg27ZtXHLJJXTq1Inzzjuv0s19lPgJ8SqqWgocdjIcFkHdjKOhZXdvwHn627Div94X+0n3efup1Qjan+Y9NHfqQ5D/b+8ztRuH31+LLGh/Okx+DnrfCGm1w9cTkdj7LAdW/hDdfTbvCgMfKXPzoEGDuP3227npppsAGD58OGPHjuXWW2+lXr16rF27lt69e3P22WeX+Y7l5557jlq1ajF37lxmzpxJjx49otuGA1T1rhQqwgyO+T2sy4e1C2HQm9B/qJcQ9up6EWz+GeZ+4t1hFK7rKNTxd8LWdfDf14vKNiz2bmUVkaTWvXt3Vq9ezYoVK5gxYwYNGzakefPm3HvvvWRlZXHKKaewfPlyVq1aVeY+vv766+D9CVlZWWRlZZVZNxGq3pVCRXW9CDavgE7neAPVJXUcCGl14bO7we0pPym07gWH9oVvn/LGLL5+HPJegSYd4Lr/QPW02LRDRIrbx//oY+miiy5ixIgRrFy5kkGDBvHWW2+xZs0apk2bRmpqKm3atAk7ZXZVkdxXCuB9SZ9wV/iEAJBa0xt03rLSe1YiI4JLuePv8BLNE10g71VvnqY182DSP6Mbu4hUOoMGDeKdd95hxIgRXHTRRWzatIlmzZqRmprK+PHjWbJkyT4/f8IJJ/D2228DMGvWLGbOnBmPsCOW/EkhEln+QPVhJxfvWirLYSd7iaBdP7jhW7jkLS+xfPUYrP8ppqGKSGIdeeSRbN68mYyMDFq0aMFll11GXl4eXbt25fXXX+eII47Y5+dvuOEGtmzZQqdOnRg6dChHH310nCKPTMKmzk5v2d5tX1H6VXUJsWe3d2dSj99602Tsj19WwNM9oVVPuPz9oqerQ+0uhD27vEn9Umt5D9mJSMQ0dXbsp87WtxJ4VwfnPntg+6jXEk7+E4y527sFttvgom2bV8GHQ7wnrPc6pCtc93Xxh+RC7drmDZAf0iV8ghERiYFyu4/M7BUzW21ms8rYfpmZzTSzH8xsopkdFf0wq4iev/emw/joehhxLWwq8F4t+sIJsHQK9P2DN49S9jWw6gd/nqUyfHwzPN8XnusDU1/W9BoiEheRXCm8BjwNvF7G9p+AE51zG8xsIJAL9IpOeFVMtRS4cqQ3FcbEp2DeKNi905uC44oPit4aV7jTe2/E5Oeg/aml97NoAswa4Y1TbFgCo+6ACX+F342DhofGsUEilY9zrsxnAJJJorr2y71ScM59Dazfx/aJzrkN/upkIDNKsVVNabXh5Pvg5qnQ+WzvltghE4q/RrR6GhzzO+9KYc2C4p8v3Amj7/ISyfkvel1MV4/xyt+7yvtT5CCVnp7OunXrEvaFGS/OOdatW0d6enrcjx3tMYVrgc+ivM+qqUFrOD+37O1HXwVfPwbfvQBn/q2ofPIzsHYBXPqed7sswKHHwrnPwLuXw7//x5ucT+QglJmZSUFBAWvWJP/Dounp6WRmxv//2FFLCmZ2El5S6LuPOkOAIQA1mh8erUNXTXWaelcR04fByf8DNRt4XUVfPQZHnAUdTitev9NvoNcNMOU5OPQ46HxOxY+5ZgF88Ds49c/Q7sSoNEMknlJTU2nbtm2iw0i0JmYWOq1qrnNuH/8DrZiIbkk1szbAp865LmVszwI+BAY65xaEq1NSpbolNVF+ngkvHA/Z18KurTD7Q28675umeFcaJRXuhFcHwOq50Ot66H1D6deWlmXPHnjtTFg6EWo19p6+rp8R3faISMzF+pbUA354zcxaAx8AV0SaEMTXIgsO7QN5L8PcT6HbpfD7L8MnBPDGIga96U3F8c0T3kuCRt3pPSNRnulvegmh7x1QuAPeu1LjEyJSSrlXCmY2DOgHNAFWAfcDqQDOuefN7CXgAmDvs92FkWQxXSn41v3oTcTX8QyoUSfyz63Nh4n/8LqfqqVAr+u8K47F//HeTLdiuld2/P/zbmd9Otsb7L5qFMz5yBu07nW9xidEqphYXynoieaqbv1P3u2qM4cD/rls1M6boG/BGO/Pehmw+Bu4YWLRHFBj7oHJz8Lgd6HjgISFLyIVo6QgkVk1G+Z/5s3HlHG09xR0/hfwyR9g01I48W446d6i+rt3wXPHeTPD3jgZUlKLtm1cBg1axb0JIlK+5E0KLdq77T8rKcTcji1ecjjizOJf/ADzx8CwQTDwMa+rCWDlLHhlAPS7G467Jf7xisg+VfqBZqnkatSBI88tnRAAOpwObU+ACY94753etBzeughq1IUjz493pCJSCSgpHMzM4LT/hW0bvHdXv32xNyh92Xu6XVXkIKVZUg92LbKg22Uw7VWoVh0uHQ7Nwz6OIiIHASUF8ab8XjkDjr0ZDu+f6GhEJIGUFATqtYDrv0l0FCJSCWhMQUREAglLCg5YtGYLAAtWbea7n8qcnVtEROIkoVcKJ//tK+as+IXTnviai1+YVGr7rt17+NFPHPtjR+Futu/afSAhiogcVBLefXTGU/8JltvkjOLz2Su5Zdj3tMkZxdCPZ9H/b1+xYFX4V1H+6aMfuCS3KJkU7t5TbHufR8ZzxP+MiU3gIiJJKOFJoaQhb0zjkxnerJ/DvlsGwGlPfF2szqatu3jnu6W8OXkpkxd53U55i9dz+H2f8W3+Wr7NXwvA2i074hi5iEjVV2XuPjrur+N47ZqeXPbSFNZsLv5lv2VHIZ/NWgnAZS9NAeDVq44Jtu/Z4/h1ZyF104s/1btp2y42/LqTNk1qxzh6EZGqocokhRWbtpe6Ytiry/1jS5X9vGl7sNzu3tEAzHrwdOrUKGryUQ9+DsDiR86MZqgiIlVWpes+ipY9YSb6C00eu/eU3r584zZ2FJY/MP3x9OV0/NNn7CzcU27dWGuTM4oTHx+f6DBEJEkkbVL400ezwpZPzF/LzsI9HOZfPey1o3A3fR75kjuHzwC8LqeyxiT+/OkcdhTuYePWnWzcupNZyzexbP1WLn1xMqt/KbpCKdy9h3s//IFl67dGqVXhLVkX2/2LyMGjynQfRcul/phDqDY5o5h0z8kAfDrzZ56+tKjLafI9/WlePx3nHJe/PIVZy39h07ZdADz31Y+8+u3iYvvq+Zdx/HFAR64+ri3Tl23k7SlLyV+9heHXHRvbhomIREHSXilU1LF//TJYbpMzKlieMH81AK9PWsK3+euChOBtWxN2X4+Nmc8/xi3kpf8sAiA1xcLW++j75QzOnVzqVloRkUQ56K4UKirngx/I+eCHsNt+WvtrmZ/7fM5KFq3xtlevFj733v7udADGz1/DqZ0PObBARUSiQFcKMbI3IQCsChlnGDd3VakB6mlLNtAmZxTfL92wz33uKNzNvR/+ENHzF1MWrePXHYVs2raL3n8ZV+6+RURASSEu5q3cTJucUfT+yziu/VceJz4+nlnLNwXbn//qRwDOe3YiC1dtZtn6rfR55EvGzFrJ3J9/Cep9PnsVb09ZSvbDX/D0l2W/ynT1L9sZlDuZO4ZPJ2/xelb+sp2nxunVpyJSvnK7j8zsFeAsYLVzrtTbV8zMgH8AZwBbgaucc/+NdqDJYKV/xfDzpu2c9c/wU1WfGvIsxvVvTgOgX8em7Czcw+CerYNt//f5Ajq3rBes5y1ez4XPT+Kv53dl9gov4YydvYpBx7QCvAkIAZat30pmw5ps37WHjdt20qJ+zai1T0SqPnNh7ucvVsHsBGAL8HoZSeEM4Ba8pNAL+Idzrld5B67Ror1rceWT+xPzQSv70IbkLalYN9CrVx/D1a9OLVZ2W//2TJi/mhkFm/TgnkgVY2bTnHPZsdp/ud1HzrmvgX3Na30OXsJwzrnJQAMzaxGtAKVIRRMCUCohAPxj3EJmFHhXE1t3FvLvOasAb7wj9DkLETn4ROPuowxgWch6gV/2c8mKZjYEGALQvFWbYtvmPjSATkM1o2m8dR7qPeV9UsemjPdvsR1354kc1rROIsMSkbI1MbO8kPVc51xutHYe14Fm51yucy7bOZfdvEmjoLxdk9rUTEuJZyhSwviQZy76/+2rBEYiIuVYu/d71P+JWkKA6CSF5UCrkPVMv2yfLOR5riuOPbTYtvz/HRiFsEREpKKikRRGAr81T29gk3OuVNdRqQObcWv/9oy5/Xiu7tO22LbqKWWH9drVx5CVWb/CQbaon17hz4iIHGzKTQpmNgyYBHQ0swIzu9bMrjez6/0qo4FFQD7wInBjpAe/49QOHNG8Xtht7Zp67zgYd+eJPDW4e1Der2MzRt7clxn3n8ant/QF4O8XH8U53VqW2sctJx8eLE+6p3+kYYmIHLTKHWh2zg0uZ7sDbopGMDOGnsayDd6MnyNv7suW7YU0r5/OYU3rcFjT2hTuLrp9tn7NVOpn1A9uqTwrqyUfT/fe2Db0rM6c0ukQ1mzZwT+/zC/zeH0Pb8I3/lvaRESkks19VL9WKvVreV1DdWpUL/ZCnCNb7rvLKK160UXPNX297qjGddIAuLRX67CfOTKjnpKCiEiIpJrmYlB2K+48tUOwXrtGdaYPPZU/n1PqmbugfjidWnhdWqd0Kj5J3ZR7S3dB9WrbqFSZiEhVlVRJ4dELs7ilf/tiZQ1qpZFSzbvV6bfHHkqttBRyrziaf13Tk3ZN6/BdyBf98e2bAPDH0zvyyc19eenKbA6pVwOAMbcfzyH1Sg9W516RzdjbT4hVkxJm6uJ9Pa8oIskqqZJCeR46pwtzHhrAaUc258QOTQFoFvJFX23vfbIGXf07nHq1bQxA7bTwPW21aqTQulGtYL1fx6blxnFF70PLrZNoFz0/KdEhiEgCHFRJoSxHNK9LzsAj6N+pGQCHhnzJP3pBFu8M6U2rkLJQqSnVij1499rVPbk4OxOAB88+ks9uO77UZ/58blF3VteMssdKHr2ga8UaIiJygCrVQHOijPG7f5xz/CarJQ1rpwXbaqal0Ltd42D9u3v7s33XHk54fHyZ+3vonC6c2z2D4w5rgnOO/kc04/ZTOvCbp0vPjHp+jwx+CJlGO9R53TO5+/3iL/i56/SOHHdYY857dmKF2igiEgldKYQws2IJIZxm9dJp3bgWn97St9j/5P/zx5P44MbjAEhPTeG4w5oE+3z5qmOC7qiyXNH7UGqnpQTPXgA4Ss9ge9NJh9O9dcOI21SWL+5IvnEQETlwulLYT10y6tMlpOunVaNaZXYx7TXq1r7Ur5kKwLtDelMrrTr/9d+IllLNmP3QgGL1a1Qvez6oGfefxlEPfl6qfPh1x3LxC5OYmHMyP2/axgXPhR8bOLxZ3WD5u/v68+akJWzYuos3Ji/ZZxtEJLkpKcRR6LMWvfwuqfaH1GHeyl/4wykdyvoYAJf3bs3H368I1vcmF6DUOxH2rrdsUPQCnccvzOKuETOL1bt7wBGc2KEpzeqmc8dpHQGUFEQOckoKCZaemsJfz88qc3tmw5oUbNjGw+d25eFziw88f3pLX1Zvjuz9Bxdlt+K4w5vQ55Evg7Ib+h22f0GLSNJSUqiE/nRmJ0b/4M0pOOb2E9i6ozBsPa/7KvLJATP8K4dIJhTMGXhExPsVkeShpFAJ/e74dvzu+HZA6ek+DlR5r988v3sGH3y/nAt6ZEbtmCJSdZT7juZYyc7Odnl5eeVXlAOyYNVmUlOq0bZJ7Yjq7yzcw5J1v9L+kLrlVxaRuIv1O5p1pZDkOlTwyz2tejUlBJGDmJ5TEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIQElBREQCESUFMxtgZvPNLN/McsJsb21m483sezObaWZnRD9UERGJtXKTgpmlAM8AA4HOwGAz61yi2p+A4c657sAlwLPRDlRERGIvkiuFnkC+c26Rc24n8A5wTok6DqjnL9cHViAiIlVOJNNcZADLQtYLgF4l6jwAfG5mtwC1gVPC7cjMhgBDAFq3bl3RWEVEBJqYWejEcbnOudxo7Txacx8NBl5zzv3NzI4F3jCzLs65PaGV/MBzwZsQL0rHFhE5mKyN5YR4kXQfLQdahaxn+mWhrgWGAzjnJgHpQJNoBCgiIvETSVKYCrQ3s7ZmloY3kDyyRJ2lQH8AM+uElxTWRDNQERGJvXKTgnOuELgZGAvMxbvLaLaZPWRmZ/vV7gR+b2YzgGHAVS5RL2oQEZH9FtGYgnNuNDC6RNnQkOU5QJ/ohiYiIvGmJ5pFRCSgpCAiIgElBRERCSgpiIhIQElBREQCSgoiIhJQUhARkYCSgoiIBJQUREQkoKQgIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKIiASUFEREJKCkICIiASUFEREJKCmIiEhASUFERAIRJQUzG2Bm880s38xyyqhzsZnNMbPZZvZ2dMMUEZF4qF5eBTNLAZ4BTgUKgKlmNtI5NyekTnvgHqCPc26DmTWLVcAiIhI7kVwp9ATynXOLnHM7gXeAc0rU+T3wjHNuA4BzbnV0wxQRkXiIJClkAMtC1gv8slAdgA5m9q2ZTTazAeF2ZGZDzCzPzPLWrFmzfxGLiBzcmuz9HvV/hkRz5+V2H1VgP+2BfkAm8LWZdXXObQyt5JzLBXIBsrOzXZSOLSJyMFnrnMuO1c4juVJYDrQKWc/0y0IVACOdc7uccz8BC/CShIiIVCGRJIWpQHsza2tmacAlwMgSdT7Cu0rAzJrgdSctil6YIiISD+UmBedcIXAzMBaYCwx3zs02s4fM7Gy/2lhgnZnNAcYDdznn1sUqaBERiQ1zLjFd+9nZ2S4vLy8hxxYRqarMbFqixxREROQgoaQgIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKIiASUFEREJKCkICIiASUFEREJKCmIiEhASUFERAJKCiIiElBSEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIIKKkYGYDzGy+meWbWc4+6l1gZs7MYvZSaRERiZ1yk4KZpQDPAAOBzsBgM+scpl5d4DZgSrSDFBGR+IjkSqEnkO+cW+Sc2wm8A5wTpt6fgUeB7VGMT0RE4iiSpJABLAtZL/DLAmbWA2jlnBsVxdhERCTOqh/oDsysGvB34KoI6g4BhgC0bt36QA8tInIwamJmeSHruc653GjtPJKksBxoFbKe6ZftVRfoAkwwM4DmwEgzO9s5Fxo4fuC5ANnZ2e4A4hYROVitdc7F7GaeSLqPpgLtzaytmaUBlwAj9250zm1yzjVxzrVxzrUBJgOlEoKIiFR+5SYF51whcDMwFpgLDHfOzTazh8zs7FgHKCIi8RPRmIJzbjQwukTZ0DLq9jvwsEREJBH0RLOIiASUFEREJKCkICIiASUFEREJKCmIiEhASUFERAJKCiIiElBSEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIQElBREQCSgoiIhJQUhARkYCSgoiIBJQUREQkoKQgIiIBJQUREQkoKYiISCCipGBmA8xsvpnlm1lOmO13mNkcM5tpZuPM7NDohyoiIrFWblIwsxTgGWAg0BkYbGadS1T7Hsh2zmUBI4DHoh2oiIjEXiRXCj2BfOfcIufcTuAd4JzQCs658c65rf7qZCAzumGKiEg8RJIUMoBlIesFfllZrgU+O5CgREQkMapHc2dmdjmQDZxYxvYhwBCA1q1bR/PQIiIHiyZmlheynuucy43WziNJCsuBViHrmX5ZMWZ2CnAfcKJzbke4HfmB5wJkZ2e7CkcrIiJrnXPZsdp5JN1HU4H2ZtbWzNKAS4CRoRXMrDvwAnC2c2519MMUEZF4KDcpOOcKgZuBscBcYLhzbraZPWRmZ/vVHgfqAO+Z2XQzG1nG7kREpBKLaEzBOTcaGF2ibGjI8ilRjktERBJATzSLiEhASUFERAJKCiIiElBSEBGRgJKCiIgElBRERCSgpCAiIgElBRERCSgpiIhIQElBREQCSgoiIhJQUhARkYCSgoiIBJQUREQkoKQgIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKIiAQiSgpmNsDM5ptZvpnlhNlew8ze9bdPMbM2UY9URERirtykYGYpwDPAQKAzMNjMOpeodi2wwTl3OPAE8Gi0AxURkdiL5EqhJ5DvnFvknNsJvAOcU6LOOcC//OURQH8zs+iFKSIi8RBJUsgAloWsF/hlYes45wqBTUDjaAQoIiLxUz2eBzOzIcAQf3WHmc2K5/HjrAmwNtFBxEgytw2Su33J3DZI7vbtbVtHM8sLKc91zuVG6yCRJIXlQKuQ9Uy/LFydAjOrDtQH1pXckR94LoCZ5Tnnsvcn6KogmduXzG2D5G5fMrcNkrt98WpbJN1HU4H2ZtbWzNKAS4CRJeqMBK70ly8EvnTOueiFKSIi8VDulYJzrtDMbgbGAinAK8652Wb2EJDnnBsJvAy8YWb5wHq8xCEiIlVMRGMKzrnRwOgSZUNDlrcDF1Xw2FHrA6ukkrl9ydw2SO72JXPbILnbF5e2mXp5RERkL01zISIigYQkhfKmzagszKyVmY03szlmNtvMbvPLG5nZv81sof9nQ7/czOwpv10zzaxHyL6u9OsvNLMrQ8qPNrMf/M88Fe+H/swsxcy+N7NP/fW2/lQl+f7UJWl+eZlTmZjZPX75fDM7PaQ8oefZzBqY2Qgzm2dmc83s2GQ5d2b2B/93cpaZDTOz9Kp87szsFTNbHXqbejzOVVnHiEPbHvd/L2ea2Ydm1iBkW4XOyf6c931yzsX1B2+w+kegHZAGzAA6xzuOCGNtAfTwl+sCC/Cm+ngMyPHLc4BH/eUzgM8AA3oDU/zyRsAi/8+G/nJDf9t3fl3zPzswzm28A3gb+NRfHw5c4i8/D9zgL98IPO8vXwK86y939s9hDaCtf25TKsN5xnvK/nf+chrQIBnOHd7Doj8BNUPO2VVV+dwBJwA9gFkhZTE/V2UdIw5tOw2o7i8/GtK2Cp+Tip73cuONxy9xib+gY4GxIev3APfEO479jP1j4FRgPtDCL2sBzPeXXwAGh9Sf728fDLwQUv6CX9YCmBdSXqxeHNqTCYwDTgY+9f/BrA35ZQ3OFd7dZ8f6y9X9elby/O2tl+jzjPeszE/442Ylz0lVPncUzSDQyD8XnwKnV/VzB7Sh+BdnzM9VWceIddtKbDsPeCvc33V552R//s2WF2siuo8imTaj0vEvvboDU4BDnHM/+5tWAof4y2W1bV/lBWHK4+VJ4I/AHn+9MbDReVOVlIynrKlMKtrmeGkLrAFeNa977CUzq00SnDvn3HLg/4ClwM9452IayXPu9orHuSrrGPF0Dd7VC1S8bfvzb3afNNAcATOrA7wP3O6c+yV0m/PScJW7hcvMzgJWO+emJTqWGKmOd8n+nHOuO/ArXvdAoAqfu4Z4k1C2BVoCtYEBCQ0qxuJxrhLx+2Bm9wGFwFvxPO6+JCIpRDJtRqVhZql4CeEt59wHfvEqM2vhb28BrPbLy2rbvsozw5THQx/gbDNbjDfz7cnAP4AG5k1VUjKeoA1WfCqTirY5XgqAAufcFH99BF6SSIZzdwrwk3NujXNuF/AB3vlMlnO3VzzOVVnHiDkzuwo4C7jMT0hQ8bato+Lnfd9i3U8Ypv+sOt4AUFuKBkyOjHccEcZqwOvAkyXKH6f44NRj/vKZFB8A+84vb4TXv93Q//kJaORvKzkAdkYC2tmPooHm9yg+aHWjv3wTxQethvvLR1J8YGwR3qBYws8z8B+go7/8gH/eqvy5A3oBs4Fa/rH/BdxS1c8dpccUYn6uyjpGHNo2AJgDNC1Rr8LnpKLnvdxY4/FLHOYv6Ay8O3l+BO5LRAwRxtkX73JyJjDd/zkDr19uHLAQ+CLkF8/wXkj0I/ADkB2yr2uAfP/n6pDybGCW/5mniWAgKAbt7EdRUmjn/wPK93/Zavjl6f56vr+9Xcjn7/Pjn0/IHTiJPs9ANyDPP38f+V8USXHugAeBef7x3/C/RKrsuQOG4Y2P7MK7yrs2HueqrGPEoW35eP390/2f5/f3nOzPed/Xj55oFhGRgAaaRUQkoKQgIiIBJQUREQkoKYiISEBJQUREAkoKIiISUFIQEZGAkoKIiAT+PwrSO73TMYFeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(epochs=110, lr=1e-6)\n",
    "learner.save(os.path.join(ROOT_PATH, 'results_' + datetime.now().strftime(\"%y%m%d%H%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()\n",
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "F7xjC8rrGWZK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠWhen Ġit Ġ' s Ġnot Ġwall owing Ġin Ġhormonal Ġmel od rama Ġ, Ġ`` ĠReal ĠWomen ĠHave ĠCur ves Ġ'' Ġis Ġa Ġsweet Ġ, Ġhonest Ġ, Ġand Ġenjoyable Ġcomedy - d rama Ġabout Ġa Ġyoung Ġwoman Ġwho Ġwants Ġmany Ġthings Ġin Ġlife Ġ, Ġbut Ġfears Ġshe Ġ' ll Ġbecome Ġher Ġmother Ġbefore Ġshe Ġgets Ġto Ġfulfill Ġher Ġdreams Ġ. &lt;/s&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠChristian ĠBale Ġ' s ĠQuinn Ġ- L RB - Ġis Ġ- RR B - Ġa Ġleather Ġclad Ġgrun ge - pir ate Ġwith Ġa Ġha ird o Ġlike ĠGand alf Ġin Ġa Ġwind - tun nel Ġand Ġa Ġsimply Ġastounding Ġcor - bl ime y - lu v - a - du ck Ġcock ney Ġaccent Ġ. Ġ' &lt;/s&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠThe Ġfilm Ġwas Ġproduced Ġby ĠJerry ĠBru ck heimer Ġand Ġdirected Ġby ĠJoel ĠSch um acher Ġ, Ġand Ġreflects Ġthe Ġworst Ġof Ġtheir Ġshallow Ġstyles Ġ: Ġwildly Ġover produced Ġ, Ġinadequ ately Ġmotivated Ġevery Ġstep Ġof Ġthe Ġway Ġand Ġdem ographically Ġtargeted Ġto Ġplease Ġevery Ġone Ġ- L RB - Ġand Ġno Ġone Ġ- RR B - Ġ. &lt;/s&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġworks Ġbecause Ġits Ġfl ab berg asting Ġprincipals Ġ, Ġ14 - year - old ĠRobert ĠMac N augh ton Ġ, Ġ6 - year - old ĠDrew ĠBarry more Ġand Ġ10 - year - old ĠHenry ĠThomas Ġ, Ġconvince Ġus Ġof Ġthe Ġexistence Ġof Ġthe Ġwise Ġ, Ġw iz ened Ġvisitor Ġfrom Ġa Ġfar away Ġplanet Ġ. &lt;/s&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠAngela ĠG he or gh iu Ġas Ġfamous Ġprim a Ġdon na ĠFlor ia ĠTos ca Ġ, ĠRoberto ĠAl agna Ġas Ġher Ġlover ĠMario ĠCav ar ad oss i Ġ, Ġand ĠRug ger o Ġas Ġthe Ġvillain ous Ġ, Ġle cher ous Ġpolice Ġchief ĠSc arp ia Ġ, Ġall Ġsing Ġbeautifully Ġand Ġact Ġadequately Ġ. &lt;/s&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHQy4layD63X"
   },
   "source": [
    "#### Export Learner (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "1OTgPawjDrVp"
   },
   "outputs": [],
   "source": [
    "# learner.export(model_name)\n",
    "# !mv ./export.pkl /content/drive/My\\ Drive/LAB/kge_sentiment_analysis\n",
    "# !mv /content/drive/My\\ Drive/LAB/kge_sentiment_analysis/export.pkl /content/drive/My\\ Drive/LAB/bsz2048_DEM-RoBERTa.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "vQvEKBH_Eq7V"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/My Drive/LAB/'\n",
    "# export_learner = load_learner(path, file = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "PMQr88C2FAO0"
   },
   "outputs": [],
   "source": [
    "# export_learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txW64dH8FPkI"
   },
   "source": [
    "#### Creating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "CL7otQdLFRUX"
   },
   "outputs": [],
   "source": [
    "# def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "#     preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "#     sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "#     reverse_sampler = np.argsort(sampler)\n",
    "#     return preds[reverse_sampler, :]\n",
    "\n",
    "# test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "2dP6IBczGZRD"
   },
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv(DATA_ROOT / 'sampleSubmission.csv')\n",
    "# sample_submission['Sentiment'] = np.argmax(test_preds, axis = 1)\n",
    "# sample_submission.to_csv('prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "EBkUrEZpG13m"
   },
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "IFGWNvhPG39j"
   },
   "outputs": [],
   "source": [
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "0CfueTuqG6v0"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# def create_download_link(title = 'Download CSV file', filename = 'data.csv'):\n",
    "#     html = '<a href=(filename)->(title)</a>'\n",
    "#     html = html.format(title=title, filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# create_download_link(filename='prediciton.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "10ceIJFxiecuBcRtznBcInn3Q8OBPR-rG",
     "timestamp": 1659685428876
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016e9d4951dc4ffaa116b68651b5a5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82ac39008291438abe8a0cdec6d0b48e",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f0efcec51584512801c27a3cd6955c1",
      "value": 456318
     }
    },
    "0d1764eea96f42b59b0613a32675d84c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea8af2f6e8c44a7ab9457f15c6c13ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_4f06c58c7d7f4db499237ce58193f37c",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "10c337408ee34116ab68750ca4016873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "132793e6053c41a5a775a7b4d3dc190c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_870b2aaafdab485c9c84d37ca50e3751",
       "IPY_MODEL_18192a8ad1094e05bb8679cdc82b0015",
       "IPY_MODEL_19dd2d607cc7428093d7974a3dc630c5"
      ],
      "layout": "IPY_MODEL_7628994d5e6f4802a9a7edb25a3d3da9"
     }
    },
    "18192a8ad1094e05bb8679cdc82b0015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4931528732d14b7da8a4bc12fc66acd3",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_800850935d4d4d41973e053ff7e9be7d",
      "value": 482
     }
    },
    "19dd2d607cc7428093d7974a3dc630c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65077ad08d2a4d869053cf49875ac04c",
      "placeholder": "​",
      "style": "IPY_MODEL_1f23acd2e5414a2493bc041d17d35d65",
      "value": " 482/482 [00:00&lt;00:00, 20.6kB/s]"
     }
    },
    "1f23acd2e5414a2493bc041d17d35d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff839855735448bafa7c923e3c82058": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20be103a8b6e4c05a5dc25015cfd358d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ba466b3677542d290e5edc913bbf915",
      "placeholder": "​",
      "style": "IPY_MODEL_918d275243764415b4aacd122ede250c",
      "value": " 1.43G/1.43G [00:05&lt;00:00, 257MB/s]"
     }
    },
    "28c07e0b489a4929926d1002df24b091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef60fa55102d4902b9ddbcc45b6090ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8532ee00cdbe476796eaec8355396cea",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "332a2f4786154442b5296395129c2e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28c07e0b489a4929926d1002df24b091",
       "IPY_MODEL_016e9d4951dc4ffaa116b68651b5a5e9",
       "IPY_MODEL_38edf987d8fc4ce58ec72c4ed0e4ed67"
      ],
      "layout": "IPY_MODEL_c12a0a03c11641d996cedcb2554837e7"
     }
    },
    "38edf987d8fc4ce58ec72c4ed0e4ed67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ff839855735448bafa7c923e3c82058",
      "placeholder": "​",
      "style": "IPY_MODEL_c99275e215d44398809e6d5accd8f6b4",
      "value": " 456k/456k [00:00&lt;00:00, 3.75MB/s]"
     }
    },
    "3d59f5ebbe854243b3543b89c3e55c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42032dc8a67d4f6cae837fd6c381fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_844024c43a194e08a1951bdb90c3d20a",
       "IPY_MODEL_9114752678be4ec2a52116ac2c4ac632",
       "IPY_MODEL_20be103a8b6e4c05a5dc25015cfd358d"
      ],
      "layout": "IPY_MODEL_591a0f885fa94b4aba32a13f567864a2"
     }
    },
    "4931528732d14b7da8a4bc12fc66acd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f06c58c7d7f4db499237ce58193f37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "591a0f885fa94b4aba32a13f567864a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba466b3677542d290e5edc913bbf915": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e4d7c27ceab4bf5bd780770c6b829fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f0efcec51584512801c27a3cd6955c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "633267e43eba4060bebdc1d043c0f155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65077ad08d2a4d869053cf49875ac04c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66ab18b60f5e4294b4309d3fd293e7a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7628994d5e6f4802a9a7edb25a3d3da9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f018262d1a047109366e216f9e83e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "800850935d4d4d41973e053ff7e9be7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82ac39008291438abe8a0cdec6d0b48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844024c43a194e08a1951bdb90c3d20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96e86f098f5f442ea05e1aed9309bb2f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d59f5ebbe854243b3543b89c3e55c50",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "8532ee00cdbe476796eaec8355396cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "870b2aaafdab485c9c84d37ca50e3751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66ab18b60f5e4294b4309d3fd293e7a4",
      "placeholder": "​",
      "style": "IPY_MODEL_c5dfa7b8af9448b1b4cb3b10812a9102",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "9114752678be4ec2a52116ac2c4ac632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2a72c584dca4d618ebfb185cc23b9fc",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_633267e43eba4060bebdc1d043c0f155",
      "value": 1425941629
     }
    },
    "918d275243764415b4aacd122ede250c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96e86f098f5f442ea05e1aed9309bb2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f9ee57980f64607aed63201e44d2263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d1764eea96f42b59b0613a32675d84c",
       "IPY_MODEL_af7c57c570614472b160423724a07590",
       "IPY_MODEL_e388830b59ba4f9d837ea6cdb9c698e7"
      ],
      "layout": "IPY_MODEL_a46848278e9a45bdbf87f4513a5da72a"
     }
    },
    "a46848278e9a45bdbf87f4513a5da72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7c57c570614472b160423724a07590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d14ec50a29224593a87a902c5a23d581",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f018262d1a047109366e216f9e83e64",
      "value": 898823
     }
    },
    "c12a0a03c11641d996cedcb2554837e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5dfa7b8af9448b1b4cb3b10812a9102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c99275e215d44398809e6d5accd8f6b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d14ec50a29224593a87a902c5a23d581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2a72c584dca4d618ebfb185cc23b9fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e388830b59ba4f9d837ea6cdb9c698e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e4d7c27ceab4bf5bd780770c6b829fb",
      "placeholder": "​",
      "style": "IPY_MODEL_10c337408ee34116ab68750ca4016873",
      "value": " 899k/899k [00:00&lt;00:00, 3.27MB/s]"
     }
    },
    "ea8af2f6e8c44a7ab9457f15c6c13ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef60fa55102d4902b9ddbcc45b6090ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
