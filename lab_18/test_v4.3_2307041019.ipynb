{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizerFast, AdamW\n",
    "# import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.backends.cudnn as cudnn\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paths & arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "# DATA_PATH = os.path.join(ROOT_PATH, 'finetune_dataset/kge_sentiment_analysis')\n",
    "DATA_PATH = os.path.join(ROOT_PATH, '../../research_datasets/finetune_dataset/kge_sentiment_analysis')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'SST5'\n",
    "# DATASET = 'SST2'\n",
    "\n",
    "BSZ = 64\n",
    "EPOCH = 400\n",
    "LR = 1e-6\n",
    "\n",
    "KOKONOMODEL = 'boomberta'\n",
    "# KOKONOMODEL = 'roberta'\n",
    "\n",
    "KOKONOTEST = '_D_' + DATASET + '_M_' + KOKONOMODEL + '_B_' + str(BSZ) + '_E_' + str(EPOCH) + '_LR_' + str(LR)\n",
    "print(KOKONOTEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-large'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some function for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encodings_df_tokensaru(encodings, idx):\n",
    "    ids, tokens, attention_mask = [], [], []\n",
    "    i = 0\n",
    "\n",
    "    for get_ids in encodings[idx].ids:\n",
    "        ids += [get_ids]\n",
    "        \n",
    "    for get_tokens in encodings[idx].tokens:\n",
    "        tokens += [get_tokens.replace('Ä ', '')]\n",
    "\n",
    "    for get_attention_mask in encodings[idx].attention_mask:\n",
    "        attention_mask += [get_attention_mask]\n",
    "        i = i+1\n",
    "\n",
    "    show_tokens_DF = pd.DataFrame({'ids': ids, 'tokens': tokens, 'attention_mask': attention_mask})\n",
    "    print('got ' + str(i))\n",
    "    return show_tokens_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_tokens_DF = get_encodings_df_tokensaru(test_encodings, 99)\n",
    "# show_tokens_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encodings_df(encodings, idx):\n",
    "    input_ids, attention_mask = [], []\n",
    "    i = 0\n",
    "\n",
    "    for get_input_ids in encodings['input_ids'][idx]:\n",
    "        input_ids += [get_input_ids]\n",
    "\n",
    "    for get_attention_mask in encodings['attention_mask'][idx]:\n",
    "        attention_mask += [get_attention_mask]\n",
    "        i = i+1\n",
    "\n",
    "    show_tokens_DF = pd.DataFrame({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "    print('got ' + str(i))\n",
    "    return show_tokens_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_tokens_DF = get_encodings_df(test_encodings, 99)\n",
    "# show_tokens_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            total_params += param.numel()\n",
    "    print(f\"Total Trainable Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_model_summary(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the SST-5 dataset\n",
    "dataset = pd.read_csv(DATA_PATH + '/train.tsv.zip', sep=\"\\t\")\n",
    "train, valid = train_test_split(dataset, random_state=42, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_dataset(dataset):\n",
    "    encodings = tokenizer(dataset['Phrase'].tolist(), truncation=True, padding=True)\n",
    "    labels = dataset['Sentiment'].tolist()\n",
    "    return encodings, labels\n",
    "\n",
    "train_encodings, train_labels = tokenize_dataset(train)\n",
    "valid_encodings, valid_labels = tokenize_dataset(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch dataset\n",
    "class TsvDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item = {}\n",
    "        item['input_ids'] = torch.tensor(self.encodings['input_ids'][idx])\n",
    "        item['attention_mask'] = torch.tensor(self.encodings['attention_mask'][idx])\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TsvDataset(train_encodings, train_labels)\n",
    "valid_dataset = TsvDataset(valid_encodings, valid_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BSZ, shuffle=True, drop_last=True, generator=torch.Generator(device='cuda'))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=True, drop_last=True, generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boomberta import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "# from ...activations import ACT2FN, gelu\n",
    "from transformers.activations import ACT2FN, gelu\n",
    "# from ...modeling_outputs import (\n",
    "#     BaseModelOutputWithPastAndCrossAttentions,\n",
    "#     BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "#     CausalLMOutputWithCrossAttentions,\n",
    "#     MaskedLMOutput,\n",
    "#     MultipleChoiceModelOutput,\n",
    "#     QuestionAnsweringModelOutput,\n",
    "#     SequenceClassifierOutput,\n",
    "#     TokenClassifierOutput,\n",
    "# )\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "# from ...modeling_utils import PreTrainedModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "# from ...pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "# from ...utils import (\n",
    "#     add_code_sample_docstrings,\n",
    "#     add_start_docstrings,\n",
    "#     add_start_docstrings_to_model_forward,\n",
    "#     logging,\n",
    "#     replace_return_docstrings,\n",
    "# )\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "# from .configuration_roberta import RobertaConfig\n",
    "from transformers.models.roberta.configuration_roberta import RobertaConfig\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"roberta-base\"\n",
    "_CONFIG_FOR_DOC = \"RobertaConfig\"\n",
    "\n",
    "ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"roberta-base\",\n",
    "    \"roberta-large\",\n",
    "    \"roberta-large-mnli\",\n",
    "    \"distilroberta-base\",\n",
    "    \"roberta-base-openai-detector\",\n",
    "    \"roberta-large-openai-detector\",\n",
    "    # See all RoBERTa models at https://huggingface.co/models?filter=roberta\n",
    "]\n",
    "\n",
    "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\n",
    "\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            This parameter can only be used when the model is initialized with `type_vocab_size` parameter with value\n",
    "            >= 2. All the value in this tensor should be always < type_vocab_size.\n",
    "\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaAttention, \n",
    "    RobertaPreTrainedModel, \n",
    "    RobertaPooler, \n",
    "    RobertaEmbeddings, \n",
    "    RobertaClassificationHead\n",
    "    )\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boom_crop(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int) -> None:\n",
    "        super(Boom_crop, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        ninp = self.out_features\n",
    "        output = torch.narrow(input, -1, 0, input.shape[-1] // ninp * ninp)\n",
    "        output = output.view(*output.shape[:-1], output.shape[-1] // ninp, ninp)\n",
    "        output = output.sum(dim=-2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boom_Layer(nn.Module):\n",
    "    def __init__(self, in_features: int, mid_features: int, dropout=0.1) -> None:\n",
    "        super(Boom_Layer, self).__init__()\n",
    "\n",
    "        self.boom_crop = Boom_crop(in_features, mid_features)\n",
    "\n",
    "        self.up_linear = nn.Linear(mid_features, in_features)\n",
    "        self.act = GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "\n",
    "        output = self.boom_crop(input)\n",
    "        output = self.up_linear(output)\n",
    "        output += input\n",
    "        output = self.act(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaIntermediateAndBoom(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # self.dense_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        # if isinstance(config.hidden_act, str):\n",
    "        #     self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        # else:\n",
    "        #     self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "        # self.dense_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "\n",
    "        self.boom = Boom_Layer(config.hidden_size, config.intermediate_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        # hidden_states = self.dense_1(input_tensor)\n",
    "        # hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "\n",
    "        # hidden_states = self.dense_2(hidden_states)\n",
    "\n",
    "        hidden_states = self.boom(input_tensor)\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = RobertaAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        self.add_cross_attention = config.add_cross_attention\n",
    "        if self.add_cross_attention:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
    "            self.crossattention = RobertaAttention(config, position_embedding_type=\"absolute\")\n",
    "        # self.intermediate = RobertaIntermediate(config)#####\n",
    "        # self.output = RobertaOutput(config)#####\n",
    "        \n",
    "        self.intermediateandboom = RobertaIntermediateAndBoom(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "\n",
    "        # if decoder, the last output is tuple of self-attn cache\n",
    "        if self.is_decoder:\n",
    "            outputs = self_attention_outputs[1:-1]\n",
    "            present_key_value = self_attention_outputs[-1]\n",
    "        else:\n",
    "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        cross_attn_present_key_value = None\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"\n",
    "                    \" by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "\n",
    "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
    "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output,\n",
    "                attention_mask,\n",
    "                head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                cross_attn_past_key_value,\n",
    "                output_attentions,\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
    "\n",
    "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
    "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
    "            present_key_value = present_key_value + cross_attn_present_key_value\n",
    "\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "        # if decoder, return the attn key/values as the last output\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (present_key_value,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        # print(attention_output.shape)\n",
    "        # intermediate_output = self.intermediate(attention_output)\n",
    "        # print(intermediate_output.shape)\n",
    "        # layer_output = self.output(intermediate_output, attention_output)\n",
    "        # print(layer_output.shape)\n",
    "\n",
    "        layer_output = self.intermediateandboom(attention_output)\n",
    "\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([ModifiedRobertaLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "        next_decoder_cache = () if use_cache else None\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                if use_cache:\n",
    "                    logger.warning(\n",
    "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                    )\n",
    "                    use_cache = False\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    past_key_value,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache += (layer_outputs[-1],)\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    next_decoder_cache,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_decoder_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaModel(RobertaPreTrainedModel):\n",
    "    \"\"\"\n",
    "\n",
    "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
    "    cross-attention is added between the self-attention layers, following the architecture described in *Attention is\n",
    "    all you need*_ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\n",
    "    Kaiser and Illia Polosukhin.\n",
    "\n",
    "    To behave as an decoder the model needs to be initialized with the `is_decoder` argument of the configuration set\n",
    "    to `True`. To be used in a Seq2Seq model, the model needs to initialized with both `is_decoder` argument and\n",
    "    `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n",
    "\n",
    "    .. _*Attention is all you need*: https://arxiv.org/abs/1706.03762\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.__init__ with Bert->Roberta\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = RobertaEmbeddings(config)\n",
    "        self.encoder = ModifiedRobertaEncoder(config)\n",
    "\n",
    "        self.pooler = RobertaPooler(config) if add_pooling_layer else None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertModel.forward\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if self.config.is_decoder:\n",
    "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        else:\n",
    "            use_cache = False\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # past_key_values_length\n",
    "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            past_key_values_length=past_key_values_length,\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values=encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedRobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.roberta = ModifiedRobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=\"'optimism'\",\n",
    "        expected_loss=0.08,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KOKONOMODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if KOKONOMODEL == 'roberta':\n",
    "    model = RobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
    "elif KOKONOMODEL == 'boomberta':\n",
    "    model = ModifiedRobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.roberta.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for i in range(len(model.roberta.encoder.layer)):\n",
    "    for param in model.roberta.encoder.layer[i].attention.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_summary(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model, train_loader, valid_loader, num_epochs, lr, device=torch.device(\"cuda:0\")):\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        cudnn.benchmark = True\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"valid\"]\n",
    "\n",
    "        self.device = device\n",
    "        self.dataloaders = {self.phases[0]: train_loader, self.phases[1]: valid_loader}\n",
    "    \n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        # self.accumulation_steps = 32 // self.dataloaders['train'].batch_size\n",
    "        \n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "        # self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        \n",
    "        self.losses =   {phase: [] for phase in self.phases}\n",
    "        self.accuracy = {phase: [] for phase in self.phases}\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        running_losses = []\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        nowtime = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"[{nowtime}] type: {phase} epoch: {epoch}\")\n",
    "\n",
    "        if phase == \"train\":\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        # total_batches = len(dataloader)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        pbar = tqdm(dataloader, total=len(dataloader), position=0, leave=True, desc=f\"Epoch {epoch}\")\n",
    "        for itr, batch in enumerate(pbar):\n",
    "            batch = {key: value.to(self.device) for key, value in batch.items()}\n",
    "            outputs = self.model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            # loss = loss / self.accumulation_steps\n",
    "            # if phase == \"train\":\n",
    "            #     loss.backward()\n",
    "            #     if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "            #         self.optimizer.step()\n",
    "            #         self.optimizer.zero_grad()\n",
    "\n",
    "            running_losses += [loss.item()]\n",
    "\n",
    "            _, predictions = outputs['logits'].max(1)\n",
    "            label = batch['labels']\n",
    "            num_correct += (predictions == label).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        # epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        epoch_loss = sum(running_losses) / len(running_losses)\n",
    "        epoch_accuracy = (num_correct/num_samples).item()\n",
    "        \n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.accuracy[phase].append(epoch_accuracy)\n",
    "\n",
    "        print(\"loss: %0.4f | accuracy: %0.4f\" % (epoch_loss, epoch_accuracy))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.model.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                'model': model,\n",
    "            }\n",
    "\n",
    "            valid_loss = self.iterate(epoch, \"valid\")\n",
    "            # self.scheduler.step(valid_loss)\n",
    "            if valid_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = valid_loss\n",
    "                nowtime = datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "                torch.save(state, \"./\" + nowtime + '_loss_' + valid_loss + KOKONOTEST + \".pth\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "Epoch 0:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:09] type: train epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|ââââââââââ| 2194/2194 [23:12<00:00,  1.58it/s]\n",
      "Epoch 0:   0%|          | 2/975 [00:00<01:26, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0665\n",
      "[10:39:22] type: valid epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.12it/s]\n",
      "Epoch 1:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[10:40:08] type: train epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|ââââââââââ| 2194/2194 [23:25<00:00,  1.56it/s]\n",
      "Epoch 1:   0%|          | 2/975 [00:00<01:15, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0664\n",
      "[11:03:34] type: valid epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.16it/s]\n",
      "Epoch 2:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[11:04:20] type: train epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|ââââââââââ| 2194/2194 [23:24<00:00,  1.56it/s]\n",
      "Epoch 2:   0%|          | 2/975 [00:00<01:23, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0661\n",
      "[11:27:45] type: valid epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.18it/s]\n",
      "Epoch 3:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[11:28:31] type: train epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|ââââââââââ| 2194/2194 [23:23<00:00,  1.56it/s]\n",
      "Epoch 3:   0%|          | 2/975 [00:00<01:14, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0669\n",
      "[11:51:55] type: valid epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.17it/s]\n",
      "Epoch 4:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[11:52:41] type: train epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|ââââââââââ| 2194/2194 [23:26<00:00,  1.56it/s]\n",
      "Epoch 4:   0%|          | 2/975 [00:00<01:14, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0664\n",
      "[12:16:07] type: valid epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.09it/s]\n",
      "Epoch 5:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[12:16:53] type: train epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|ââââââââââ| 2194/2194 [23:23<00:00,  1.56it/s]\n",
      "Epoch 5:   0%|          | 1/975 [00:00<01:53,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0660\n",
      "[12:40:18] type: valid epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.11it/s]\n",
      "Epoch 6:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[12:41:04] type: train epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|ââââââââââ| 2194/2194 [23:19<00:00,  1.57it/s]\n",
      "Epoch 6:   0%|          | 1/975 [00:00<01:38,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0660\n",
      "[13:04:24] type: valid epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.13it/s]\n",
      "Epoch 7:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0621\n",
      "\n",
      "[13:05:10] type: train epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|ââââââââââ| 2194/2194 [23:20<00:00,  1.57it/s]\n",
      "Epoch 7:   0%|          | 1/975 [00:00<01:40,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0667\n",
      "[13:28:31] type: valid epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|ââââââââââ| 975/975 [00:45<00:00, 21.21it/s]\n",
      "Epoch 8:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[13:29:17] type: train epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n",
      "Epoch 8:   0%|          | 2/975 [00:00<01:18, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0666\n",
      "[13:52:39] type: valid epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.10it/s]\n",
      "Epoch 9:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[13:53:25] type: train epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|ââââââââââ| 2194/2194 [23:24<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 2/975 [00:00<01:16, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:50] type: valid epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.19it/s]\n",
      "Epoch 10:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[14:17:36] type: train epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|ââââââââââ| 2194/2194 [23:23<00:00,  1.56it/s]\n",
      "Epoch 10:   0%|          | 2/975 [00:00<01:13, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0660\n",
      "[14:40:59] type: valid epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.18it/s]\n",
      "Epoch 11:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[14:41:45] type: train epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%|          | 2/975 [00:00<01:15, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:08] type: valid epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.08it/s]\n",
      "Epoch 12:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[15:05:55] type: train epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|ââââââââââ| 2194/2194 [23:24<00:00,  1.56it/s]\n",
      "Epoch 12:   0%|          | 2/975 [00:00<01:16, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0661\n",
      "[15:29:19] type: valid epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.15it/s]\n",
      "Epoch 13:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[15:30:06] type: train epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n",
      "Epoch 13:   0%|          | 2/975 [00:00<01:12, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0663\n",
      "[15:53:29] type: valid epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.10it/s]\n",
      "Epoch 14:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[15:54:15] type: train epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|ââââââââââ| 2194/2194 [23:23<00:00,  1.56it/s]\n",
      "Epoch 14:   0%|          | 2/975 [00:00<01:24, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0666\n",
      "[16:17:39] type: valid epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.15it/s]\n",
      "Epoch 15:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[16:18:25] type: train epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|ââââââââââ| 2194/2194 [23:25<00:00,  1.56it/s]\n",
      "Epoch 15:   0%|          | 2/975 [00:00<01:25, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0664\n",
      "[16:41:51] type: valid epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.08it/s]\n",
      "Epoch 16:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[16:42:37] type: train epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|ââââââââââ| 2194/2194 [23:28<00:00,  1.56it/s]\n",
      "Epoch 16:   0%|          | 2/975 [00:00<01:27, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0671\n",
      "[17:06:06] type: valid epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.01it/s]\n",
      "Epoch 17:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[17:06:52] type: train epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|ââââââââââ| 2194/2194 [23:26<00:00,  1.56it/s]\n",
      "Epoch 17:   0%|          | 2/975 [00:00<01:19, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0659\n",
      "[17:30:19] type: valid epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.09it/s]\n",
      "Epoch 18:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[17:31:05] type: train epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|ââââââââââ| 2194/2194 [23:24<00:00,  1.56it/s]\n",
      "Epoch 18:   0%|          | 1/975 [00:00<01:53,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0669\n",
      "[17:54:30] type: valid epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.13it/s]\n",
      "Epoch 19:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[17:55:16] type: train epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|ââââââââââ| 2194/2194 [23:21<00:00,  1.56it/s]\n",
      "Epoch 19:   0%|          | 2/975 [00:00<01:17, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0665\n",
      "[18:18:39] type: valid epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|ââââââââââ| 975/975 [00:46<00:00, 20.98it/s]\n",
      "Epoch 20:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[18:19:25] type: train epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|ââââââââââ| 2194/2194 [23:19<00:00,  1.57it/s]\n",
      "Epoch 20:   0%|          | 2/975 [00:00<01:12, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0669\n",
      "[18:42:45] type: valid epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|ââââââââââ| 975/975 [00:45<00:00, 21.20it/s]\n",
      "Epoch 21:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[18:43:32] type: train epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|ââââââââââ| 2194/2194 [23:20<00:00,  1.57it/s]\n",
      "Epoch 21:   0%|          | 2/975 [00:00<01:14, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0663\n",
      "[19:06:52] type: valid epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.13it/s]\n",
      "Epoch 22:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[19:07:39] type: train epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|ââââââââââ| 2194/2194 [23:19<00:00,  1.57it/s]\n",
      "Epoch 22:   0%|          | 1/975 [00:00<01:38,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0666\n",
      "[19:30:58] type: valid epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.13it/s]\n",
      "Epoch 23:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[19:31:44] type: train epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|ââââââââââ| 2194/2194 [23:20<00:00,  1.57it/s]\n",
      "Epoch 23:   0%|          | 2/975 [00:00<01:25, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0664\n",
      "[19:55:04] type: valid epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.10it/s]\n",
      "Epoch 24:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[19:55:51] type: train epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|ââââââââââ| 2194/2194 [23:23<00:00,  1.56it/s]\n",
      "Epoch 24:   0%|          | 2/975 [00:00<01:19, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0658\n",
      "[20:19:14] type: valid epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.03it/s]\n",
      "Epoch 25:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[20:20:00] type: train epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|ââââââââââ| 2194/2194 [23:23<00:00,  1.56it/s]\n",
      "Epoch 25:   0%|          | 2/975 [00:00<01:22, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0674\n",
      "[20:43:25] type: valid epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.01it/s]\n",
      "Epoch 26:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[20:44:11] type: train epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|ââââââââââ| 2194/2194 [23:24<00:00,  1.56it/s]\n",
      "Epoch 26:   0%|          | 2/975 [00:00<01:09, 13.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0663\n",
      "[21:07:35] type: valid epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.17it/s]\n",
      "Epoch 27:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[21:08:21] type: train epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|ââââââââââ| 2194/2194 [23:20<00:00,  1.57it/s]\n",
      "Epoch 27:   0%|          | 2/975 [00:00<01:21, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0667\n",
      "[21:31:42] type: valid epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.10it/s]\n",
      "Epoch 28:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[21:32:28] type: train epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|ââââââââââ| 2194/2194 [23:20<00:00,  1.57it/s]\n",
      "Epoch 28:   0%|          | 2/975 [00:00<01:10, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0666\n",
      "[21:55:49] type: valid epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.13it/s]\n",
      "Epoch 29:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[21:56:35] type: train epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|ââââââââââ| 2194/2194 [23:21<00:00,  1.57it/s]\n",
      "Epoch 29:   0%|          | 2/975 [00:00<01:18, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0674\n",
      "[22:19:57] type: valid epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.09it/s]\n",
      "Epoch 30:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[22:20:43] type: train epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n",
      "Epoch 30:   0%|          | 2/975 [00:00<01:23, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0671\n",
      "[22:44:06] type: valid epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.13it/s]\n",
      "Epoch 31:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[22:44:52] type: train epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31:   0%|          | 2/975 [00:00<01:21, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:14] type: valid epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.02it/s]\n",
      "Epoch 32:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[23:09:01] type: train epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n",
      "Epoch 32:   0%|          | 2/975 [00:00<01:13, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0660\n",
      "[23:32:23] type: valid epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.15it/s]\n",
      "Epoch 33:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[23:33:09] type: train epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n",
      "Epoch 33:   0%|          | 2/975 [00:00<01:14, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0668\n",
      "[23:56:32] type: valid epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.17it/s]\n",
      "Epoch 34:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[23:57:18] type: train epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|ââââââââââ| 2194/2194 [23:22<00:00,  1.56it/s]\n",
      "Epoch 34:   0%|          | 2/975 [00:00<01:21, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0666\n",
      "[00:20:41] type: valid epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.08it/s]\n",
      "Epoch 35:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[00:21:27] type: train epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|ââââââââââ| 2194/2194 [23:18<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35:   0%|          | 2/975 [00:00<01:19, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:44:46] type: valid epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.12it/s]\n",
      "Epoch 36:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[00:45:32] type: train epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|ââââââââââ| 2194/2194 [23:19<00:00,  1.57it/s]\n",
      "Epoch 36:   0%|          | 2/975 [00:00<01:18, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0659\n",
      "[01:08:52] type: valid epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|ââââââââââ| 975/975 [00:46<00:00, 21.06it/s]\n",
      "Epoch 37:   0%|          | 0/2194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: nan | accuracy: 0.0622\n",
      "\n",
      "[01:09:39] type: train epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37:  14%|ââ        | 311/2194 [03:18<20:05,  1.56it/s]"
     ]
    }
   ],
   "source": [
    "model_trainer = Trainer(model, train_loader, valid_loader, EPOCH, LR, device)\n",
    "model_trainer.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model_trainer.losses\n",
    "accuracy = model_trainer.accuracy\n",
    "\n",
    "def plot(scores, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"valid\"], label=f'valid {name}')\n",
    "    plt.title(f'{name} plot')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(f'{name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot(losses, \"loss\")\n",
    "plot(accuracy, \"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
