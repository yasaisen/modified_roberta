{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1oqh0F6W3ad"
   },
   "source": [
    "# Train a language model (Masked Language Modelling) from scratch using Huggingface Transformers and a custom tokenizer\n",
    "\n",
    "### Inspired from the great notebook by Huggingfce (link to blogpost [link](https://huggingface.co/blog/how-to-train)).\n",
    "\n",
    "# Brief Introduction\n",
    "This blog post is the first part of a series where we want to create a product names generator using a transformer model. For a few weeks I was investigating different models and alternatives in Huggingface to train a text generation model. We have a short list of products with their description and our goal is to obtain the name of the product. I did some experiments with the Transformer model in Tensorflow as well as the T5 summarizer. Finally, in order to deepen the use of Huggingface transformers, I decided to approach the problem with a somewhat more complex approach, an encoder decoder model. Maybe it was not the best option but I wanted to learn new things about huggingface Transformers. In the next post of the series we will introduce you deeper in this concept.\n",
    "\n",
    "Here, in this first part, we will show how to train a tokenizer from scratch and how to use Masked Language Modeling technique to create a RoBERTa model. This personalized model will become the base model for our future encoder Decoder model.\n",
    "\n",
    "# Our Solution\n",
    "For our experiment we are going to train from scratch a RoBERTa model, it will become the encoder and the decoder of a future model. But our domain is very specific, words and concepts about clothes, shapes, colors, … Therefore, we are interested in defining our own tokenizer created from our specific vocabulary, avoiding to include more common words from other domains or use cases which are irrelevant for our final purpose.\n",
    "\n",
    "*We can describe our training phase in three main steps*:\n",
    "- Create and train a byte-level, **Byte-pair encoding tokenizer** with the same special tokens as RoBERTa\n",
    "- Train a RoBERTa model from scratch using **Masked Language Modeling**, MLM.\n",
    "- Warm start and **fine tune an encoder decoder model** based on our RoBERTa pretrained model.\n",
    "\n",
    "In this post we’ll demo how to train a “small” RoBERTa model (6 layers, 768 hidden size, 12 attention heads) – that’s the same number of layers & heads as DistilBERT – on a language from a clothing shop. And in a next notebook, we’ll then fine-tune the model on a downstream task of text generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flij-vszUsQm"
   },
   "source": [
    "# Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.4.0\n",
      "  Using cached datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (1.18.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (1.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (0.14.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (20.9)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (0.18.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets==2.4.0) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets==2.4.0) (4.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0) (5.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets==2.4.0) (2.4.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.4.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.4.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.4.0) (2020.4.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets==2.4.0) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==2.4.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==2.4.0) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets==2.4.0) (1.14.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.0.2\n",
      "    Uninstalling datasets-1.0.2:\n",
      "      Successfully uninstalled datasets-1.0.2\n",
      "Successfully installed datasets-2.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1666704240152,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "kD140sFjh0LQ",
    "outputId": "1ddde541-2709-4ab9-f272-868ddd0963de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 22 01:59:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76       Driver Version: 515.76       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:20:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8    28W / 200W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16109,
     "status": "ok",
     "timestamp": 1666704256700,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "HOk4iZ9YZvec",
    "outputId": "ba8a9a79-cd68-49aa-8663-bcd34c25ed6f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1666704262405,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "mc6KQfWIUuZB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import math\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvVMVDYjUaRt"
   },
   "source": [
    "# Loading the datasets\n",
    "\n",
    "As we mentioned before, our dataset contains around 31.000 items, about clothes from an important retailer, including a long product description and a short product name, our target variable. First, we execute a exploratory data analysis and we can observe that the count of rows with outliers values is a small number. The count of words looks like a left skewed distribution, 75% of rows in the range 50–60 words and a maximum about 125 words. The target variable contains about 3 to 6 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TwDqHbL9SY0"
   },
   "source": [
    "Set the variables to the data folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666704262406,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "f2tjpFnyU-8T"
   },
   "outputs": [],
   "source": [
    "# #Set the path to the data folder, datafile and output folder and files\n",
    "\n",
    "# Version = 'v_1.5.2'\n",
    "\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "\n",
    "# # wikitext_folder = os.path.abspath(os.path.join(root_folder, '../dataset/wikitext'))\n",
    "# # cc_news_folder = os.path.abspath(os.path.join(root_folder, '../dataset/cc_news'))\n",
    "# model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "# output_folder = os.path.abspath(os.path.join(root_folder, 'output'))\n",
    "# # tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))\n",
    "\n",
    "# # train_filename = 'train'\n",
    "# # test_filename = 'test'\n",
    "# outputfile = 'wikitext_submission.csv'\n",
    "\n",
    "# # wikitext_trainfile_path = os.path.abspath(os.path.join(wikitext_folder,train_filename))\n",
    "# # cc_news_trainfile_path = os.path.abspath(os.path.join(cc_news_folder,train_filename))\n",
    "# # testfile_path = os.path.abspath(os.path.join(wikitext_folder,test_filename))\n",
    "# outputfile_path = os.path.abspath(os.path.join(output_folder,outputfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666704262406,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "V9583qjTaVoI"
   },
   "outputs": [],
   "source": [
    "def checkpath(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666704262407,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "7DGAcLU_Ysto"
   },
   "outputs": [],
   "source": [
    " # import dataset\n",
    "\n",
    "wikitext_folder = os.path.abspath(os.path.join(ROOT_PATH, 'dataset/wikitext'))\n",
    "cc_news_folder = os.path.abspath(os.path.join(ROOT_PATH, 'dataset/cc_news'))\n",
    "\n",
    "train_filename = 'train'\n",
    "test_filename = 'test'\n",
    "\n",
    "wikitext_trainfile_path = os.path.abspath(os.path.join(wikitext_folder,train_filename))\n",
    "cc_news_trainfile_path = os.path.abspath(os.path.join(cc_news_folder,train_filename))\n",
    "testfile_path = os.path.abspath(os.path.join(wikitext_folder,test_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1666704262790,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "uGqB-U0bDifT"
   },
   "outputs": [],
   "source": [
    " # model version\n",
    "mVersion = 'M_v_7.0.3'\n",
    "\n",
    "root_folder = os.path.abspath(os.path.join(ROOT_PATH, mVersion))\n",
    "\n",
    "model_folder = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "checkpath(model_folder)\n",
    "\n",
    "output_folder = os.path.abspath(os.path.join(root_folder, 'output'))\n",
    "\n",
    "outputfile = 'wikitext_submission.csv'\n",
    "\n",
    "outputfile_path = os.path.abspath(os.path.join(output_folder,outputfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666704262790,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "udGV6EfxavCY"
   },
   "outputs": [],
   "source": [
    "#  # last model version\n",
    "# Version = 'M_v_4.1.2' # 04\n",
    "\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "\n",
    "# pre_model_folder = os.path.abspath(os.path.join(root_folder, 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666704262791,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "K8ol3_URCad5"
   },
   "outputs": [],
   "source": [
    "#  # tokenizer version\n",
    "# Version = 'T_v_1.3.3'\n",
    "\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "\n",
    "# tokenizer_folder = os.path.abspath(os.path.join(root_folder, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666704262791,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "DeaiAuJW3T1V"
   },
   "outputs": [],
   "source": [
    "#  # dataset version\n",
    "# Version = 'D_v_1.2.1'\n",
    "\n",
    "# root_folder = os.path.abspath(os.path.join('/content/drive/My Drive/07_research_main/lab_10', Version))\n",
    "\n",
    "# train_filename = 'train_dataset_list.csv'\n",
    "# test_filename = 'test_dataset_list.csv'\n",
    "\n",
    "# train_file_path = os.path.abspath(os.path.join(root_folder,train_filename))\n",
    "# test_file_path = os.path.abspath(os.path.join(root_folder,test_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx_diDArVIHa"
   },
   "source": [
    "Load the train datafile with the product descriptions and names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1666704263016,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "DCCbW4Wg88dt"
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6910,
     "status": "ok",
     "timestamp": 1666704269922,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "IPoDiXbtQRN0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Valkyria Chronicles III = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senjō no Valkyria 3 : &lt;unk&gt; Chronicles ( Japa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The game began development in 2010 , carrying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                                   \n",
       "1                     = Valkyria Chronicles III = \\n\n",
       "2                                                   \n",
       "3   Senjō no Valkyria 3 : <unk> Chronicles ( Japa...\n",
       "4   The game began development in 2010 , carrying..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext_train_df = load_from_disk(wikitext_trainfile_path).to_pandas()\n",
    "wikitext_train_df.head()\n",
    "# wikitext_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20574,
     "status": "ok",
     "timestamp": 1666704290493,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ea22ZEHcQ8yy",
    "outputId": "41205ce2-3cef-4b69-f136-0707d8b6a960"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's a surprising twist to Regina Willoughb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The New York City Ballet Board of Directors an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Philadelphia Eagles and the New England Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Looking for your next audition shoe? Shot at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York City Ballet principal dancer Rebecca ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  There's a surprising twist to Regina Willoughb...\n",
       "1  The New York City Ballet Board of Directors an...\n",
       "2  The Philadelphia Eagles and the New England Pa...\n",
       "3  Looking for your next audition shoe? Shot at a...\n",
       "4  New York City Ballet principal dancer Rebecca ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_news_train_df = load_from_disk(cc_news_trainfile_path).to_pandas()\n",
    "cc_news_train_df.pop(\"title\")\n",
    "cc_news_train_df.pop(\"domain\")\n",
    "cc_news_train_df.pop(\"date\")\n",
    "cc_news_train_df.pop(\"description\")\n",
    "cc_news_train_df.pop(\"url\")\n",
    "cc_news_train_df.pop(\"image_url\")\n",
    "cc_news_train_df.head()\n",
    "# cc_news_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  A series of escapades demonstrating the adage ...\n",
       "1  A series of escapades demonstrating the adage ...\n",
       "2                                           A series\n",
       "3                                                  A\n",
       "4                                             series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SST5_train_df = pd.read_csv('/home/finetune_dataset/kge_sentiment_analysis/train.tsv.zip', sep=\"\\t\")\n",
    "SST5_train_df.pop(\"PhraseId\")\n",
    "SST5_train_df.pop(\"SentenceId\")\n",
    "SST5_train_df.pop(\"Sentiment\")\n",
    "SST5_train_df = SST5_train_df.rename(columns={'Phrase': 'text'})\n",
    "\n",
    "SST5_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  A series of escapades demonstrating the adage ...\n",
       "1  A series of escapades demonstrating the adage ...\n",
       "2                                           A series\n",
       "3                                                  A\n",
       "4                                             series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SST5_test_df = pd.read_csv('/home/finetune_dataset/kge_sentiment_analysis/test.tsv.zip', sep=\"\\t\")\n",
    "SST5_test_df.pop(\"PhraseId\")\n",
    "SST5_test_df.pop(\"SentenceId\")\n",
    "SST5_test_df = SST5_train_df.rename(columns={'Phrase': 'text'})\n",
    "\n",
    "SST5_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  A series of escapades demonstrating the adage ...\n",
       "1  A series of escapades demonstrating the adage ...\n",
       "2                                           A series\n",
       "3                                                  A\n",
       "4                                             series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SST2_train_df = pd.read_csv('/home/finetune_dataset/IMDB_MovieReviews/IMDB_Dataset.csv.zip')\n",
    "SST2_train_df.pop(\"sentiment\")\n",
    "SST2_train_df = SST5_train_df.rename(columns={'review': 'text'})\n",
    "\n",
    "SST2_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitext_test_df = load_from_disk(testfile_path).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1666704290494,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zohUzj7PQ5xw",
    "outputId": "324bce1c-7bfe-4d62-be85-e27f092d17e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2982129 entries, 0 to 2982128\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   text    object\n",
      "dtypes: object(1)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the train dataset\n",
    "train_df = pd.concat([wikitext_train_df, cc_news_train_df, SST5_train_df, SST5_test_df, SST2_train_df, wikitext_test_df], ignore_index=True)\n",
    "# train_df.head()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1666704291303,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "eMlW2iAIikfM",
    "outputId": "6cb3a66e-1037-4d67-af57-82c09853ba8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As most of the songs are in the form of Ovee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the rest of the world was dodging spoilers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Throughout the day on July 2 , the depression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The street in Bradford where Faisal Hussein, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                                   \n",
       "1   As most of the songs are in the form of Ovee ...\n",
       "2  As the rest of the world was dodging spoilers ...\n",
       "3   Throughout the day on July 2 , the depression...\n",
       "4  The street in Bradford where Faisal Hussein, 2..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(train_df, random_state=42, test_size = 0.0015) #kj666:)))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1666704292214,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "MqxDq-LcVL0T",
    "outputId": "684ac33e-5868-4612-a208-12a7eaadcd7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Examples:  2977655\n",
      "Null Values\n",
      " text    0\n",
      "dtype: int64\n",
      "Num Examples:  2977655\n"
     ]
    }
   ],
   "source": [
    "# Show the count of rows\n",
    "print('Num Examples: ',len(train_df))\n",
    "print('Null Values\\n', train_df.isna().sum())\n",
    "# Drop rows with Null values \n",
    "train_df.dropna(inplace=True)\n",
    "print('Num Examples: ',len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666704292215,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "GlbRvlnkE8OU",
    "outputId": "0227678b-6c93-468e-ba1f-8c360856e682"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2579206</th>\n",
       "      <td>Subsequently , in November 1946 , the Deputy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267090</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960920</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729001</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415785</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "2579206   Subsequently , in November 1946 , the Deputy ...\n",
       "2267090                                                   \n",
       "960920                                                    \n",
       "729001                                                    \n",
       "1415785                                                   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGjcMQ_J9yXu"
   },
   "source": [
    "Then, we read the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1666704293145,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "pbCZSLQxVYr-",
    "outputId": "ae21ce07-8154-47fb-fabf-050216e469b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Examples:  4474\n",
      "Null Values\n",
      " text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset \n",
    "print('Num Examples: ',len(test_df))\n",
    "print('Null Values\\n', test_df.isna().sum())\n",
    "# there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666704293146,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "lQX2J1_m7jlD"
   },
   "outputs": [],
   "source": [
    "# ###\n",
    "# train_df = train_df.sample(frac=0.00001, random_state=0, axis=0)\n",
    "# test_df = test_df.sample(frac=0.001, random_state=0, axis=0)\n",
    "# train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_Djave6qwUA"
   },
   "source": [
    "# Build a Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv3X5LvKVtAN"
   },
   "source": [
    "## Create the dataset to train a tokenizer\n",
    "\n",
    "*To train a tokenizer we need to save our dataset in a bunch of text files*. We create a plain text file for every description value and we will split each sample using a newline character. We include both the train and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666704293147,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "FU9C8eNEc1jz"
   },
   "outputs": [],
   "source": [
    "# # Drop the files from the output dir\n",
    "# txt_files_dir = \"./text_split\"\n",
    "# !rm -rf {txt_files_dir}\n",
    "# !mkdir {txt_files_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666704293147,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "3GW5loLTdtUy"
   },
   "outputs": [],
   "source": [
    "# # Store values in a dataframe column (Series object) to files, one file per record\n",
    "# def column_to_files(column, prefix, txt_files_dir):\n",
    "#     # The prefix is a unique ID to avoid to overwrite a text file\n",
    "#     i=prefix\n",
    "#     #For every value in the df, with just one column\n",
    "#     for row in column.to_list():\n",
    "#       # Create the filename using the prefix ID\n",
    "#       file_name = os.path.join(txt_files_dir, str(i)+'.txt')\n",
    "#       try:\n",
    "#         # Create the file and write the column text to it\n",
    "#         f = open(file_name, 'wb')\n",
    "#         f.write(row.encode('utf-8'))\n",
    "#         f.close()\n",
    "#       except Exception as e:  #catch exceptions(for eg. empty rows)\n",
    "#         print(row, e) \n",
    "#       i+=1\n",
    "#     # Return the last ID\n",
    "#     return i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqC5EASdrd8a"
   },
   "source": [
    "Include the training dataset to the main text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666704293148,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "AurkxAD-Vx-M"
   },
   "outputs": [],
   "source": [
    "# data = train_df[\"text\"]\n",
    "# # Removing the end of line character \\n\n",
    "# data = data.replace(\"\\n\",\" \")\n",
    "# # Set the ID to 0\n",
    "# prefix=0\n",
    "# # Create a file for every description value\n",
    "# prefix = column_to_files(data, prefix, txt_files_dir)\n",
    "# # Print the last ID\n",
    "# print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrJTp3dRrkCX"
   },
   "source": [
    "Also include the test dataset to the text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666704293148,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ldqNgudjd540"
   },
   "outputs": [],
   "source": [
    "# data = test_df[\"text\"]\n",
    "# # Removing the end of line character \\n\n",
    "# data = data.replace(\"\\n\",\" \")\n",
    "# print(len(data))\n",
    "# # Create a file for every description value\n",
    "# prefix = column_to_files(data, prefix, txt_files_dir)\n",
    "# print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPdhaKxTrxJx"
   },
   "source": [
    "**Include the target variable for training** NOOOO¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1666704293149,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "7rxjGQJQox_y"
   },
   "outputs": [],
   "source": [
    "# data = train_df[\"text\"]\n",
    "# data = data.replace(\"\\n\",\" \")\n",
    "# print(len(data))\n",
    "# prefix = column_to_files(data, prefix, txt_files_dir)\n",
    "# print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-kkz81OY6xH"
   },
   "source": [
    "## Train the tokenizer\n",
    "\n",
    "The Stanford NLP group define the tokenization as:\n",
    "\n",
    "\"*Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation.*\"\n",
    "\n",
    "A tokenizer breaks a string of characters, usually sentences of text, into tokens, an integer representation of the token, usually by looking for whitespace (tabs, spaces, new lines). It usually splits a sentence into words but there are many options like subwords.\n",
    "\n",
    "We will use a **byte-level Byte-pair encoding tokenizer**, byte pair encoding (BPE) is a simple form of data compression in which the most common pair of consecutive bytes of data is replaced with a byte that does not occur within that data. The benefit of this method is that it will start building its vocabulary from an alphabet of single chars, so all words will be decomposable into tokens. We can avoid the presence of unknown (UNK) tokens.\n",
    "\n",
    "A great explanation on tokenizers can be found on the huggingface documentation, https://huggingface.co/transformers/tokenizer_summary.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 43445,
     "status": "ok",
     "timestamp": 1666704336574,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5duRggBRZKvP",
    "outputId": "110e0dd6-7850-4817-eb4a-56ad281dce56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-dc55dakg\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git': 'git' while executing command git version\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\u001b[31m\n",
      "\u001b[0mtokenizers             0.13.3\n",
      "transformers           4.28.1\n",
      "Collecting datasets==1.0.2\n",
      "  Using cached datasets-1.0.2-py3-none-any.whl (1.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (1.18.1)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (12.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (1.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (3.0.12)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets==1.0.2) (3.2.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.0.2) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.0.2) (2020.4.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.0.2) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.0.2) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.14.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "Successfully installed datasets-1.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# We won't need TensorFlow here\n",
    "!pip uninstall -y tensorflow\n",
    "# Install `transformers` from master\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "# !pip install -q transformers==4.21.1\n",
    "!pip list | grep -E 'transformers|tokenizers'\n",
    "# transformers version at notebook update --- 2.11.0\n",
    "# tokenizers version at notebook update --- 0.8.0rc1\n",
    "!pip install datasets==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYVIE1XcsV8_"
   },
   "source": [
    "We choose to train a byte-level Byte-pair encoding tokenizer (the same as GPT-2), with the same special tokens as RoBERTa. Let’s pick its size to be 8,192 because our specific vocabulary is very limited and simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1666704336577,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QgdLhEQS4c5f"
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "# from tokenizers.processors import BertProcessing\n",
    "\n",
    "# import torch\n",
    "# from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzKv-3nH66yq"
   },
   "source": [
    "Now we can train our tokenizer on the text files containing our vocabulary, we need to specify the vocabulary size, the min frequency for a token to be included and the special tokens. We choose a vocab size of 8,192 and a min frequency of 2 (you can tune this value depending on your max vocabulary size). \n",
    "\n",
    "The special tokens depends on the model, for RoBERTa we include a short list: \n",
    "- \\<s> or BOS, beginning Of Sentence\n",
    "- \\</s> or EOS, End Of Sentence\n",
    "- \\<pad> the padding token\n",
    "- \\<unk> the unknown token\n",
    "- \\<mask> the masking token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1666704336578,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "IMnymRDLe0hi"
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# paths = [str(x) for x in Path(\".\").glob(\"text_split/*.txt\")]\n",
    "\n",
    "# # Initialize a tokenizer\n",
    "# tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "\n",
    "# # Customize training\n",
    "# tokenizer.train(files=paths, vocab_size=50265, min_frequency=2,\n",
    "#                 show_progress=True,\n",
    "#                 special_tokens=[\n",
    "#                                 \"<s>\",\n",
    "#                                 \"<pad>\",\n",
    "#                                 \"</s>\",\n",
    "#                                 \"<unk>\",\n",
    "#                                 \"<mask>\",\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1666704336580,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "JBCOT9aI98fl"
   },
   "outputs": [],
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ei7bqpRf1LH"
   },
   "source": [
    "The count of samples is small and the tokenizer trains very fast. Now we can save the tokenizer to disk, later we will use it to train the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1666704336581,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "EIS-irI0f32P"
   },
   "outputs": [],
   "source": [
    "# #Save the Tokenizer to disk\n",
    "# tokenizer.save_model(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOOfYSuQhSqT"
   },
   "source": [
    "We now have both a `vocab.json`, which is a list of the most frequent tokens ranked by frequency and it is used to convert tokens to IDs, and a `merges.txt` file that maps texts to tokens.\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"<s>\": 0,\n",
    "\t\"<pad>\": 1,\n",
    "\t\"</s>\": 2,\n",
    "\t\"<unk>\": 3,\n",
    "\t\"<mask>\": 4,\n",
    "\t\"!\": 5,\n",
    "\t\"\\\"\": 6,\n",
    "\t\"#\": 7,\n",
    "\t\"$\": 8,\n",
    "\t\"%\": 9,\n",
    "\t\"&\": 10,\n",
    "\t\"'\": 11,\n",
    "\t\"(\": 12,\n",
    "\t\")\": 13,\n",
    "\t# ...\n",
    "}\n",
    "\n",
    "# merges.txt\n",
    "l a\n",
    "Ġ k\n",
    "o n\n",
    "Ġ la\n",
    "t a\n",
    "Ġ e\n",
    "Ġ d\n",
    "Ġ p\n",
    "# ...\n",
    "```\n",
    "\n",
    "What is great is that our tokenizer is optimized for our very specific vocabulary. Compared to a generic tokenizer trained for English, more native words are represented by a single, unsplit token. \n",
    "\n",
    "Here’s  how you can use it in `tokenizers`, including handling the RoBERTa special tokens – of course, you’ll also be able to use it directly from `transformers`. We can instantiate our tokenizer using both files and test it with some text from our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1666704336583,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "tKVWB8WShT-z"
   },
   "outputs": [],
   "source": [
    "# # Create the tokenizer using vocab.json and mrege.txt files\n",
    "# tokenizer = ByteLevelBPETokenizer(\n",
    "#     os.path.abspath(os.path.join(tokenizer_folder,'vocab.json')),\n",
    "#     os.path.abspath(os.path.join(tokenizer_folder,'merges.txt'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1666704336584,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "hO5M3vrAhcuj"
   },
   "outputs": [],
   "source": [
    "# # Prepare the tokenizer\n",
    "# tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "#     (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "#     (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "# )\n",
    "# tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z2IxmcK_eSf"
   },
   "source": [
    "Let's show some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1666704336586,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "E3Ye27nchfzq"
   },
   "outputs": [],
   "source": [
    "# tokenizer.encode(\"knit midi dress with vneckline straps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1666704336588,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "X8ya5_7rhjKS"
   },
   "outputs": [],
   "source": [
    "# # Show the tokens created\n",
    "# tokenizer.encode(\"knit midi dress with vneckline straps.\").tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpUC_CDhnWW"
   },
   "source": [
    "# Train a language model from scratch\n",
    "\n",
    "**Update:** This section follows along the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, using our new [`Trainer`](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py) directly. Feel free to pick the approach you like best.\n",
    "\n",
    "> We’ll train a RoBERTa-like model, which is a BERT-like with a couple of changes (check the [documentation](https://huggingface.co/transformers/model_doc/roberta.html) for more details). In summary: *It builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates* .\n",
    "\n",
    "As the model is BERT-like, we’ll train it on a task of **Masked language modeling**. It involves masking part of the input, about 10-20% of thre tokens, then learning a model to predict the missing tokens. MLM is often used within pretraining tasks, **to give models the opportunity to learn textual patterns from unlabeled data**. It can be fine tuned to a particular downstream task. The main benefit is that we do not need labeled data (hard to obtain), no text needs to be labeled by human labelers in order to predict the missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylwOUseU3doR"
   },
   "source": [
    "We define some global parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1666704336589,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "V6VsZnOd636F"
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64    # input batch size for training (default: 64)\n",
    "VALID_BATCH_SIZE = 4    # input batch size for testing (default: 1000)\n",
    "TRAIN_EPOCHS = 10        # number of epochs to train (default: 10)\n",
    "LEARNING_RATE = 2e-4    # learning rate (default: 0.001)\n",
    "WEIGHT_DECAY = 0.01\n",
    "SEED = 42               # random seed (default: 42)\n",
    "MAX_LEN = 128\n",
    "SUMMARY_LEN = 7\n",
    "BOOM = 4\n",
    "SAVE_STEPS = 78420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1853,
     "status": "ok",
     "timestamp": 1666704338379,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "VNZZs-r6iKAV",
    "outputId": "bd4a21ff-195a-4174-e6bc-42967847080f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that PyTorch sees it\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0qQzgrBi1OX"
   },
   "source": [
    "##Define the model\n",
    "\n",
    "We are going to train the model from scratch, not from a pretrained one. We create a model configuration for our RoBERTa model setting the main parameters:\n",
    "- Vocabulary size\n",
    "- Attention heads\n",
    "- Hidden layers\n",
    "- etc,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1666704338380,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "LTXXutqeDzPi"
   },
   "outputs": [],
   "source": [
    "# from transformers import RobertaConfig\n",
    "\n",
    "# config = RobertaConfig.from_pretrained('roberta-large')\n",
    "\n",
    "# config.num_hidden_layers = 10\n",
    "\n",
    "# # config.vocab_size = 8192 ###50265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1666704338381,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "EeAgx8icaiza"
   },
   "outputs": [],
   "source": [
    "# print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yNCw-3hFv9h"
   },
   "source": [
    "Finally let's initialize our model using the configuration file. As we are training from scratch, we only initialize from a config that define the architecture of the model but *not restoring previously trained weights*. The weights will be randomly initialized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1666704338382,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "t1RCnPn7CCur",
    "outputId": "6950546a-8b7b-4b3a-ffc4-0eae51122d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.28.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print('transformers version: %s' %(transformers.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1666704338943,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "G7pBEVNV47nI"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaLMHead, RobertaPreTrainedModel\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import Tensor\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"roberta-base\"\n",
    "_CONFIG_FOR_DOC = \"RobertaConfig\"\n",
    "_TOKENIZER_FOR_DOC = \"RobertaTokenizer\"\n",
    "\n",
    "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "            Indices can be obtained using [`RobertaTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
    "            1]`:\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1666704338944,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "aiFBn6U24-zF"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1666704338945,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Do63MmlK5HK-"
   },
   "outputs": [],
   "source": [
    "class Boom_new(nn.Module):\n",
    "     def __init__(self, in_features: int, out_features: int, dropout=0.1, shortcut: bool = True, device=None, dtype=None) -> None:\n",
    "         factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "         super(Boom_new, self).__init__()\n",
    "\n",
    "         self.linear1 = nn.Linear(in_features, out_features)\n",
    "         self.dropout = nn.Dropout(dropout) if dropout else None\n",
    "         if not shortcut:\n",
    "             self.linear2 = nn.Linear(out_features, in_features)\n",
    "         self.shortcut = shortcut\n",
    "         self.act = GELU()\n",
    " \n",
    "     def forward(self, input: Tensor) -> Tensor:\n",
    "         x = self.act(self.linear1(input))\n",
    "         if self.dropout: x = self.dropout(x)\n",
    "         if self.shortcut:\n",
    "             ninp = input.shape[-1]\n",
    "             x = torch.narrow(x, -1, 0, x.shape[-1] // ninp * ninp)\n",
    "             x = x.view(*x.shape[:-1], x.shape[-1] // ninp, ninp)\n",
    "             z = x.sum(dim=-2)\n",
    "         else:\n",
    "             z = self.linear2(x)\n",
    " \n",
    "         return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1666704338947,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "XvhosciFKGK_"
   },
   "outputs": [],
   "source": [
    "class ModifiedRobertaForMaskedLM(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_save = [r\"lm_head.decoder.weight\", r\"lm_head.decoder.bias\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"lm_head.decoder.weight\", r\"lm_head.decoder.bias\"]\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if config.is_decoder:\n",
    "            logger.warning(\n",
    "                \"If you want to use `RobertaForMaskedLM` make sure `config.is_decoder=False` for \"\n",
    "                \"bi-directional self-attention.\"\n",
    "            )\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.Boom = Boom_new(config.hidden_size, (config.hidden_size * BOOM))\n",
    "        self.LINEAR = nn.Linear(config.hidden_size,config.hidden_size)\n",
    "        self.lm_head = RobertaLMHead(config)\n",
    "\n",
    "        # The LM head weights require special treatment only when they are tied with the word embeddings\n",
    "        self.update_keys_to_ignore(config, [\"lm_head.decoder.weight\"])\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head.decoder = new_embeddings\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        processor_class=_TOKENIZER_FOR_DOC,\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MaskedLMOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        mask=\"<mask>\",\n",
    "        expected_output=\"' Paris'\",\n",
    "        expected_loss=0.1,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], MaskedLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n",
    "            config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\n",
    "            loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
    "        kwargs (`Dict[str, any]`, optional, defaults to *{}*):\n",
    "            Used to hide legacy arguments that have been deprecated.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.Boom(sequence_output)\n",
    "        sequence_output = self.LINEAR(sequence_output)\n",
    "        prediction_scores = self.lm_head(sequence_output)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return MaskedLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=prediction_scores,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1666704338949,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "BzMqR-dzF4Ro"
   },
   "outputs": [],
   "source": [
    "# model = ModifiedRobertaForMaskedLM(config=config)\n",
    "# print('Num parameters: ',model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "cd6ad41fbd8e4f4b8227923b80f17f8e",
      "3a3b1f09c5f840d388a7c0cf8e6b780e",
      "6872e1027f3649a194ed29964e2d6c71",
      "6076afddbacb47b4857f8b8382029b32",
      "15a4a36006a842cdbd5e693a932479c0",
      "9da5046952ad44aeab0db1d887b8ea97",
      "631ca02d0f0148f08d8fe4812c346157",
      "1aa323aa48c64b30b2c86510f9645dd1",
      "b23c2ea042904a5e8bef6a4abc3c8891",
      "89c80273e17e423f9cee0f3ec5fd8b83",
      "273fe0b1d79c479facdd9dc866d816d5"
     ]
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1666704338951,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "wqH6c3Z6cSif",
    "outputId": "7a323c4e-a366-4bbe-b7d5-90b235818814"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig.from_pretrained('roberta-large')\n",
    "\n",
    "config.num_hidden_layers = 10\n",
    "\n",
    "# config.vocab_size = 8192 ###50265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1666704338953,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "N0RECGOI44S9"
   },
   "outputs": [],
   "source": [
    "# model = ModifiedRobertaForMaskedLM.from_pretrained(pre_model_folder)\n",
    "# print('Num parameters: ',model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "c4645b2bda554f63b62517a72061f01c",
      "cd2464226a8c4849a12f085b40e328d1",
      "76946f1729db401f9998f7ec2f902304",
      "ad17beeed1994152bc730840cc7f8e73",
      "ac4ee4da9fc0423bab18cbc3fadfc469",
      "fb680875fa3647a2b9eaee548e0e15e3",
      "98274de3ae5d4df79f7208933ffab26d",
      "5440d72cdf494c57a1749fabba531e20",
      "4e9f5f52e19e4bf7860c73810b860c25",
      "e6025847c5da4135a65ad33026f8c0e0",
      "aafe707e0cc3469887582205dbc2d686"
     ]
    },
    "executionInfo": {
     "elapsed": 29337,
     "status": "ok",
     "timestamp": 1666704368248,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "pzXVThnOZ_Ti",
    "outputId": "3f233fef-999e-48f8-ecc9-179f40a9c47a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing ModifiedRobertaForMaskedLM: ['roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.22.attention.output.dense.weight']\n",
      "- This IS expected if you are initializing ModifiedRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ModifiedRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ModifiedRobertaForMaskedLM were not initialized from the model checkpoint at roberta-large and are newly initialized: ['LINEAR.weight', 'Boom.linear1.bias', 'LINEAR.bias', 'Boom.linear1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters:  184312921\n"
     ]
    }
   ],
   "source": [
    "# from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = ModifiedRobertaForMaskedLM.from_pretrained('roberta-large', config=config)\n",
    "print('Num parameters: ',model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1666704368249,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "gyOcTRapFq_V",
    "outputId": "f63c46e2-3115-4d4a-e789-72339705b03b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedRobertaForMaskedLM(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (Boom): Boom_new(\n",
      "    (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (act): GELU()\n",
      "  )\n",
      "  (LINEAR): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=1024, out_features=50265, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwQ82JiE5pi"
   },
   "source": [
    "Now let's recreate our tokenizer, using the tokenizer trained and saved in the previous step. We will use a `RoBERTaTokenizerFast` object and the `from_pretrained` method, to initialize our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f5b05448c7cd4083b24d205ce0dece39",
      "f4d3fe3f09904911b808ee41fda5c0bb",
      "ee09b08abe574ef2b52e9e59eaa863de",
      "85dbc86be7a34db79f89acd16798292e",
      "c48bac8f03d94a108ea66f515aca3274",
      "be634c52c2d149f29a62bcbaf20ed24d",
      "c02ef9e5f3bd4909ab082b9073332f8e",
      "7e0eb396e6034ef0a43ed35f67001f53",
      "ca8a6c1eddf8448b8f165d68f4f71ae4",
      "320ef2ba0216483f96a7fc9c1c901d69",
      "fc83d5f2402243c79363cb1c8d5705cd",
      "9655b628e619442b9d9c44a66304c72f",
      "53ce2d3015554e62a17336decbf9ea7e",
      "746723148e164e019c7473c5a8bfb6c0",
      "e9f8c7f2686c47aebf4972302ba1fc13",
      "b4109d9bb90c4cfeb5975554137efd55",
      "0101178233e54b68954ab56ae4903d80",
      "728e706b1ea041669d84526011933e34",
      "0c0fe872edca4fffbb7ed7c992d34f74",
      "474a99ed27a3433db4d6e7f81304e916",
      "ad6b4a6fe7b44c4caffc8f163e99f4f8",
      "e32c8313e6ce436b93549e3a08ccf413"
     ]
    },
    "executionInfo": {
     "elapsed": 2235,
     "status": "ok",
     "timestamp": 1666704370449,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "4keFBUjQFOD1",
    "outputId": "6e234c3a-3dc0-4be3-aca2-cf3bb3600de0"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "# Create the tokenizer from a trained one\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', max_len=MAX_LEN)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(tokenizer_folder, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1666704370449,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "RgXwwfgbG8WN",
    "outputId": "6a1381b4-e23e-4623-d083-e4c9f9a5e72f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizer(name_or_path='roberta-large', vocab_size=50265, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBtUHRMliOLM"
   },
   "source": [
    "## Building the training Dataset\n",
    "\n",
    "We'll build a Pytorch dataset, subclassing the Dataset Class. The CustomDataset receives a Pandas Series with the `description` variable values and the tokenizer to encode those values. The Dataset returns a list of tokens for every product description in the Series.\n",
    "\n",
    "In order to evaluate the model during training, we will generate a train dataset for training and a evaluation dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBdFLR-dZnXs"
   },
   "source": [
    "https://ryanong.co.uk/2020/06/11/day-163-how-to-build-a-language-model-from-scratch-implementation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1666704370450,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "-RBzSqDcnoG6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1666704370450,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "idY_-O7z0rY4"
   },
   "outputs": [],
   "source": [
    "# get_train_dataset = pd.read_csv(train_file_path, dtype = 'Int64', keep_default_na = False)\n",
    "# # get_train_dataset = get_train_dataset.sample(frac=1).reset_index(drop=True)\n",
    "# get_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1666704370451,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6Dn-V0syNNKd"
   },
   "outputs": [],
   "source": [
    "# ###\n",
    "# get_train_dataset = get_train_dataset[0:250959]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1666704370451,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "AhtZVbbKNHh1"
   },
   "outputs": [],
   "source": [
    "# train_dataset_list_ = [[y for y in x if pd.notna(y)] for x in get_train_dataset.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1666704370452,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Y1MLItvREIEJ"
   },
   "outputs": [],
   "source": [
    "# get_test_dataset = pd.read_csv(test_file_path, dtype = 'Int64', keep_default_na = False)\n",
    "# test_dataset_list_ = [[y for y in x if pd.notna(y)] for x in get_test_dataset.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1666704370453,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Z5Ausw4SN8H3"
   },
   "outputs": [],
   "source": [
    "# len(train_dataset_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1666704370453,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "gpioQ3TQEYLw"
   },
   "outputs": [],
   "source": [
    "# print(test_dataset_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1666704370454,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "WFMmfy_LDpRZ"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        # or use the RobertaTokenizer from `transformers` directly.\n",
    "\n",
    "        self.examples = []\n",
    "        \n",
    "        for example in df.values:\n",
    "            x=tokenizer.encode_plus(example, max_length = MAX_LEN, truncation=True, padding=True)\n",
    "            self.examples += [x.input_ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # We’ll pad at the batch level.\n",
    "        return torch.tensor(self.examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1666704370454,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "IANvVtIfQLNA"
   },
   "outputs": [],
   "source": [
    "# class ModifiedCustomDataset(Dataset):\n",
    "#     def __init__(self, df_list):\n",
    "#         # or use the RobertaTokenizer from `transformers` directly.\n",
    "\n",
    "#         self.examples = df_list\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.examples)\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         # We’ll pad at the batch level.\n",
    "#         return torch.tensor(self.examples[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4Ovn-MTm149"
   },
   "source": [
    "Concat the training and test dataset, only with the description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1666704370455,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "0miQ7KOQ3eHp"
   },
   "outputs": [],
   "source": [
    "# Concatenate the train dataset and the test dataset for language modelling\n",
    "#df=pd.concat([train_df['description'], test_df['description']], axis=0)\n",
    "#print('Total: ',len(df), len(train_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACOfK4avA_qx"
   },
   "source": [
    "Create the custom datasets, for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 3284596,
     "status": "ok",
     "timestamp": 1666707655026,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "5aTvI2sBDK5N"
   },
   "outputs": [],
   "source": [
    "# Create the train and evaluation dataset\n",
    "train_dataset = CustomDataset(train_df['text'], tokenizer)\n",
    "eval_dataset = CustomDataset(test_df['text'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666707655026,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "mHEC6fqwQgSi"
   },
   "outputs": [],
   "source": [
    "# # Create the train and evaluation dataset\n",
    "# train_dataset = ModifiedCustomDataset(train_dataset_list_)\n",
    "# eval_dataset = ModifiedCustomDataset(test_dataset_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666707655026,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "oESyOrJAGplY"
   },
   "outputs": [],
   "source": [
    "# len(train_dataset.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666707655027,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "867UjcoBtWUz"
   },
   "outputs": [],
   "source": [
    "# print(eval_dataset.examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm5cA1XUBkNB"
   },
   "source": [
    "## Define the Data Collactor for masking our language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDLs73HcIHk5"
   },
   "source": [
    "Like in the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, we need to define a data_collator.\n",
    "\n",
    "Once we have the dataset, a **Data Collator will helps us to mask our training texts**. This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on. Data collators are objects that will form a batch by using a list of dataset elements as input and may apply some processing like padding or random masking. The `DataCollatorForLanguageModeling` method allow us to set the probability with which to randomly mask tokens in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1666707655439,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Define the Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZhOfZ-RByBr"
   },
   "source": [
    "## Initialize and train our Trainer\n",
    "\n",
    "When we want to train a transformer model, the basic approach is to create a Trainer class that provides an API for feature-complete training and contains the basic training loop. First, we define the training arguments, there are many of them but the more relevant are\n",
    "- `output_dir`, where the model artifacts will be saved\n",
    "- `num_train_epochs`\n",
    "- `per_device_train_batch_size`, the batch size\n",
    "\n",
    "\n",
    " and then the `Trainer` object is created with the arguments, the input dataset and the data collator defined:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4491,
     "status": "ok",
     "timestamp": 1666707659927,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YpvnFFmZJD-N",
    "outputId": "f7fb0876-1cad-4840-c95b-c6d0067465d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/M_v_7.0.3/model\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "print(model_folder)\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_folder,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    num_train_epochs=TRAIN_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    #eval_steps=4096,\n",
    "    save_total_limit=1,\n",
    "    fp16 = False,\n",
    "#     load_best_model_at_end = True,###############################\n",
    ")\n",
    "# Create the trainer for our model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    #prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6sASa36Nf-N"
   },
   "source": [
    "And now, we are ready to train our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1666707659928,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "GxyfXuU1FEVN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "executionInfo": {
     "elapsed": 45092765,
     "status": "ok",
     "timestamp": 1666752752671,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "VmaHZXzmkNtJ",
    "outputId": "4fddbc78-ef50-47c9-9608-deeb65b74d8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='226146' max='465260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [226146/465260 46:59:26 < 49:41:08, 1.34 it/s, Epoch 4.86/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.555000</td>\n",
       "      <td>2.373737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.388500</td>\n",
       "      <td>2.171558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.244500</td>\n",
       "      <td>2.138920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.123700</td>\n",
       "      <td>1.993297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GegoobjKwfu8"
   },
   "source": [
    "As a result, we can watch how the loss is decreasing while training. We can evaluate our model on the validation set. The perplexity is high because we only have to make predictions for the masked tokens (which represent 15% of the total here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5611016750335693,\n",
       " 'eval_runtime': 16.5772,\n",
       " 'eval_samples_per_second': 269.889,\n",
       " 'eval_steps_per_second': 67.503,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 26228,
     "status": "ok",
     "timestamp": 1666752778885,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "4lI4mgajKz70",
    "outputId": "24166591-13c8-40d9-d72a-957093bb29ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 4.76\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZkooHz1-_2h"
   },
   "source": [
    "## Save our final model and tokenizer to disk\n",
    "\n",
    "Save the model and tokenizer ina way that they can be restored for a future downstream task, our encoder decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22886,
     "status": "ok",
     "timestamp": 1666752801767,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QDNgPls7_l13",
    "outputId": "e76b9847-65f4-4cb6-c5da-27f280c39198"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'state_dict': trainer.model.state_dict(), 'model': trainer.model,}, os.path.join(model_folder, mVersion + '.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0caceCy_p1-"
   },
   "source": [
    "# Checking the trained model using a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIQJ8ND_AEhl"
   },
   "source": [
    "Looking at the training and eval losses going down is not enough, we would like to apply our model to check if our language model is learning anything interesting. An easy way is via the FillMaskPipeline.\n",
    "\n",
    "Pipelines are simple wrappers around tokenizers and models. **We can use the 'fill-mask' pipeline** where we input a sequence containing a masked token (<mask>) and it returns a list of the most probable filled sequences, with their probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5098,
     "status": "error",
     "timestamp": 1666752806852,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ltXgXyCbAJLY",
    "outputId": "447ba0c6-0562-4c4a-9eac-42316b0338a2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model_folder,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1666752806853,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "UIvgZ3S6AO0z"
   },
   "outputs": [],
   "source": [
    "# knit midi dress with vneckline\n",
    "# =>\n",
    "fill_mask(\"midi <mask> with vneckline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0qCyyhNAWZi"
   },
   "source": [
    "Ok, simple syntax/grammar works. Let’s try a slightly more interesting prompt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1666752806854,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "YZ9HSQxAAbme"
   },
   "outputs": [],
   "source": [
    "# The test text: Round neck sweater with long sleeves\n",
    "fill_mask(\"Round neck sweater with <mask> sleeves.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb",
     "timestamp": 1612196531906
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0101178233e54b68954ab56ae4903d80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c0fe872edca4fffbb7ed7c992d34f74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15a4a36006a842cdbd5e693a932479c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1aa323aa48c64b30b2c86510f9645dd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "273fe0b1d79c479facdd9dc866d816d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "320ef2ba0216483f96a7fc9c1c901d69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a3b1f09c5f840d388a7c0cf8e6b780e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9da5046952ad44aeab0db1d887b8ea97",
      "placeholder": "​",
      "style": "IPY_MODEL_631ca02d0f0148f08d8fe4812c346157",
      "value": "Downloading: 100%"
     }
    },
    "474a99ed27a3433db4d6e7f81304e916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e9f5f52e19e4bf7860c73810b860c25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53ce2d3015554e62a17336decbf9ea7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0101178233e54b68954ab56ae4903d80",
      "placeholder": "​",
      "style": "IPY_MODEL_728e706b1ea041669d84526011933e34",
      "value": "Downloading: 100%"
     }
    },
    "5440d72cdf494c57a1749fabba531e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6076afddbacb47b4857f8b8382029b32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89c80273e17e423f9cee0f3ec5fd8b83",
      "placeholder": "​",
      "style": "IPY_MODEL_273fe0b1d79c479facdd9dc866d816d5",
      "value": " 482/482 [00:00&lt;00:00, 19.1kB/s]"
     }
    },
    "631ca02d0f0148f08d8fe4812c346157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6872e1027f3649a194ed29964e2d6c71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1aa323aa48c64b30b2c86510f9645dd1",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b23c2ea042904a5e8bef6a4abc3c8891",
      "value": 482
     }
    },
    "728e706b1ea041669d84526011933e34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "746723148e164e019c7473c5a8bfb6c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c0fe872edca4fffbb7ed7c992d34f74",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_474a99ed27a3433db4d6e7f81304e916",
      "value": 456318
     }
    },
    "76946f1729db401f9998f7ec2f902304": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5440d72cdf494c57a1749fabba531e20",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e9f5f52e19e4bf7860c73810b860c25",
      "value": 1425941629
     }
    },
    "7e0eb396e6034ef0a43ed35f67001f53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85dbc86be7a34db79f89acd16798292e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_320ef2ba0216483f96a7fc9c1c901d69",
      "placeholder": "​",
      "style": "IPY_MODEL_fc83d5f2402243c79363cb1c8d5705cd",
      "value": " 899k/899k [00:00&lt;00:00, 1.78MB/s]"
     }
    },
    "89c80273e17e423f9cee0f3ec5fd8b83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9655b628e619442b9d9c44a66304c72f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53ce2d3015554e62a17336decbf9ea7e",
       "IPY_MODEL_746723148e164e019c7473c5a8bfb6c0",
       "IPY_MODEL_e9f8c7f2686c47aebf4972302ba1fc13"
      ],
      "layout": "IPY_MODEL_b4109d9bb90c4cfeb5975554137efd55"
     }
    },
    "98274de3ae5d4df79f7208933ffab26d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9da5046952ad44aeab0db1d887b8ea97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aafe707e0cc3469887582205dbc2d686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac4ee4da9fc0423bab18cbc3fadfc469": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad17beeed1994152bc730840cc7f8e73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6025847c5da4135a65ad33026f8c0e0",
      "placeholder": "​",
      "style": "IPY_MODEL_aafe707e0cc3469887582205dbc2d686",
      "value": " 1.43G/1.43G [00:24&lt;00:00, 61.4MB/s]"
     }
    },
    "ad6b4a6fe7b44c4caffc8f163e99f4f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b23c2ea042904a5e8bef6a4abc3c8891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4109d9bb90c4cfeb5975554137efd55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be634c52c2d149f29a62bcbaf20ed24d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c02ef9e5f3bd4909ab082b9073332f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4645b2bda554f63b62517a72061f01c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd2464226a8c4849a12f085b40e328d1",
       "IPY_MODEL_76946f1729db401f9998f7ec2f902304",
       "IPY_MODEL_ad17beeed1994152bc730840cc7f8e73"
      ],
      "layout": "IPY_MODEL_ac4ee4da9fc0423bab18cbc3fadfc469"
     }
    },
    "c48bac8f03d94a108ea66f515aca3274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca8a6c1eddf8448b8f165d68f4f71ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd2464226a8c4849a12f085b40e328d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb680875fa3647a2b9eaee548e0e15e3",
      "placeholder": "​",
      "style": "IPY_MODEL_98274de3ae5d4df79f7208933ffab26d",
      "value": "Downloading: 100%"
     }
    },
    "cd6ad41fbd8e4f4b8227923b80f17f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a3b1f09c5f840d388a7c0cf8e6b780e",
       "IPY_MODEL_6872e1027f3649a194ed29964e2d6c71",
       "IPY_MODEL_6076afddbacb47b4857f8b8382029b32"
      ],
      "layout": "IPY_MODEL_15a4a36006a842cdbd5e693a932479c0"
     }
    },
    "e32c8313e6ce436b93549e3a08ccf413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6025847c5da4135a65ad33026f8c0e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9f8c7f2686c47aebf4972302ba1fc13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad6b4a6fe7b44c4caffc8f163e99f4f8",
      "placeholder": "​",
      "style": "IPY_MODEL_e32c8313e6ce436b93549e3a08ccf413",
      "value": " 456k/456k [00:00&lt;00:00, 1.72MB/s]"
     }
    },
    "ee09b08abe574ef2b52e9e59eaa863de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e0eb396e6034ef0a43ed35f67001f53",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca8a6c1eddf8448b8f165d68f4f71ae4",
      "value": 898823
     }
    },
    "f4d3fe3f09904911b808ee41fda5c0bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be634c52c2d149f29a62bcbaf20ed24d",
      "placeholder": "​",
      "style": "IPY_MODEL_c02ef9e5f3bd4909ab082b9073332f8e",
      "value": "Downloading: 100%"
     }
    },
    "f5b05448c7cd4083b24d205ce0dece39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4d3fe3f09904911b808ee41fda5c0bb",
       "IPY_MODEL_ee09b08abe574ef2b52e9e59eaa863de",
       "IPY_MODEL_85dbc86be7a34db79f89acd16798292e"
      ],
      "layout": "IPY_MODEL_c48bac8f03d94a108ea66f515aca3274"
     }
    },
    "fb680875fa3647a2b9eaee548e0e15e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc83d5f2402243c79363cb1c8d5705cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
