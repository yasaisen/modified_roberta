{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9MXcbCW8f7Eh"
   },
   "source": [
    "### Some Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install transformers\n",
    "# !pip install Scikit-learn\n",
    "# !pip uninstall opencv-python\n",
    "# !pip install opencv-contrib-python\n",
    "# !apt-get update\n",
    "# !apt-get install ffmpeg\n",
    "# !apt-get install libsm6\n",
    "# !apt-get install libxext6\n",
    "# !apt-get install unzip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 22 02:49:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P8    13W /  N/A |     30MiB /  6144MiB |     15%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     10721      G   /usr/lib/xorg/Xorg                 29MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ### for_multi_GPU\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5122,
     "status": "ok",
     "timestamp": 1677512171549,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "CvAFrPlS4bLU",
    "outputId": "2900b98f-10a0-48ae-ae6a-0aff7f787c20"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "# import os\n",
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "S_rtoBGhgSae"
   },
   "source": [
    "### Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30443,
     "status": "ok",
     "timestamp": 1677512201987,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "UKCi74HiH1A9",
    "outputId": "779d592f-9214-477e-c922-233d7845cb7c"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# ROOT_PATH = '/home/yasaisen/Desktop/11_research/11_research_main/lab_05'\n",
    "ROOT_PATH = '/home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1677512201988,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Uh-pffjlIDDw"
   },
   "outputs": [],
   "source": [
    "def checkpath(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2263,
     "status": "ok",
     "timestamp": 1677512204231,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "SRDsG25wIKf-"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "Version = '230312_v0.1.0'\n",
    "\n",
    "root_folder = os.path.abspath(os.path.join(ROOT_PATH, Version))\n",
    "\n",
    "# model_DIR = os.path.abspath(os.path.join(root_folder, 'model'))\n",
    "# checkpath(root_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupVit Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2463,
     "status": "ok",
     "timestamp": 1677512217559,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "1tdXYOBI7W7Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:49:21.547449: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 02:49:21.646813: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-22 02:49:22.042452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yasaisen/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-22 02:49:22.042502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yasaisen/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-22 02:49:22.042506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import collections.abc\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "\n",
    "# from ...activations import ACT2FN\n",
    "from transformers.activations import ACT2FN\n",
    "\n",
    "# from ...modeling_outputs import BaseModelOutput, BaseModelOutputWithPooling\n",
    "from transformers.modeling_outputs import BaseModelOutput, BaseModelOutputWithPooling\n",
    "# from ...modeling_utils import PreTrainedModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "# from ...utils import (\n",
    "#     ModelOutput,\n",
    "#     add_start_docstrings,\n",
    "#     add_start_docstrings_to_model_forward,\n",
    "#     logging,\n",
    "#     replace_return_docstrings,\n",
    "# )\n",
    "from transformers.utils import (\n",
    "    ModelOutput,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "# from .configuration_groupvit import GroupViTConfig, GroupViTTextConfig, GroupViTVisionConfig\n",
    "from transformers.models.groupvit.configuration_groupvit import GroupViTConfig, GroupViTTextConfig #, GroupViTVisionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from typing import TYPE_CHECKING, Any, Mapping, Optional, Union\n",
    "\n",
    "# from ...configuration_utils import PretrainedConfig\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "# from ...onnx import OnnxConfig\n",
    "from transformers.onnx import OnnxConfig\n",
    "# from ...utils import logging\n",
    "from transformers.utils import logging\n",
    "\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    # from ...processing_utils import ProcessorMixin\n",
    "    from transformers.processing_utils import ProcessorMixin\n",
    "    # from ...utils import TensorType\n",
    "    from transformers.utils import TensorType\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "GROUPVIT_PRETRAINED_CONFIG_ARCHIVE_MAP = {\n",
    "    \"nvidia/groupvit-gcc-yfcc\": \"https://huggingface.co/nvidia/groupvit-gcc-yfcc/resolve/main/config.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupViTVisionConfig(PretrainedConfig):\n",
    "    r\"\"\"\n",
    "    This is the configuration class to store the configuration of a [`GroupViTVisionModel`]. It is used to instantiate\n",
    "    an GroupViT model according to the specified arguments, defining the model architecture. Instantiating a\n",
    "    configuration with the defaults will yield a similar configuration to that of the GroupViT\n",
    "    [nvidia/groupvit-gcc-yfcc](https://huggingface.co/nvidia/groupvit-gcc-yfcc) architecture.\n",
    "\n",
    "    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n",
    "    documentation from [`PretrainedConfig`] for more information.\n",
    "\n",
    "    Args:\n",
    "        hidden_size (`int`, *optional*, defaults to 384):\n",
    "            Dimensionality of the encoder layers and the pooler layer.\n",
    "        intermediate_size (`int`, *optional*, defaults to 1536):\n",
    "            Dimensionality of the \"intermediate\" (i.e., feed-forward) layer in the Transformer encoder.\n",
    "        depths (`List[int]`, *optional*, defaults to [6, 3, 3]):\n",
    "            The number of layers in each encoder block.\n",
    "        num_group_tokens (`List[int]`, *optional*, defaults to [64, 8, 0]):\n",
    "            The number of group tokens for each stage.\n",
    "        num_output_groups (`List[int]`, *optional*, defaults to [64, 8, 8]):\n",
    "            The number of output groups for each stage, 0 means no group.\n",
    "        num_attention_heads (`int`, *optional*, defaults to 6):\n",
    "            Number of attention heads for each attention layer in the Transformer encoder.\n",
    "        image_size (`int`, *optional*, defaults to 224):\n",
    "            The size (resolution) of each image.\n",
    "        patch_size (`int`, *optional*, defaults to 16):\n",
    "            The size (resolution) of each patch.\n",
    "        hidden_act (`str` or `function`, *optional*, defaults to `\"gelu\"`):\n",
    "            The non-linear activation function (function or string) in the encoder and pooler. If string, `\"gelu\"`,\n",
    "            `\"relu\"`, `\"selu\"` and `\"gelu_new\"` ``\"quick_gelu\"` are supported.\n",
    "        layer_norm_eps (`float`, *optional*, defaults to 1e-5):\n",
    "            The epsilon used by the layer normalization layers.\n",
    "        dropout (`float`, *optional*, defaults to 0.0):\n",
    "            The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.\n",
    "        attention_dropout (`float`, *optional*, defaults to 0.0):\n",
    "            The dropout ratio for the attention probabilities.\n",
    "        initializer_range (`float`, *optional*, defaults to 0.02):\n",
    "            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
    "        initializer_factor (`float`, *optional*, defaults to 1.0):\n",
    "            A factor for initializing all weight matrices (should be kept to 1, used internally for initialization\n",
    "            testing).\n",
    "\n",
    "    Example:\n",
    "\n",
    "    ```python\n",
    "    >>> from transformers import GroupViTVisionConfig, GroupViTVisionModel\n",
    "\n",
    "    >>> # Initializing a GroupViTVisionModel with nvidia/groupvit-gcc-yfcc style configuration\n",
    "    >>> configuration = GroupViTVisionConfig()\n",
    "\n",
    "    >>> model = GroupViTVisionModel(configuration)\n",
    "\n",
    "    >>> # Accessing the model configuration\n",
    "    >>> configuration = model.config\n",
    "    ```\"\"\"\n",
    "\n",
    "    model_type = \"groupvit_vision_model\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size=384,\n",
    "        intermediate_size=1536,\n",
    "        depths=[6, 3, 3],\n",
    "        num_hidden_layers=12,\n",
    "        num_group_tokens=[64, 8, 0],\n",
    "        num_output_groups=[64, 8, 8],\n",
    "        num_attention_heads=6,\n",
    "        image_size=1024,\n",
    "        patch_size=16,\n",
    "        num_channels=3,\n",
    "        hidden_act=\"gelu\",\n",
    "        layer_norm_eps=1e-5,\n",
    "        dropout=0.0,\n",
    "        attention_dropout=0.0,\n",
    "        initializer_range=0.02,\n",
    "        initializer_factor=1.0,\n",
    "        assign_eps=1.0,\n",
    "        assign_mlp_ratio=[0.5, 4],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.depths = depths\n",
    "        if num_hidden_layers != sum(depths):\n",
    "            logger.warning(\n",
    "                f\"Manually setting num_hidden_layers to {num_hidden_layers}, but we expect num_hidden_layers =\"\n",
    "                f\" sum(depth) = {sum(depths)}\"\n",
    "            )\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_group_tokens = num_group_tokens\n",
    "        self.num_output_groups = num_output_groups\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_channels = num_channels\n",
    "        self.hidden_act = hidden_act\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.dropout = dropout\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.initializer_range = initializer_range\n",
    "        self.initializer_factor = initializer_factor\n",
    "        self.assign_eps = assign_eps\n",
    "        self.assign_mlp_ratio = assign_mlp_ratio\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs) -> \"PretrainedConfig\":\n",
    "        config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
    "\n",
    "        # get the vision config dict if we are loading from GroupViTConfig\n",
    "        if config_dict.get(\"model_type\") == \"groupvit\":\n",
    "            config_dict = config_dict[\"vision_config\"]\n",
    "\n",
    "        if \"model_type\" in config_dict and hasattr(cls, \"model_type\") and config_dict[\"model_type\"] != cls.model_type:\n",
    "            logger.warning(\n",
    "                f\"You are using a model of type {config_dict['model_type']} to instantiate a model of type \"\n",
    "                f\"{cls.model_type}. This is not supported for all configurations of models and can yield errors.\"\n",
    "            )\n",
    "\n",
    "        return cls.from_dict(config_dict, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217559,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "M97ik37v9rbD"
   },
   "outputs": [],
   "source": [
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"nvidia/groupvit-gcc-yfcc\"\n",
    "\n",
    "GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"nvidia/groupvit-gcc-yfcc\",\n",
    "    # See all GroupViT models at https://huggingface.co/models?filter=groupvit\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217560,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "TfjSCoDn9utr"
   },
   "outputs": [],
   "source": [
    "# Copied from transformers.models.bart.modeling_bart._expand_mask\n",
    "def _expand_mask(mask: torch.Tensor, dtype: torch.dtype, tgt_len: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n",
    "    \"\"\"\n",
    "    bsz, src_len = mask.size()\n",
    "    tgt_len = tgt_len if tgt_len is not None else src_len\n",
    "\n",
    "    expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)\n",
    "\n",
    "    inverted_mask = 1.0 - expanded_mask\n",
    "\n",
    "    return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217560,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6PRDe_fu9xoT"
   },
   "outputs": [],
   "source": [
    "# contrastive loss function, adapted from\n",
    "# https://sachinruk.github.io/blog/pytorch/pytorch%20lightning/loss%20function/gpu/2021/03/07/CLIP.html\n",
    "def contrastive_loss(logits: torch.Tensor) -> torch.Tensor:\n",
    "    return nn.functional.cross_entropy(logits, torch.arange(len(logits), device=logits.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217560,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "NTvFTrtG9z1z"
   },
   "outputs": [],
   "source": [
    "# Copied from transformers.models.clip.modeling_clip.clip_loss with clip->groupvit\n",
    "def groupvit_loss(similarity: torch.Tensor) -> torch.Tensor:\n",
    "    caption_loss = contrastive_loss(similarity)\n",
    "    image_loss = contrastive_loss(similarity.t())\n",
    "    return (caption_loss + image_loss) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217560,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "iOvAJP0L91ns"
   },
   "outputs": [],
   "source": [
    "def hard_softmax(logits: torch.Tensor, dim: int):\n",
    "    y_soft = logits.softmax(dim)\n",
    "    # Straight through.\n",
    "    index = y_soft.max(dim, keepdim=True)[1]\n",
    "    y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
    "    ret = y_hard - y_soft.detach() + y_soft\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217560,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "6-b2H_fE93b1"
   },
   "outputs": [],
   "source": [
    "def gumbel_softmax(logits: torch.Tensor, tau: float = 1, hard: bool = False, dim: int = -1) -> torch.Tensor:\n",
    "    # more stable https://github.com/pytorch/pytorch/issues/41663\n",
    "    gumbel_dist = torch.distributions.gumbel.Gumbel(\n",
    "        torch.tensor(0.0, device=logits.device, dtype=logits.dtype),\n",
    "        torch.tensor(1.0, device=logits.device, dtype=logits.dtype),\n",
    "    )\n",
    "    gumbels = gumbel_dist.sample(logits.shape)\n",
    "\n",
    "    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n",
    "    y_soft = gumbels.softmax(dim)\n",
    "\n",
    "    if hard:\n",
    "        # Straight through.\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
    "        ret = y_hard - y_soft.detach() + y_soft\n",
    "    else:\n",
    "        # Reparametrization trick.\n",
    "        ret = y_soft\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217561,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "sh78Xa0q9564"
   },
   "outputs": [],
   "source": [
    "def resize_attention_map(attentions, height, width, align_corners=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        attentions (`torch.Tensor`): attention map of shape [batch_size, groups, feat_height*feat_width]\n",
    "        height (`int`): height of the output attention map\n",
    "        width (`int`): width of the output attention map\n",
    "        align_corners (`bool`, *optional*): the `align_corner` argument for `nn.functional.interpolate`.\n",
    "\n",
    "    Returns:\n",
    "        `torch.Tensor`: resized attention map of shape [batch_size, groups, height, width]\n",
    "    \"\"\"\n",
    "\n",
    "    scale = (height * width // attentions.shape[2]) ** 0.5\n",
    "    if height > width:\n",
    "        feat_width = int(np.round(width / scale))\n",
    "        feat_height = attentions.shape[2] // feat_width\n",
    "    else:\n",
    "        feat_height = int(np.round(height / scale))\n",
    "        feat_width = attentions.shape[2] // feat_height\n",
    "\n",
    "    batch_size = attentions.shape[0]\n",
    "    groups = attentions.shape[1]  # number of group token\n",
    "    # [batch_size, groups, height*width, groups] -> [batch_size, groups, height, width]\n",
    "    attentions = attentions.reshape(batch_size, groups, feat_height, feat_width)\n",
    "    attentions = nn.functional.interpolate(\n",
    "        attentions, size=(height, width), mode=\"bilinear\", align_corners=align_corners\n",
    "    )\n",
    "    return attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217561,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "KyZtU92l98ix"
   },
   "outputs": [],
   "source": [
    "def get_grouping_from_attentions(attentions, hw_shape):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        attentions (`tuple(torch.FloatTensor)`: tuple of attention maps returned by `GroupViTVisionTransformer`\n",
    "        hw_shape (`tuple(int)`): height and width of the output attention map\n",
    "    Returns:\n",
    "        `torch.Tensor`: the attention map of shape [batch_size, groups, height, width]\n",
    "    \"\"\"\n",
    "\n",
    "    attn_maps = []\n",
    "    with torch.no_grad():\n",
    "        prev_attn_masks = None\n",
    "        for attn_masks in attentions:\n",
    "            # [batch_size, num_groups, height x width] -> [batch_size, height x width, num_groups]\n",
    "            attn_masks = attn_masks.permute(0, 2, 1).contiguous()\n",
    "            if prev_attn_masks is None:\n",
    "                prev_attn_masks = attn_masks\n",
    "            else:\n",
    "                prev_attn_masks = prev_attn_masks @ attn_masks\n",
    "            # [batch_size, heightxwidth, num_groups] -> [batch_size, num_groups, heightxwidth] -> [batch_size, num_groups, height, width]\n",
    "            cur_attn_map = resize_attention_map(prev_attn_masks.permute(0, 2, 1).contiguous(), *hw_shape)\n",
    "            attn_maps.append(cur_attn_map)\n",
    "\n",
    "    # [batch_size, num_groups, height, width]\n",
    "    final_grouping = attn_maps[-1]\n",
    "\n",
    "    return final_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217561,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "sX37CrAn9_Mw"
   },
   "outputs": [],
   "source": [
    "class GroupViTCrossAttentionLayer(nn.Module):\n",
    "    def __init__(self, config: GroupViTVisionConfig):\n",
    "        super().__init__()\n",
    "        self.attn = GroupViTAttention(config)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.mlp = GroupViTMLP(config)\n",
    "        self.norm_post = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        # print(query.shape, key.shape)\n",
    "        x = query\n",
    "        x = x + self.attn(query, encoder_hidden_states=key)[0]\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        x = self.norm_post(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217561,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "LfMDcjbu-BFh"
   },
   "outputs": [],
   "source": [
    "class GroupViTAssignAttention(nn.Module):\n",
    "    def __init__(self, config: GroupViTVisionConfig):\n",
    "        super().__init__()\n",
    "        self.scale = config.hidden_size**-0.5\n",
    "\n",
    "        self.q_proj = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.k_proj = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.v_proj = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.proj = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.assign_eps = config.assign_eps\n",
    "\n",
    "    def get_attn(self, attn, gumbel=True, hard=True):\n",
    "        if gumbel and self.training:\n",
    "            attn = gumbel_softmax(attn, dim=-2, hard=hard)\n",
    "        else:\n",
    "            if hard:\n",
    "                attn = hard_softmax(attn, dim=-2)\n",
    "            else:\n",
    "                attn = nn.functional.softmax(attn, dim=-2)\n",
    "\n",
    "        return attn\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        # print(query.shape, key.shape)\n",
    "        value = key\n",
    "        # [batch_size, query_length, channels]\n",
    "        query = self.q_proj(query)\n",
    "\n",
    "        # [batch_size, key_length, channels]\n",
    "        key = self.k_proj(key)\n",
    "\n",
    "        # [batch_size, key_length, channels]\n",
    "        value = self.v_proj(value)\n",
    "\n",
    "        # [batch_size, query_length, key_length]\n",
    "        raw_attn = (query @ key.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        attn = self.get_attn(raw_attn)\n",
    "        soft_attn = self.get_attn(raw_attn, gumbel=False, hard=False)\n",
    "\n",
    "        attn = attn / (attn.sum(dim=-1, keepdim=True) + self.assign_eps)\n",
    "\n",
    "        out = attn @ value\n",
    "\n",
    "        out = self.proj(out)\n",
    "\n",
    "        # print('=', out.shape, soft_attn.shape)\n",
    "\n",
    "        return out, soft_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217562,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "yOJBrOGt-GKD"
   },
   "outputs": [],
   "source": [
    "class GroupViTTokenAssign(nn.Module):\n",
    "    def __init__(self, config: GroupViTVisionConfig, num_group_token, num_output_group):\n",
    "        super().__init__()\n",
    "        self.num_output_group = num_output_group\n",
    "        # norm on group_tokens\n",
    "        self.norm_tokens = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        assign_mlp_ratio = (\n",
    "            config.assign_mlp_ratio\n",
    "            if isinstance(config.assign_mlp_ratio, collections.abc.Iterable)\n",
    "            else (config.assign_mlp_ratio, config.assign_mlp_ratio)\n",
    "        )\n",
    "        tokens_dim, channels_dim = [int(x * config.hidden_size) for x in assign_mlp_ratio]\n",
    "        self.mlp_inter = GroupViTMixerMLP(config, num_group_token, tokens_dim, num_output_group)\n",
    "        self.norm_post_tokens = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        # norm on x\n",
    "        self.norm_x = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.pre_assign_attn = GroupViTCrossAttentionLayer(config)\n",
    "\n",
    "        self.assign = GroupViTAssignAttention(config)\n",
    "        self.norm_new_x = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.mlp_channels = GroupViTMLP(config, config.hidden_size, channels_dim, config.hidden_size)\n",
    "\n",
    "    def project_group_token(self, group_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            group_tokens (torch.Tensor): group tokens, [batch_size, num_group_tokens, channels]\n",
    "\n",
    "        Returns:\n",
    "            projected_group_tokens (torch.Tensor): [batch_size, num_output_groups, channels]\n",
    "        \"\"\"\n",
    "        # [B, num_output_groups, C] <- [B, num_group_tokens, C]\n",
    "        projected_group_tokens = self.mlp_inter(group_tokens)\n",
    "        projected_group_tokens = self.norm_post_tokens(projected_group_tokens)\n",
    "        return projected_group_tokens\n",
    "\n",
    "    def forward(self, image_tokens, group_tokens):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_tokens (`torch.Tensor`): image tokens, of shape [batch_size, input_length, channels]\n",
    "            group_tokens (`torch.Tensor`): group tokens, [batch_size, num_group_tokens, channels]\n",
    "        \"\"\"\n",
    "        # print('all_input', 'image_tokens', image_tokens.shape, 'group_tokens', group_tokens.shape)\n",
    "        # print(' ')\n",
    "        # print('=norm_tokens', 'input', 'group_tokens', group_tokens.shape)\n",
    "        group_tokens = self.norm_tokens(group_tokens)\n",
    "        # print('=norm_tokens', 'output', 'group_tokens', group_tokens.shape)\n",
    "        # print(' ')\n",
    "        # print('=norm_x', 'input', 'image_tokens', image_tokens.shape)\n",
    "        image_tokens = self.norm_x(image_tokens)\n",
    "        # print('=norm_x', 'output', 'image_tokens', image_tokens.shape)\n",
    "        # print(' ')\n",
    "        # [batch_size, num_output_groups, channels]\n",
    "        \n",
    "        # print('=project_group_token', 'input', 'group_tokens', group_tokens.shape)\n",
    "        projected_group_tokens = self.project_group_token(group_tokens)\n",
    "        # print('=project_group_token', 'output', 'projected_group_tokens', projected_group_tokens.shape)\n",
    "        # print(' ')\n",
    "        # print('=pre_assign_attn', 'input', 'projected_group_tokens', projected_group_tokens.shape, 'image_tokens', image_tokens.shape)\n",
    "        projected_group_tokens = self.pre_assign_attn(projected_group_tokens, image_tokens)\n",
    "        # print('=pre_assign_attn', 'output', 'projected_group_tokens', projected_group_tokens.shape)\n",
    "        # print(' ')\n",
    "        # print('=assign', 'input', 'projected_group_tokens', projected_group_tokens.shape, 'image_tokens', image_tokens.shape)\n",
    "        new_image_tokens, attention = self.assign(projected_group_tokens, image_tokens)\n",
    "        # print('=assign', 'output', 'new_image_tokens', new_image_tokens.shape, 'attention', attention.shape)\n",
    "        # print(' ')\n",
    "\n",
    "\n",
    "        # print('= +=', 'input', 'projected_group_tokens', projected_group_tokens.shape)\n",
    "        new_image_tokens += projected_group_tokens\n",
    "        # print('= +=', 'output', 'new_image_tokens', new_image_tokens.shape)\n",
    "        # print(' ')\n",
    "\n",
    "\n",
    "        # print('=norm_new_x', 'input', 'new_image_tokens', new_image_tokens.shape)\n",
    "        # temp = self.norm_new_x(new_image_tokens)\n",
    "        # print('=norm_new_x', 'output', 'temp', temp.shape)\n",
    "        # print(' ')\n",
    "        # print('=mlp_channels', 'input', 'temp', temp.shape)\n",
    "        # temp = self.mlp_channels(temp)\n",
    "        # print('=mlp_channels', 'output', 'temp', temp.shape)\n",
    "        # print(' ')\n",
    "        # print('= +=', 'input', 'temp', temp.shape)\n",
    "        # new_image_tokens = new_image_tokens + temp\n",
    "        # print('= +=', 'output', 'new_image_tokens', new_image_tokens.shape)\n",
    "        # print(' ')\n",
    "        # print('=norm_x', 'input', 'image_tokens', image_tokens.shape)\n",
    "        new_image_tokens = new_image_tokens + self.mlp_channels(self.norm_new_x(new_image_tokens))\n",
    "        # print('=norm_x', 'output', 'image_tokens', image_tokens.shape)\n",
    "        # print(' ')\n",
    "\n",
    "\n",
    "        # print('all_output', 'new_image_tokens', new_image_tokens.shape, 'attention', attention.shape)\n",
    "        return new_image_tokens, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217562,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "1eBLeUct-JCq"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GroupViTModelOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `return_loss` is `True`):\n",
    "            Contrastive loss for image-text similarity.\n",
    "        logits_per_image (`torch.FloatTensor` of shape `(image_batch_size, text_batch_size)`):\n",
    "            The scaled dot product scores between `image_embeds` and `text_embeds`. This represents the image-text\n",
    "            similarity scores.\n",
    "        logits_per_text (`torch.FloatTensor` of shape `(text_batch_size, image_batch_size)`):\n",
    "            The scaled dot product scores between `text_embeds` and `image_embeds`. This represents the text-image\n",
    "            similarity scores.\n",
    "        segmentation_logits (`torch.FloatTensor` of shape `(batch_size, config.num_labels, logits_height, logits_width)`):\n",
    "            Classification scores for each pixel.\n",
    "\n",
    "            <Tip warning={true}>\n",
    "\n",
    "            The logits returned do not necessarily have the same size as the `pixel_values` passed as inputs. This is\n",
    "            to avoid doing two interpolations and lose some quality when a user needs to resize the logits to the\n",
    "            original image size as post-processing. You should always check your logits shape and resize as needed.\n",
    "\n",
    "            </Tip>\n",
    "\n",
    "        text_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):\n",
    "            The text embeddings obtained by applying the projection layer to the pooled output of\n",
    "            [`GroupViTTextModel`].\n",
    "        image_embeds (`torch.FloatTensor` of shape `(batch_size, output_dim`):\n",
    "            The image embeddings obtained by applying the projection layer to the pooled output of\n",
    "            [`GroupViTVisionModel`].\n",
    "        text_model_output (`BaseModelOutputWithPooling`):\n",
    "            The output of the [`GroupViTTextModel`].\n",
    "        vision_model_output (`BaseModelOutputWithPooling`):\n",
    "            The output of the [`GroupViTVisionModel`].\n",
    "    \"\"\"\n",
    "\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits_per_image: torch.FloatTensor = None\n",
    "    logits_per_text: torch.FloatTensor = None\n",
    "    segmentation_logits: torch.FloatTensor = None\n",
    "    text_embeds: torch.FloatTensor = None\n",
    "    image_embeds: torch.FloatTensor = None\n",
    "    text_model_output: BaseModelOutputWithPooling = None\n",
    "    vision_model_output: BaseModelOutputWithPooling = None\n",
    "\n",
    "    def to_tuple(self) -> Tuple[Any]:\n",
    "        return tuple(\n",
    "            self[k] if k not in [\"text_model_output\", \"vision_model_output\"] else getattr(self, k).to_tuple()\n",
    "            for k in self.keys()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217562,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "8atGssmE-OgA"
   },
   "outputs": [],
   "source": [
    "class GroupViTPatchEmbeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Image to Patch Embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size: int = 224,\n",
    "        patch_size: Union[int, Tuple[int, int]] = 16,\n",
    "        num_channels: int = 3,\n",
    "        embed_dim: int = 768,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        image_size = image_size if isinstance(image_size, collections.abc.Iterable) else (image_size, image_size)\n",
    "        patch_size = patch_size if isinstance(patch_size, collections.abc.Iterable) else (patch_size, patch_size)\n",
    "        num_patches = (image_size[1] // patch_size[1]) * (image_size[0] // patch_size[0])\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.projection = nn.Conv2d(num_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = False) -> torch.Tensor:\n",
    "        batch_size, num_channels, height, width = pixel_values.shape\n",
    "        if not interpolate_pos_encoding:\n",
    "            if height != self.image_size[0] or width != self.image_size[1]:\n",
    "                raise ValueError(\n",
    "                    f\"Input image size ({height}*{width}) doesn't match model\"\n",
    "                    f\" ({self.image_size[0]}*{self.image_size[1]}).\"\n",
    "                )\n",
    "        x = self.projection(pixel_values).flatten(2).transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217562,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "pvmCYxCX-Q5x"
   },
   "outputs": [],
   "source": [
    "class GroupViTVisionEmbeddings(nn.Module):\n",
    "    def __init__(self, config: GroupViTVisionConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embeddings = GroupViTPatchEmbeddings(\n",
    "            image_size=config.image_size,\n",
    "            patch_size=config.patch_size,\n",
    "            num_channels=config.num_channels,\n",
    "            embed_dim=config.hidden_size,\n",
    "        )\n",
    "        num_patches = self.patch_embeddings.num_patches\n",
    "        self.position_embeddings = nn.Parameter(torch.zeros(1, num_patches, config.hidden_size))\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.config = config\n",
    "\n",
    "    def interpolate_pos_encoding(self, embeddings: torch.Tensor, height: int, width: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        This method allows to interpolate the pre-trained position encodings, to be able to use the model on higher\n",
    "        resolution images.\n",
    "\n",
    "        Source:\n",
    "        https://github.com/facebookresearch/dino/blob/de9ee3df6cf39fac952ab558447af1fa1365362a/vision_transformer.py#L174\n",
    "        \"\"\"\n",
    "\n",
    "        npatch = embeddings.shape[1]\n",
    "        if npatch == self.position_embeddings.shape[1] and height == width:\n",
    "            return self.position_embeddings\n",
    "        patch_pos_embed = self.position_embeddings\n",
    "        num_original_pos_embed = patch_pos_embed.shape[1]\n",
    "        dim = embeddings.shape[-1]\n",
    "        feat_height = height // self.config.patch_size\n",
    "        feat_width = width // self.config.patch_size\n",
    "        # we add a small number to avoid floating point error in the interpolation\n",
    "        # see discussion at https://github.com/facebookresearch/dino/issues/8\n",
    "        feat_height, feat_width = feat_height + 0.1, feat_width + 0.1\n",
    "        original_height = original_width = math.sqrt(num_original_pos_embed)\n",
    "        reshaped_patch_pos_embed = patch_pos_embed.reshape(1, int(original_height), int(original_width), dim).permute(\n",
    "            0, 3, 1, 2\n",
    "        )\n",
    "        scale_factor = (feat_height / original_height, feat_width / original_width)\n",
    "        patch_pos_embed = nn.functional.interpolate(\n",
    "            reshaped_patch_pos_embed,\n",
    "            scale_factor=scale_factor,\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        patch_pos_embed = patch_pos_embed.permute(0, 2, 3, 1).view(1, -1, dim)\n",
    "        return patch_pos_embed\n",
    "\n",
    "    def forward(self, pixel_values: torch.Tensor, interpolate_pos_encoding: bool = False) -> torch.Tensor:\n",
    "        batch_size, num_channels, height, width = pixel_values.shape\n",
    "\n",
    "        # print('all_input', 'pixel_values', pixel_values.shape, 'interpolate_pos_encoding', interpolate_pos_encoding)\n",
    "        # print()\n",
    "        # print('patch_embeddings', 'input', 'pixel_values', pixel_values.shape, 'interpolate_pos_encoding', interpolate_pos_encoding)\n",
    "        embeddings = self.patch_embeddings(pixel_values, interpolate_pos_encoding=interpolate_pos_encoding)\n",
    "        # print('patch_embeddings', 'output', 'embeddings', embeddings.shape)\n",
    "        # print()\n",
    "        # print('layernorm', 'input', 'embeddings', embeddings.shape)\n",
    "        embeddings = self.layernorm(embeddings)\n",
    "        # print('layernorm', 'output', 'embeddings', embeddings.shape)\n",
    "        # print()\n",
    "        \n",
    "        batch_size, seq_len, _ = embeddings.size()\n",
    "\n",
    "        # add positional encoding to each token\n",
    "        if interpolate_pos_encoding:\n",
    "            # print('+= interpolate_pos_encoding', 'input', 'embeddings', embeddings.shape, 'height', height.shape, 'width', width.shape)\n",
    "            embeddings = embeddings + self.interpolate_pos_encoding(embeddings, height, width)\n",
    "            # print('+= interpolate_pos_encoding', 'output', 'embeddings', embeddings.shape)\n",
    "            # print()\n",
    "        else:\n",
    "            # print('+= position_embeddings', 'input', 'embeddings', embeddings.shape)\n",
    "            embeddings = embeddings + self.position_embeddings\n",
    "        #     print('+= position_embeddings', 'output', 'embeddings', embeddings.shape)\n",
    "        #     print()\n",
    "\n",
    "        # print('dropout', 'input', 'embeddings', embeddings.shape)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        # print('dropout', 'output', 'embeddings', embeddings.shape)\n",
    "        # print()\n",
    "        # print('all_output', 'embeddings', embeddings.shape)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217563,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "jZ_xSDus-ULA"
   },
   "outputs": [],
   "source": [
    "# Copied from transformers.models.clip.modeling_clip.CLIPTextEmbeddings with CLIP->GroupViT\n",
    "class GroupViTTextEmbeddings(nn.Module):\n",
    "    def __init__(self, config: GroupViTTextConfig):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size\n",
    "\n",
    "        self.token_embedding = nn.Embedding(config.vocab_size, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(config.max_position_embeddings, embed_dim)\n",
    "\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        seq_length = input_ids.shape[-1] if input_ids is not None else inputs_embeds.shape[-2]\n",
    "\n",
    "        if position_ids is None:\n",
    "            position_ids = self.position_ids[:, :seq_length]\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.token_embedding(input_ids)\n",
    "\n",
    "        position_embeddings = self.position_embedding(position_ids)\n",
    "        embeddings = inputs_embeds + position_embeddings\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217563,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "WI0LJqF--anN"
   },
   "outputs": [],
   "source": [
    "class GroupViTStage(nn.Module):\n",
    "    \"\"\"This corresponds to the `GroupingLayer` class in the GroupViT implementation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: GroupViTVisionConfig,\n",
    "        depth: int,\n",
    "        num_prev_group_token: int,\n",
    "        num_group_token: int,\n",
    "        num_output_group: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.num_group_token = num_group_token\n",
    "        if num_group_token > 0:\n",
    "            self.group_token = nn.Parameter(torch.zeros(1, num_group_token, config.hidden_size))\n",
    "        else:\n",
    "            self.group_token = None\n",
    "        self.gradient_checkpointing = False\n",
    "        self.layers = nn.ModuleList([GroupViTEncoderLayer(config) for _ in range(depth)])\n",
    "\n",
    "        if num_group_token > 0:\n",
    "            self.downsample = GroupViTTokenAssign(\n",
    "                config=config,\n",
    "                num_group_token=num_group_token,\n",
    "                num_output_group=num_output_group,\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        if num_prev_group_token > 0 and num_group_token > 0:\n",
    "            self.group_projector = nn.Sequential(\n",
    "                nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps),\n",
    "                GroupViTMixerMLP(config, num_prev_group_token, config.hidden_size // 2, num_group_token),\n",
    "            )\n",
    "        else:\n",
    "            self.group_projector = None\n",
    "\n",
    "    @property\n",
    "    def with_group_token(self):\n",
    "        return self.group_token is not None\n",
    "\n",
    "    def split_x(self, x):\n",
    "        if self.with_group_token:\n",
    "            return x[:, : -self.num_group_token], x[:, -self.num_group_token :]\n",
    "        else:\n",
    "            return x, None\n",
    "\n",
    "    def concat_x(self, x: torch.Tensor, group_token: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        if group_token is None:\n",
    "            return x\n",
    "        return torch.cat([x, group_token], dim=1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        prev_group_token: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.FloatTensor]:\n",
    "        print('all_input', 'hidden_states', hidden_states.shape, \n",
    "              'output_attentions', output_attentions)\n",
    "        if prev_group_token != None:\n",
    "            print('prev_group_token', prev_group_token.shape)\n",
    "        else:\n",
    "            print('prev_group_token', prev_group_token)\n",
    "        print()\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
    "            attention_mask (`torch.FloatTensor`): attention mask of size\n",
    "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
    "                `(config.encoder_attention_heads,)`.\n",
    "            output_attentions (`bool`, *optional*):\n",
    "                Whether or not to return the grouping tensors of Grouping block.\n",
    "        \"\"\"\n",
    "        if self.with_group_token:\n",
    "            print('.expand(hidden_states.size(0), -1, -1)', 'input', 'self.group_token', self.group_token.shape)\n",
    "            group_token = self.group_token.expand(hidden_states.size(0), -1, -1)\n",
    "            print('.expand(hidden_states.size(0), -1, -1)', 'output', 'group_token', group_token.shape)\n",
    "            print()\n",
    "            if self.group_projector is not None:\n",
    "                print('self.group_projector', 'input', 'prev_group_token', prev_group_token.shape)\n",
    "                temp = self.group_projector(prev_group_token)\n",
    "                print('self.group_projector', 'output', 'temp', temp.shape)\n",
    "                print()\n",
    "                print('+=', 'input', 'group_token', group_token.shape, 'temp', temp.shape)\n",
    "                group_token = group_token + temp\n",
    "                print('+=', 'output', 'group_token', group_token.shape)\n",
    "                print()\n",
    "        else:\n",
    "            group_token = None\n",
    "            print('group_token = None')\n",
    "            print()\n",
    "\n",
    "        print('=', 'input', 'hidden_states', hidden_states.shape)\n",
    "        x = hidden_states\n",
    "        print('=', 'output', 'x', x.shape)\n",
    "        print()\n",
    "        print('self.concat_x', 'input', 'x', x.shape)\n",
    "        if group_token != None:\n",
    "            print('group_token', group_token.shape)\n",
    "        else:\n",
    "            print('group_token', group_token)\n",
    "        cat_x = self.concat_x(x, group_token)\n",
    "        print('self.concat_x', 'output', 'cat_x', cat_x.shape)\n",
    "        print()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            print('layer', 'input', 'cat_x', cat_x.shape, 'None', 'None')\n",
    "            layer_out = layer(cat_x, attention_mask=None, causal_attention_mask=None)\n",
    "            print('layer', 'output', 'layer_out', layer_out)\n",
    "            print()\n",
    "            print('=', 'input', 'layer_out[0]', layer_out[0].shape)\n",
    "            cat_x = layer_out[0]\n",
    "            print('=', 'output', 'cat_x', cat_x.shape)\n",
    "            print()\n",
    "\n",
    "        print('self.split_x', 'input', 'cat_x', cat_x.shape)\n",
    "        x, group_token = self.split_x(cat_x)\n",
    "        print('self.split_x', 'output', 'x', x.shape)\n",
    "        if group_token != None:\n",
    "            print('group_token', group_token.shape)\n",
    "        else:\n",
    "            print('group_token', group_token)\n",
    "        print()\n",
    "\n",
    "        attention = None\n",
    "        print('attention = None')\n",
    "        print()\n",
    "        if self.downsample is not None:\n",
    "            print('self.downsample', 'input', 'x', x.shape, 'group_token', group_token)\n",
    "            x, attention = self.downsample(x, group_token)\n",
    "            print('self.split_x', 'output', 'x', x.shape, 'attention', attention.shape)\n",
    "            print()\n",
    "\n",
    "        print('=', 'input', 'x', x.shape, 'group_token', group_token)\n",
    "        outputs = (x, group_token)\n",
    "        print('=', 'output', 'outputs', outputs)\n",
    "        print()\n",
    "        if output_attentions:\n",
    "            print('+=', 'input', 'outputs', outputs, 'attention', attention)\n",
    "            outputs = outputs + (attention,)\n",
    "            print('+=', 'output', 'outputs', outputs)\n",
    "            print()\n",
    "        print('all_output', outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217563,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "lZNeThbG-bdS"
   },
   "outputs": [],
   "source": [
    "class GroupViTMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: GroupViTVisionConfig,\n",
    "        hidden_size: Optional[int] = None,\n",
    "        intermediate_size: Optional[int] = None,\n",
    "        output_size: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.activation_fn = ACT2FN[config.hidden_act]\n",
    "        hidden_size = hidden_size if hidden_size is not None else config.hidden_size\n",
    "        intermediate_size = intermediate_size if intermediate_size is not None else config.intermediate_size\n",
    "        output_size = output_size if output_size is not None else hidden_size\n",
    "        self.fc1 = nn.Linear(hidden_size, intermediate_size)\n",
    "        self.fc2 = nn.Linear(intermediate_size, output_size)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.fc1(hidden_states)\n",
    "        hidden_states = self.activation_fn(hidden_states)\n",
    "        hidden_states = self.fc2(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217563,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "F5PfLQe2-dnX"
   },
   "outputs": [],
   "source": [
    "class GroupViTMixerMLP(GroupViTMLP):\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x.transpose(1, 2))\n",
    "        return x.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217564,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "zIDEv8MG-fPE"
   },
   "outputs": [],
   "source": [
    "class GroupViTAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        if self.head_dim * self.num_heads != self.embed_dim:\n",
    "            raise ValueError(\n",
    "                f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`:\"\n",
    "                f\" {self.num_heads}).\"\n",
    "            )\n",
    "        self.scale = self.head_dim**-0.5\n",
    "        self.dropout = config.attention_dropout\n",
    "\n",
    "        self.k_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.v_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.q_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        causal_attention_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n",
    "\n",
    "        bsz, tgt_len, embed_dim = hidden_states.size()\n",
    "        is_cross_attention = encoder_hidden_states is not None\n",
    "\n",
    "        # get query proj\n",
    "        query_states = self.q_proj(hidden_states) * self.scale\n",
    "        if is_cross_attention:\n",
    "            key_states = self._shape(self.k_proj(encoder_hidden_states), -1, bsz)\n",
    "            value_states = self._shape(self.v_proj(encoder_hidden_states), -1, bsz)\n",
    "        else:\n",
    "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
    "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
    "\n",
    "        proj_shape = (bsz * self.num_heads, -1, self.head_dim)\n",
    "        query_states = self._shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
    "        key_states = key_states.view(*proj_shape)\n",
    "        value_states = value_states.view(*proj_shape)\n",
    "\n",
    "        src_len = key_states.size(1)\n",
    "        attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "\n",
    "        if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
    "            raise ValueError(\n",
    "                f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is\"\n",
    "                f\" {attn_weights.size()}\"\n",
    "            )\n",
    "\n",
    "        # apply the causal_attention_mask first\n",
    "        if causal_attention_mask is not None:\n",
    "            if causal_attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
    "                raise ValueError(\n",
    "                    f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is\"\n",
    "                    f\" {causal_attention_mask.size()}\"\n",
    "                )\n",
    "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + causal_attention_mask\n",
    "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
    "                raise ValueError(\n",
    "                    f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"\n",
    "                )\n",
    "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n",
    "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "\n",
    "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        if output_attentions:\n",
    "            # this operation is a bit akward, but it's required to\n",
    "            # make sure that attn_weights keeps its gradient.\n",
    "            # In order to do so, attn_weights have to reshaped\n",
    "            # twice and have to be reused in the following\n",
    "            attn_weights_reshaped = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
    "            attn_weights = attn_weights_reshaped.view(bsz * self.num_heads, tgt_len, src_len)\n",
    "        else:\n",
    "            attn_weights_reshaped = None\n",
    "\n",
    "        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        attn_output = torch.bmm(attn_probs, value_states)\n",
    "\n",
    "        if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
    "            raise ValueError(\n",
    "                f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is\"\n",
    "                f\" {attn_output.size()}\"\n",
    "            )\n",
    "\n",
    "        attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim)\n",
    "        attn_output = attn_output.transpose(1, 2)\n",
    "        attn_output = attn_output.reshape(bsz, tgt_len, embed_dim)\n",
    "\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        return attn_output, attn_weights_reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217564,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "MxxVauJA-ioM"
   },
   "outputs": [],
   "source": [
    "# Copied from transformers.models.clip.modeling_clip.CLIPEncoderLayer with CLIP->GroupViT\n",
    "class GroupViTEncoderLayer(nn.Module):\n",
    "    def __init__(self, config: GroupViTConfig):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.self_attn = GroupViTAttention(config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_eps)\n",
    "        self.mlp = GroupViTMLP(config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        causal_attention_mask: torch.Tensor,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.FloatTensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
    "            attention_mask (`torch.FloatTensor`): attention mask of size\n",
    "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
    "                `(config.encoder_attention_heads,)`.\n",
    "            output_attentions (`bool`, *optional*):\n",
    "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
    "                returned tensors for more detail.\n",
    "        \"\"\"\n",
    "        # print('hidden_states_input', hidden_states.shape)\n",
    "        residual = hidden_states\n",
    "\n",
    "        hidden_states = self.layer_norm1(hidden_states)\n",
    "        hidden_states, attn_weights = self.self_attn(\n",
    "            hidden_states=hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            causal_attention_mask=causal_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.layer_norm2(hidden_states)\n",
    "        hidden_states = self.mlp(hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "\n",
    "        if output_attentions:\n",
    "            outputs += (attn_weights,)\n",
    "        # print('hidden_states_output', hidden_states.shape)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217564,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "iFAIWiAZ-k9h"
   },
   "outputs": [],
   "source": [
    "class GroupViTPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
    "    models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = GroupViTConfig\n",
    "    base_model_prefix = \"groupvit\"\n",
    "    supports_gradient_checkpointing = True\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize the weights\"\"\"\n",
    "\n",
    "        init_range = self.config.initializer_range\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=init_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "        factor = self.config.initializer_factor\n",
    "        if isinstance(module, GroupViTTextEmbeddings):\n",
    "            module.token_embedding.weight.data.normal_(mean=0.0, std=factor * 0.02)\n",
    "            module.position_embedding.weight.data.normal_(mean=0.0, std=factor * 0.02)\n",
    "        elif isinstance(module, GroupViTAttention):\n",
    "            factor = self.config.initializer_factor\n",
    "            in_proj_std = (module.embed_dim**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n",
    "            out_proj_std = (module.embed_dim**-0.5) * factor\n",
    "            nn.init.normal_(module.q_proj.weight, std=in_proj_std)\n",
    "            nn.init.normal_(module.k_proj.weight, std=in_proj_std)\n",
    "            nn.init.normal_(module.v_proj.weight, std=in_proj_std)\n",
    "            nn.init.normal_(module.out_proj.weight, std=out_proj_std)\n",
    "        elif isinstance(module, GroupViTMLP):\n",
    "            factor = self.config.initializer_factor\n",
    "            in_proj_std = (\n",
    "                (module.config.hidden_size**-0.5) * ((2 * module.config.num_hidden_layers) ** -0.5) * factor\n",
    "            )\n",
    "            fc_std = (2 * module.config.hidden_size) ** -0.5 * factor\n",
    "            nn.init.normal_(module.fc1.weight, std=fc_std)\n",
    "            nn.init.normal_(module.fc2.weight, std=in_proj_std)\n",
    "\n",
    "    def _set_gradient_checkpointing(self, module, value=False):\n",
    "        if isinstance(module, (GroupViTTextEncoder, GroupViTVisionEncoder)):\n",
    "            module.gradient_checkpointing = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217564,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "jzru1jUe-wAJ"
   },
   "outputs": [],
   "source": [
    "GROUPVIT_START_DOCSTRING = r\"\"\"\n",
    "    This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass. Use it\n",
    "    as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and\n",
    "    behavior.\n",
    "\n",
    "    Parameters:\n",
    "        config ([`GroupViTConfig`]): Model configuration class with all the parameters of the model.\n",
    "            Initializing with a config file does not load the weights associated with the model, only the\n",
    "            configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
    "\"\"\"\n",
    "\n",
    "GROUPVIT_TEXT_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
    "            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide\n",
    "            it.\n",
    "\n",
    "            Indices can be obtained using [`CLIPTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\"\n",
    "\n",
    "GROUPVIT_VISION_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
    "            Pixel values. Padding will be ignored by default should you provide it. Pixel values can be obtained using\n",
    "            [`AutoImageProcessor`]. See [`CLIPImageProcessor.__call__`] for details.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\"\n",
    "\n",
    "GROUPVIT_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
    "            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide\n",
    "            it.\n",
    "\n",
    "            Indices can be obtained using [`CLIPTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n",
    "            Pixel values. Pixel values can be obtained using [`AutoImageProcessor`]. See\n",
    "            [`CLIPImageProcessor.__call__`] for details.\n",
    "        return_loss (`bool`, *optional*):\n",
    "            Whether or not to return the contrastive loss.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217564,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "diwTOUkc-yuM"
   },
   "outputs": [],
   "source": [
    "class GroupViTVisionEncoder(nn.Module):\n",
    "    def __init__(self, config: GroupViTVisionConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.stages = nn.ModuleList(\n",
    "            [\n",
    "                GroupViTStage(\n",
    "                    config=config,\n",
    "                    depth=config.depths[i],\n",
    "                    num_group_token=config.num_group_tokens[i],\n",
    "                    num_output_group=config.num_output_groups[i],\n",
    "                    num_prev_group_token=config.num_output_groups[i - 1] if i > 0 else 0,\n",
    "                )\n",
    "                for i in range(len(config.depths))\n",
    "            ]\n",
    "        )\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[tuple, BaseModelOutput]:\n",
    "        # print('all_input', 'hidden_states', hidden_states.shape, \n",
    "        #       'output_hidden_states', output_hidden_states, \n",
    "        #       'output_attentions', output_attentions, \n",
    "        #       'return_dict', return_dict)\n",
    "        # print()\n",
    "\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_groupings = () if output_attentions else None\n",
    "\n",
    "        group_tokens = None\n",
    "        # print('first_input', 'output_attentions', output_attentions, \n",
    "        #       'output_hidden_states', output_hidden_states, \n",
    "        #       'return_dict', return_dict, \n",
    "        #       'all_hidden_states', all_hidden_states,\n",
    "        #       'all_groupings', all_groupings,\n",
    "        #       'group_tokens', group_tokens)\n",
    "        # print()\n",
    "\n",
    "        for i, stage in enumerate(self.stages):\n",
    "            if output_hidden_states:\n",
    "                # print('+=', 'input', 'all_hidden_states', all_hidden_states.shape, 'hidden_states', hidden_states.shape)\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "                # print('+=', 'output', 'all_hidden_states', all_hidden_states.shape)\n",
    "                # print()\n",
    "\n",
    "            # print('stage', 'input', 'hidden_states', hidden_states.shape, 'group_tokens', group_tokens, 'output_attentions', output_attentions)\n",
    "            layer_outputs = stage(hidden_states, group_tokens, output_attentions)\n",
    "            # print('stage', 'output', 'layer_outputs', layer_outputs)\n",
    "            # print()\n",
    "\n",
    "            # print('=', 'input', 'layer_outputs[0]', layer_outputs[0].shape)\n",
    "            hidden_states = layer_outputs[0]\n",
    "            # print('=', 'output', 'hidden_states', hidden_states.shape)\n",
    "            # print()\n",
    "            # print('=', 'input', 'layer_outputs[1]', layer_outputs[1])\n",
    "            group_tokens = layer_outputs[1]\n",
    "            # print('=', 'output', 'group_tokens', group_tokens)\n",
    "            # print()\n",
    "\n",
    "            if output_attentions and layer_outputs[2] is not None:\n",
    "                # print('+=', 'input', 'all_groupings', all_groupings, 'layer_outputs[2]', layer_outputs[2].shape)\n",
    "                all_groupings = all_groupings + (layer_outputs[2],)\n",
    "                # print('+=', 'output', 'all_groupings', all_groupings)\n",
    "                # print()\n",
    "\n",
    "        if output_hidden_states:\n",
    "            # print('+=', 'input', 'all_hidden_states', all_hidden_states.shape, 'hidden_states', hidden_states.shape)\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "            # print('+=', 'output', 'all_hidden_states', all_hidden_states.shape)\n",
    "            # print()\n",
    "\n",
    "        if not return_dict:\n",
    "            # print('all_output', 'if not return_dict', \n",
    "            #       'hidden_states', hidden_states.shape, \n",
    "            #       'all_hidden_states', all_hidden_states.shape, \n",
    "            #       'all_groupings', all_groupings)\n",
    "            temp = tuple(v for v in [hidden_states, all_hidden_states, all_groupings] if v is not None)\n",
    "\n",
    "            return temp\n",
    "        \n",
    "        # print('BaseModelOutput', 'input', \n",
    "                #   'hidden_states', hidden_states, \n",
    "                #   'all_hidden_states', all_hidden_states, \n",
    "                #   'all_groupings', all_groupings)\n",
    "        temp = BaseModelOutput(\n",
    "            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_groupings\n",
    "        )\n",
    "        # print('BaseModelOutput', 'output', 'temp', temp)\n",
    "        # print()\n",
    "        # print('all_output', 'temp', temp)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677512217565,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "ErgnsQgL-zvh"
   },
   "outputs": [],
   "source": [
    "class GroupViTTextEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer encoder consisting of `config.num_hidden_layers` self-attention layers. Each layer is a\n",
    "    [`GroupViTEncoderLayer`].\n",
    "\n",
    "    Args:\n",
    "        config: GroupViTTextConfig\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: GroupViTTextConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layers = nn.ModuleList([GroupViTEncoderLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        inputs_embeds,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        causal_attention_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutput]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n",
    "                Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.\n",
    "                This is useful if you want more control over how to convert `input_ids` indices into associated vectors\n",
    "                than the model's internal embedding lookup matrix.\n",
    "            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "                - 1 for tokens that are **not masked**,\n",
    "                - 0 for tokens that are **masked**.\n",
    "\n",
    "                [What are attention masks?](../glossary#attention-mask)\n",
    "            causal_attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "                Causal mask for the text model. Mask values selected in `[0, 1]`:\n",
    "\n",
    "                - 1 for tokens that are **not masked**,\n",
    "                - 0 for tokens that are **masked**.\n",
    "\n",
    "                [What are attention masks?](../glossary#attention-mask)\n",
    "            output_attentions (`bool`, *optional*):\n",
    "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
    "                returned tensors for more detail.\n",
    "            output_hidden_states (`bool`, *optional*):\n",
    "                Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n",
    "                for more detail.\n",
    "            return_dict (`bool`, *optional*):\n",
    "                Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        encoder_states = () if output_hidden_states else None\n",
    "        all_attentions = () if output_attentions else None\n",
    "\n",
    "        hidden_states = inputs_embeds\n",
    "        for idx, encoder_layer in enumerate(self.layers):\n",
    "            if output_hidden_states:\n",
    "                encoder_states = encoder_states + (hidden_states,)\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(encoder_layer),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    causal_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = encoder_layer(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    causal_attention_mask,\n",
    "                    output_attentions=output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[1],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            encoder_states = encoder_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_states, encoder_states, all_attentions] if v is not None)\n",
    "        return BaseModelOutput(\n",
    "            last_hidden_state=hidden_states, hidden_states=encoder_states, attentions=all_attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1677512217566,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "fsgeLvGW_gB0"
   },
   "outputs": [],
   "source": [
    "# Copied from transformers.models.clip.modeling_clip.CLIPTextTransformer with CLIPText->GroupViTText, CLIPEncoder->GroupViTTextEncoder, CLIP_TEXT->GROUPVIT_TEXT\n",
    "class GroupViTTextTransformer(nn.Module):\n",
    "    def __init__(self, config: GroupViTTextConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        embed_dim = config.hidden_size\n",
    "        self.embeddings = GroupViTTextEmbeddings(config)\n",
    "        self.encoder = GroupViTTextEncoder(config)\n",
    "        self.final_layer_norm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(GROUPVIT_TEXT_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTTextConfig)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPooling]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if input_ids is None:\n",
    "            raise ValueError(\"You have to specify input_ids\")\n",
    "\n",
    "        input_shape = input_ids.size()\n",
    "        input_ids = input_ids.view(-1, input_shape[-1])\n",
    "\n",
    "        hidden_states = self.embeddings(input_ids=input_ids, position_ids=position_ids)\n",
    "\n",
    "        bsz, seq_len = input_shape\n",
    "        # CLIP's text model uses causal mask, prepare it here.\n",
    "        # https://github.com/openai/CLIP/blob/cfcffb90e69f37bf2ff1e988237a0fbe41f33c04/clip/model.py#L324\n",
    "        causal_attention_mask = self._build_causal_attention_mask(bsz, seq_len, hidden_states.dtype).to(\n",
    "            hidden_states.device\n",
    "        )\n",
    "        # expand attention_mask\n",
    "        if attention_mask is not None:\n",
    "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
    "            attention_mask = _expand_mask(attention_mask, hidden_states.dtype)\n",
    "\n",
    "        encoder_outputs = self.encoder(\n",
    "            inputs_embeds=hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            causal_attention_mask=causal_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        last_hidden_state = encoder_outputs[0]\n",
    "        last_hidden_state = self.final_layer_norm(last_hidden_state)\n",
    "\n",
    "        # text_embeds.shape = [batch_size, sequence_length, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        # casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14\n",
    "        pooled_output = last_hidden_state[\n",
    "            torch.arange(last_hidden_state.shape[0], device=last_hidden_state.device),\n",
    "            input_ids.to(dtype=torch.int, device=last_hidden_state.device).argmax(dim=-1),\n",
    "        ]\n",
    "\n",
    "        if not return_dict:\n",
    "            return (last_hidden_state, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            last_hidden_state=last_hidden_state,\n",
    "            pooler_output=pooled_output,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def _build_causal_attention_mask(self, bsz, seq_len, dtype):\n",
    "        # lazily create causal attention mask, with full attention between the vision tokens\n",
    "        # pytorch uses additive attention mask; fill with -inf\n",
    "        mask = torch.empty(bsz, seq_len, seq_len, dtype=dtype)\n",
    "        mask.fill_(torch.tensor(torch.finfo(dtype).min))\n",
    "        mask.triu_(1)  # zero out the lower diagonal\n",
    "        mask = mask.unsqueeze(1)  # expand mask\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1677512218961,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "QAAhPken_ibc"
   },
   "outputs": [],
   "source": [
    "class GroupViTTextModel(GroupViTPreTrainedModel):\n",
    "    config_class = GroupViTTextConfig\n",
    "\n",
    "    def __init__(self, config: GroupViTTextConfig):\n",
    "        super().__init__(config)\n",
    "        self.text_model = GroupViTTextTransformer(config)\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self) -> nn.Module:\n",
    "        return self.text_model.embeddings.token_embedding\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.text_model.embeddings.token_embedding = value\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(GROUPVIT_TEXT_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTTextConfig)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPooling]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from transformers import CLIPTokenizer, GroupViTTextModel\n",
    "\n",
    "        >>> tokenizer = CLIPTokenizer.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "        >>> model = GroupViTTextModel.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "        >>> inputs = tokenizer([\"a photo of a cat\", \"a photo of a dog\"], padding=True, return_tensors=\"pt\")\n",
    "\n",
    "        >>> outputs = model(**inputs)\n",
    "        >>> last_hidden_state = outputs.last_hidden_state\n",
    "        >>> pooled_output = outputs.pooler_output  # pooled (EOS token) states\n",
    "        ```\"\"\"\n",
    "        return self.text_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677512218961,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "pNJ4HozD_ls2"
   },
   "outputs": [],
   "source": [
    "class GroupViTVisionTransformer(nn.Module):########################\n",
    "    def __init__(self, config: GroupViTVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        embed_dim = config.hidden_size\n",
    "\n",
    "        self.embeddings = GroupViTVisionEmbeddings(config)\n",
    "        self.encoder = GroupViTVisionEncoder(config)\n",
    "        self.layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTVisionConfig)\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPooling]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if pixel_values is None:\n",
    "            raise ValueError(\"You have to specify pixel_values\")\n",
    "\n",
    "        hidden_states = self.embeddings(pixel_values)\n",
    "\n",
    "        encoder_outputs = self.encoder(\n",
    "            hidden_states=hidden_states,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            output_attentions=output_attentions,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        last_hidden_state = encoder_outputs[0]\n",
    "\n",
    "        # normalize the last hidden state\n",
    "        last_hidden_state = self.layernorm(last_hidden_state)\n",
    "        pooled_output = last_hidden_state.mean(dim=1)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (last_hidden_state, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPooling(\n",
    "            last_hidden_state=last_hidden_state,\n",
    "            pooler_output=pooled_output,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677512218961,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Tf5zCFfp_pS0"
   },
   "outputs": [],
   "source": [
    "class GroupViTVisionModel(GroupViTPreTrainedModel):\n",
    "    config_class = GroupViTVisionConfig\n",
    "    main_input_name = \"pixel_values\"\n",
    "\n",
    "    def __init__(self, config: GroupViTVisionConfig, projection_dim=128):\n",
    "        super().__init__(config)\n",
    "        self.vision_model = GroupViTVisionTransformer(config)\n",
    "\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection_intermediate_dim = 4096\n",
    "        self.vision_embed_dim = config.hidden_size\n",
    "\n",
    "        self.visual_projection = nn.Sequential(\n",
    "            nn.Linear(self.vision_embed_dim, self.projection_intermediate_dim, bias=True),\n",
    "            nn.BatchNorm1d(self.projection_intermediate_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.projection_intermediate_dim, self.projection_dim, bias=True),\n",
    "        )\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self) -> GroupViTPatchEmbeddings:\n",
    "        return self.vision_model.embeddings.patch_embeddings\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTVisionConfig)\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPooling]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from PIL import Image\n",
    "        >>> import requests\n",
    "        >>> from transformers import AutoProcessor, GroupViTVisionModel\n",
    "\n",
    "        >>> processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "        >>> model = GroupViTVisionModel.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "        >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "        >>> image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "        >>> inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "        >>> outputs = model(**inputs)\n",
    "        >>> last_hidden_state = outputs.last_hidden_state\n",
    "        >>> pooled_output = outputs.pooler_output  # pooled CLS states\n",
    "        ```\"\"\"\n",
    "\n",
    "        # print(type(pixel_values), type(output_attentions), type(output_hidden_states), type(return_dict))\n",
    "        # print(pixel_values.shape, output_attentions, output_hidden_states, return_dict)\n",
    "        # print('pixel_values=', pixel_values.shape)\n",
    "        output_attentions = True\n",
    "        output_hidden_states = False\n",
    "        return_dict = True\n",
    "        # print(pixel_values.shape, output_attentions, output_hidden_states, return_dict)\n",
    "        vision_outputs = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        # print(vision_outputs)\n",
    "\n",
    "        attentions = vision_outputs[2]\n",
    "            \n",
    "        # [batch_size_image, num_group, height, width]\n",
    "        grouping = get_grouping_from_attentions(attentions, pixel_values.shape[2:])\n",
    "        seg_logits = grouping\n",
    "\n",
    "        pooled_output = vision_outputs[1]  # pooled_output\n",
    "        image_features = self.visual_projection(pooled_output)\n",
    "\n",
    "        # print(image_features.shape)\n",
    "        return vision_outputs, seg_logits, image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677512218962,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "Q3lIeXoH_slB"
   },
   "outputs": [],
   "source": [
    "@add_start_docstrings(GROUPVIT_START_DOCSTRING)\n",
    "class GroupViTModel(GroupViTPreTrainedModel):\n",
    "    config_class = GroupViTConfig\n",
    "\n",
    "    def __init__(self, config: GroupViTConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # if not isinstance(config.text_config, GroupViTTextConfig):\n",
    "        #     raise ValueError(\n",
    "        #         \"config.text_config is expected to be of type GroupViTTextConfig but is of type\"\n",
    "        #         f\" {type(config.text_config)}.\"\n",
    "        #     )\n",
    "\n",
    "        if not isinstance(config.vision_config, GroupViTVisionConfig):\n",
    "            raise ValueError(\n",
    "                \"config.vision_config is expected to be of type GroupViTVisionConfig but is of type\"\n",
    "                f\" {type(config.vision_config)}.\"\n",
    "            )\n",
    "\n",
    "        # text_config = config.text_config\n",
    "        vision_config = config.vision_config\n",
    "\n",
    "        self.projection_dim = config.projection_dim\n",
    "        self.projection_intermediate_dim = config.projection_intermediate_dim\n",
    "        # self.text_embed_dim = text_config.hidden_size\n",
    "        self.vision_embed_dim = vision_config.hidden_size\n",
    "        # print('hidden_size', vision_config.hidden_size)\n",
    "\n",
    "        # self.text_model = GroupViTTextTransformer(text_config)\n",
    "        self.vision_model = GroupViTVisionTransformer(vision_config)\n",
    "\n",
    "        self.visual_projection = nn.Sequential(\n",
    "            nn.Linear(self.vision_embed_dim, self.projection_intermediate_dim, bias=True),\n",
    "            nn.BatchNorm1d(self.projection_intermediate_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.projection_intermediate_dim, self.projection_dim, bias=True),\n",
    "        )\n",
    "        # self.text_projection = nn.Sequential(\n",
    "        #     nn.Linear(self.text_embed_dim, self.projection_intermediate_dim, bias=True),\n",
    "        #     nn.BatchNorm1d(self.projection_intermediate_dim),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(self.projection_intermediate_dim, self.projection_dim, bias=True),\n",
    "        # )\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * self.config.logit_scale_init_value)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    # @add_start_docstrings_to_model_forward(GROUPVIT_TEXT_INPUTS_DOCSTRING)\n",
    "    # def get_text_features(\n",
    "    #     self,\n",
    "    #     input_ids: Optional[torch.Tensor] = None,\n",
    "    #     attention_mask: Optional[torch.Tensor] = None,\n",
    "    #     position_ids: Optional[torch.Tensor] = None,\n",
    "    #     output_attentions: Optional[bool] = None,\n",
    "    #     output_hidden_states: Optional[bool] = None,\n",
    "    #     return_dict: Optional[bool] = None,\n",
    "    # ) -> torch.FloatTensor:\n",
    "    #     r\"\"\"\n",
    "    #     Returns:\n",
    "    #         text_features (`torch.FloatTensor` of shape `(batch_size, output_dim`): The text embeddings obtained by\n",
    "    #         applying the projection layer to the pooled output of [`GroupViTTextModel`].\n",
    "\n",
    "    #     Examples:\n",
    "\n",
    "    #     ```python\n",
    "    #     >>> from transformers import CLIPTokenizer, GroupViTModel\n",
    "\n",
    "    #     >>> model = GroupViTModel.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "    #     >>> tokenizer = CLIPTokenizer.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "    #     >>> inputs = tokenizer([\"a photo of a cat\", \"a photo of a dog\"], padding=True, return_tensors=\"pt\")\n",
    "    #     >>> text_features = model.get_text_features(**inputs)\n",
    "    #     ```\"\"\"\n",
    "    #     # Use GROUPVIT model's config for some fields (if specified) instead of those of vision & text components.\n",
    "    #     output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "    #     output_hidden_states = (\n",
    "    #         output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "    #     )\n",
    "    #     return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "    #     text_outputs = self.text_model(\n",
    "    #         input_ids=input_ids,\n",
    "    #         attention_mask=attention_mask,\n",
    "    #         position_ids=position_ids,\n",
    "    #         output_attentions=output_attentions,\n",
    "    #         output_hidden_states=output_hidden_states,\n",
    "    #         return_dict=return_dict,\n",
    "    #     )\n",
    "\n",
    "    #     pooled_output = text_outputs[1]\n",
    "    #     text_features = self.text_projection(pooled_output)\n",
    "\n",
    "    #     return text_features\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)\n",
    "    def get_image_features(\n",
    "        self,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "            image_features (`torch.FloatTensor` of shape `(batch_size, output_dim`): The image embeddings obtained by\n",
    "            applying the projection layer to the pooled output of [`GroupViTVisionModel`].\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from PIL import Image\n",
    "        >>> import requests\n",
    "        >>> from transformers import AutoProcessor, GroupViTModel\n",
    "\n",
    "        >>> model = GroupViTModel.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "        >>> processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "        >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "        >>> image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "        >>> inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "        >>> image_features = model.get_image_features(**inputs)\n",
    "        ```\"\"\"\n",
    "        # Use GROUPVIT model's config for some fields (if specified) instead of those of vision & text components.\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        print(pixel_values.shape, output_attentions, output_hidden_states, return_dict)\n",
    "\n",
    "        vision_outputs = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = vision_outputs[1]  # pooled_output\n",
    "        print('01 ', pooled_output.shape)\n",
    "\n",
    "        image_features = self.visual_projection(pooled_output)\n",
    "        print('02 ', image_features.shape)\n",
    "\n",
    "        return image_features\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(GROUPVIT_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=GroupViTModelOutput, config_class=GroupViTConfig)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        pixel_values: Optional[torch.FloatTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        return_loss: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_segmentation: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, GroupViTModelOutput]:\n",
    "        r\"\"\"\n",
    "        Returns:\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from PIL import Image\n",
    "        >>> import requests\n",
    "        >>> from transformers import AutoProcessor, GroupViTModel\n",
    "\n",
    "        >>> model = GroupViTModel.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "        >>> processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "        >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "        >>> image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "        >>> inputs = processor(\n",
    "        ...     text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True\n",
    "        ... )\n",
    "\n",
    "        >>> outputs = model(**inputs)\n",
    "        >>> logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "        >>> probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "        ```\"\"\"\n",
    "        # Use GROUPVIT model's config for some fields (if specified) instead of those of vision & text components.\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_segmentation = (\n",
    "            output_segmentation if output_segmentation is not None else self.config.output_segmentation\n",
    "        )\n",
    "        if output_segmentation:\n",
    "            output_attentions = True\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # print(type(pixel_values), type(output_attentions), type(output_hidden_states), type(return_dict))\n",
    "        print(pixel_values.shape, output_attentions, output_hidden_states, return_dict)\n",
    "\n",
    "        vision_outputs = self.vision_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        # print(vision_outputs)\n",
    "\n",
    "        # text_outputs = self.text_model(\n",
    "        #     input_ids=input_ids,\n",
    "        #     attention_mask=attention_mask,\n",
    "        #     position_ids=position_ids,\n",
    "        #     output_attentions=output_attentions,\n",
    "        #     output_hidden_states=output_hidden_states,\n",
    "        #     return_dict=return_dict,\n",
    "        # )\n",
    "\n",
    "        image_embeds = vision_outputs[1]\n",
    "        image_embeds = self.visual_projection(image_embeds)\n",
    "\n",
    "        # text_embeds = text_outputs[1]\n",
    "        # text_embeds = self.text_projection(text_embeds)\n",
    "\n",
    "        # normalized features\n",
    "        image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)\n",
    "        # text_embeds = text_embeds / text_embeds.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        # logit_scale = self.logit_scale.exp()\n",
    "        # logits_per_text = torch.matmul(text_embeds, image_embeds.t()) * logit_scale\n",
    "        # logits_per_image = logits_per_text.t()\n",
    "\n",
    "        seg_logits = None\n",
    "        if output_segmentation:\n",
    "            # grouped features\n",
    "            # [batch_size_image, num_group, hidden_size]\n",
    "            image_group_embeds = vision_outputs[0]\n",
    "            print('image_group_embeds_01', image_group_embeds.shape, type(image_group_embeds)) # torch.Size([1, 8, 384]) <class 'torch.Tensor'>\n",
    "\n",
    "            # [batch_size_image*num_group, hidden_size]\n",
    "            image_group_embeds = self.visual_projection(image_group_embeds.reshape(-1, image_group_embeds.shape[-1]))\n",
    "            print('image_group_embeds_02', image_group_embeds.shape, type(image_group_embeds)) # torch.Size([8, 256]) <class 'torch.Tensor'>\n",
    "\n",
    "            if output_hidden_states:\n",
    "                attentions = vision_outputs[3]\n",
    "                print('attentions_01', attentions.shape, type(attentions)) # *\n",
    "\n",
    "            else:\n",
    "                attentions = vision_outputs[2]\n",
    "                print('attentions_02', attentions[0].shape, type(attentions[0]), attentions[1].shape, type(attentions[1])) # torch.Size([1, 64, 196]) torch.Size([1, 8, 64]) <class 'torch.Tensor'>\n",
    "                \n",
    "            # [batch_size_image, num_group, height, width]\n",
    "            grouping = get_grouping_from_attentions(attentions, pixel_values.shape[2:])\n",
    "            print(pixel_values.shape)\n",
    "            print(pixel_values.shape[2:])\n",
    "            print('grouping_01', grouping.shape, type(grouping)) # torch.Size([1, 8, 224, 224]) <class 'torch.Tensor'>\n",
    "            seg_logits = grouping\n",
    "\n",
    "            # # normalized features\n",
    "            # image_group_embeds = image_group_embeds / image_group_embeds.norm(dim=-1, keepdim=True)\n",
    "            # print('image_group_embeds_03', image_group_embeds.shape, type(image_group_embeds)) # torch.Size([8, 256]) <class 'torch.Tensor'>\n",
    "\n",
    "            # # [batch_size_image x num_group, batch_size_text]\n",
    "            # logits_per_image_group = torch.matmul(image_group_embeds, text_embeds.t()) * logit_scale\n",
    "            # print('logits_per_image_group_01', logits_per_image_group.shape, type(logits_per_image_group)) # torch.Size([8, 3]) <class 'torch.Tensor'>\n",
    "\n",
    "            # # [batch_size_image, batch_size_text, num_group]\n",
    "            # logits_per_image_group = logits_per_image_group.reshape(\n",
    "            #     image_embeds.shape[0], -1, text_embeds.shape[0]\n",
    "            # ).permute(0, 2, 1)\n",
    "            # print('logits_per_image_group_02', logits_per_image_group.shape, type(logits_per_image_group)) # torch.Size([1, 3, 8]) <class 'torch.Tensor'>\n",
    "\n",
    "\n",
    "            # # [batch_size_image, batch_size_text, height x width]\n",
    "            # flatten_grouping = grouping.reshape(grouping.shape[0], grouping.shape[1], -1)\n",
    "            # print('flatten_grouping_01', flatten_grouping.shape, type(flatten_grouping)) # torch.Size([1, 8, 50176]) <class 'torch.Tensor'>\n",
    "\n",
    "\n",
    "            # # [batch_size_image, batch_size_text, height, width]\n",
    "            # seg_logits = torch.matmul(logits_per_image_group, flatten_grouping) * logit_scale\n",
    "            # print('seg_logits_01', seg_logits.shape, type(seg_logits)) # torch.Size([1, 3, 50176]) <class 'torch.Tensor'>\n",
    "\n",
    "            # seg_logits = seg_logits.reshape(\n",
    "            #     seg_logits.shape[0], seg_logits.shape[1], grouping.shape[2], grouping.shape[3]\n",
    "            # )\n",
    "            # print('seg_logits_02', seg_logits.shape, type(seg_logits)) # torch.Size([1, 3, 224, 224]) <class 'torch.Tensor'>\n",
    "\n",
    "        loss = None\n",
    "        if return_loss:\n",
    "            loss = groupvit_loss(logits_per_text)\n",
    "\n",
    "        if not return_dict:\n",
    "            if seg_logits is not None:\n",
    "                output = (\n",
    "                    logits_per_image,\n",
    "                    logits_per_text,\n",
    "                    seg_logits,\n",
    "                    text_embeds,\n",
    "                    image_embeds,\n",
    "                    text_outputs,\n",
    "                    vision_outputs,\n",
    "                )\n",
    "            else:\n",
    "                output = (logits_per_image, logits_per_text, text_embeds, image_embeds, text_outputs, vision_outputs)\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return GroupViTModelOutput(\n",
    "            loss=loss,\n",
    "            # logits_per_image=logits_per_image,\n",
    "            # logits_per_text=logits_per_text,\n",
    "            segmentation_logits=seg_logits,\n",
    "            # text_embeds=text_embeds,\n",
    "            image_embeds=image_embeds,\n",
    "            # text_model_output=text_outputs,\n",
    "            vision_model_output=vision_outputs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "all_input hidden_states torch.Size([32, 196, 384]) output_attentions True\n",
      "prev_group_token None\n",
      "\n",
      ".expand(hidden_states.size(0), -1, -1) input self.group_token torch.Size([1, 64, 384])\n",
      ".expand(hidden_states.size(0), -1, -1) output group_token torch.Size([32, 64, 384])\n",
      "\n",
      "= input hidden_states torch.Size([32, 196, 384])\n",
      "= output x torch.Size([32, 196, 384])\n",
      "\n",
      "self.concat_x input x torch.Size([32, 196, 384])\n",
      "group_token torch.Size([32, 64, 384])\n",
      "self.concat_x output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 260, 384]) None None\n",
      "layer output layer_out (tensor([[[ 3.3183e-01,  2.8850e-04, -8.2914e-01,  ..., -2.0351e+00,\n",
      "           4.3549e-01,  8.3127e-01],\n",
      "         [ 6.4787e-01,  4.9799e-01,  1.1589e+00,  ...,  9.0648e-01,\n",
      "           1.2173e+00,  4.9343e-01],\n",
      "         [ 1.6151e-01, -6.7626e-02, -3.6144e-01,  ..., -3.5182e-01,\n",
      "           1.2622e+00,  4.1239e-01],\n",
      "         ...,\n",
      "         [-5.6672e-02,  6.8764e-02, -2.4181e-01,  ..., -1.1855e-01,\n",
      "           8.8759e-02, -1.7755e-01],\n",
      "         [-5.6672e-02,  6.8764e-02, -2.4181e-01,  ..., -1.1855e-01,\n",
      "           8.8759e-02, -1.7755e-01],\n",
      "         [-5.6672e-02,  6.8764e-02, -2.4181e-01,  ..., -1.1855e-01,\n",
      "           8.8759e-02, -1.7755e-01]],\n",
      "\n",
      "        [[ 6.2254e-01, -1.4627e-01,  6.3372e-01,  ..., -1.3143e-01,\n",
      "           1.0693e+00,  1.7140e-01],\n",
      "         [-3.1896e-01,  7.7959e-01,  7.7954e-01,  ...,  2.1048e+00,\n",
      "           8.0653e-01, -8.3698e-01],\n",
      "         [-1.1386e+00,  6.0710e-01,  3.8900e-02,  ...,  5.2899e-01,\n",
      "           4.0477e-01,  1.2372e-01],\n",
      "         ...,\n",
      "         [ 1.5223e-01, -1.3524e-01, -2.4195e-01,  ...,  1.3564e-03,\n",
      "          -1.1734e-02, -2.2976e-03],\n",
      "         [ 1.5223e-01, -1.3524e-01, -2.4195e-01,  ...,  1.3564e-03,\n",
      "          -1.1734e-02, -2.2977e-03],\n",
      "         [ 1.5223e-01, -1.3524e-01, -2.4195e-01,  ...,  1.3564e-03,\n",
      "          -1.1734e-02, -2.2977e-03]],\n",
      "\n",
      "        [[ 6.5812e-01,  1.3316e+00,  4.2388e-02,  ...,  1.0845e+00,\n",
      "          -7.5908e-01, -7.8521e-01],\n",
      "         [-1.6954e+00,  1.2989e+00,  1.1777e-01,  ...,  9.4309e-01,\n",
      "           2.9041e-01,  1.1504e+00],\n",
      "         [-8.7348e-01,  2.7891e-01, -1.2925e+00,  ...,  4.0042e-01,\n",
      "           1.0530e-01, -3.5580e-02],\n",
      "         ...,\n",
      "         [-2.9063e-01,  2.0424e-01,  5.1687e-02,  ..., -7.1547e-02,\n",
      "           1.0841e-01, -8.6380e-02],\n",
      "         [-2.9063e-01,  2.0424e-01,  5.1687e-02,  ..., -7.1547e-02,\n",
      "           1.0841e-01, -8.6380e-02],\n",
      "         [-2.9063e-01,  2.0424e-01,  5.1687e-02,  ..., -7.1547e-02,\n",
      "           1.0841e-01, -8.6380e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.6987e-01, -4.9612e-01,  1.0075e+00,  ..., -1.3839e+00,\n",
      "           9.6265e-01,  1.5346e+00],\n",
      "         [ 3.6768e-01,  4.9300e-01, -7.0475e-01,  ..., -6.3320e-01,\n",
      "          -1.9336e+00,  2.9399e-01],\n",
      "         [-1.0490e+00,  6.4347e-01,  1.2676e-01,  ..., -1.7886e+00,\n",
      "           6.0564e-01, -1.0985e-01],\n",
      "         ...,\n",
      "         [-7.6020e-02, -1.2968e-01, -9.6405e-02,  ..., -5.3235e-02,\n",
      "           2.7005e-01, -1.4307e-01],\n",
      "         [-7.6020e-02, -1.2968e-01, -9.6405e-02,  ..., -5.3235e-02,\n",
      "           2.7005e-01, -1.4307e-01],\n",
      "         [-7.6020e-02, -1.2968e-01, -9.6405e-02,  ..., -5.3235e-02,\n",
      "           2.7005e-01, -1.4307e-01]],\n",
      "\n",
      "        [[-1.4940e+00,  9.3088e-01,  5.3871e-02,  ..., -1.5488e+00,\n",
      "          -1.0937e-02,  8.3258e-01],\n",
      "         [ 5.2091e-01, -5.8697e-01, -5.6701e-01,  ...,  3.1060e-01,\n",
      "           1.3619e+00, -2.2146e-01],\n",
      "         [-8.7753e-01,  3.0292e-01,  9.2540e-02,  ...,  6.3371e-01,\n",
      "          -1.1176e+00, -1.2639e+00],\n",
      "         ...,\n",
      "         [-3.2657e-02,  1.8985e-01, -7.6803e-02,  ...,  2.0429e-02,\n",
      "           1.1188e-01,  2.8477e-02],\n",
      "         [-3.2657e-02,  1.8985e-01, -7.6803e-02,  ...,  2.0429e-02,\n",
      "           1.1188e-01,  2.8477e-02],\n",
      "         [-3.2657e-02,  1.8985e-01, -7.6803e-02,  ...,  2.0429e-02,\n",
      "           1.1188e-01,  2.8477e-02]],\n",
      "\n",
      "        [[-2.1888e+00, -1.1977e+00, -1.7785e-01,  ..., -3.3371e-02,\n",
      "          -5.8538e-01,  5.6518e-03],\n",
      "         [-2.4933e-01, -1.5348e+00,  1.7985e+00,  ...,  1.1477e+00,\n",
      "          -9.0821e-01, -1.7419e-01],\n",
      "         [ 1.5041e+00,  2.1701e+00,  8.8256e-01,  ..., -5.5084e-01,\n",
      "          -5.1414e-01,  3.5961e-01],\n",
      "         ...,\n",
      "         [-1.1953e-01,  1.9286e-01, -7.7406e-02,  ...,  1.2699e-01,\n",
      "           2.1910e-01,  5.3803e-02],\n",
      "         [-1.1953e-01,  1.9286e-01, -7.7406e-02,  ...,  1.2699e-01,\n",
      "           2.1910e-01,  5.3803e-02],\n",
      "         [-1.1953e-01,  1.9286e-01, -7.7406e-02,  ...,  1.2699e-01,\n",
      "           2.1910e-01,  5.3803e-02]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 260, 384])\n",
      "= output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 260, 384]) None None\n",
      "layer output layer_out (tensor([[[ 2.7718e-01,  7.2640e-02, -6.7648e-01,  ..., -2.1728e+00,\n",
      "           1.0557e-01,  8.7307e-01],\n",
      "         [ 5.5976e-01,  7.1924e-01,  1.2864e+00,  ...,  7.3905e-01,\n",
      "           1.2246e+00,  5.3486e-01],\n",
      "         [-4.5128e-04, -2.6016e-01, -2.8758e-01,  ..., -4.4790e-01,\n",
      "           1.3458e+00,  9.5924e-02],\n",
      "         ...,\n",
      "         [ 1.4599e-02,  3.5397e-02,  1.2835e-01,  ..., -2.5304e-01,\n",
      "           9.3001e-02,  6.2506e-02],\n",
      "         [ 1.4599e-02,  3.5397e-02,  1.2835e-01,  ..., -2.5304e-01,\n",
      "           9.3002e-02,  6.2506e-02],\n",
      "         [ 1.4599e-02,  3.5397e-02,  1.2835e-01,  ..., -2.5304e-01,\n",
      "           9.3002e-02,  6.2506e-02]],\n",
      "\n",
      "        [[ 8.5289e-01, -6.0664e-02,  3.9767e-01,  ..., -3.2456e-01,\n",
      "           8.6141e-01,  2.0601e-01],\n",
      "         [-2.5689e-01,  5.7600e-01,  1.2240e+00,  ...,  2.0907e+00,\n",
      "           3.7781e-01, -6.8232e-01],\n",
      "         [-1.1501e+00,  3.3922e-01,  8.3501e-03,  ...,  7.0275e-01,\n",
      "           2.0967e-02,  1.8938e-01],\n",
      "         ...,\n",
      "         [ 1.5216e-01, -1.9468e-01,  9.6700e-02,  ...,  2.2114e-01,\n",
      "           5.9681e-02, -9.0860e-02],\n",
      "         [ 1.5216e-01, -1.9468e-01,  9.6700e-02,  ...,  2.2114e-01,\n",
      "           5.9681e-02, -9.0860e-02],\n",
      "         [ 1.5216e-01, -1.9468e-01,  9.6700e-02,  ...,  2.2114e-01,\n",
      "           5.9681e-02, -9.0860e-02]],\n",
      "\n",
      "        [[ 9.8319e-01,  1.1330e+00,  1.8344e-01,  ...,  1.3599e+00,\n",
      "          -9.3456e-01, -1.1552e+00],\n",
      "         [-1.8284e+00,  1.5194e+00, -8.7848e-02,  ...,  7.7983e-01,\n",
      "           2.3275e-02,  1.1726e+00],\n",
      "         [-8.8899e-01,  2.2357e-01, -1.2500e+00,  ...,  6.0069e-01,\n",
      "           3.7632e-01, -1.4917e-01],\n",
      "         ...,\n",
      "         [-1.4928e-01, -1.4245e-01,  6.8767e-02,  ..., -4.2016e-02,\n",
      "          -3.7901e-02, -1.5138e-01],\n",
      "         [-1.4928e-01, -1.4245e-01,  6.8767e-02,  ..., -4.2016e-02,\n",
      "          -3.7901e-02, -1.5138e-01],\n",
      "         [-1.4928e-01, -1.4245e-01,  6.8767e-02,  ..., -4.2016e-02,\n",
      "          -3.7901e-02, -1.5138e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.4299e-01, -8.1936e-01,  7.7661e-01,  ..., -1.5475e+00,\n",
      "           8.1355e-01,  1.3219e+00],\n",
      "         [ 5.8663e-01,  2.7602e-01, -8.6344e-01,  ..., -9.0625e-01,\n",
      "          -1.9318e+00,  2.0461e-01],\n",
      "         [-9.1608e-01,  1.1095e+00,  3.3573e-01,  ..., -1.7949e+00,\n",
      "           1.6639e-01, -1.5803e-01],\n",
      "         ...,\n",
      "         [-2.5376e-01, -5.0012e-02,  8.3511e-02,  ...,  1.2024e-01,\n",
      "           4.6364e-01,  2.2735e-02],\n",
      "         [-2.5376e-01, -5.0012e-02,  8.3511e-02,  ...,  1.2024e-01,\n",
      "           4.6364e-01,  2.2735e-02],\n",
      "         [-2.5376e-01, -5.0012e-02,  8.3511e-02,  ...,  1.2024e-01,\n",
      "           4.6364e-01,  2.2735e-02]],\n",
      "\n",
      "        [[-1.3533e+00,  8.5424e-01,  2.6760e-02,  ..., -1.5266e+00,\n",
      "          -2.9977e-01,  1.3272e+00],\n",
      "         [ 4.3826e-01, -5.7880e-01, -3.8380e-01,  ...,  5.5331e-01,\n",
      "           1.3696e+00, -2.1506e-01],\n",
      "         [-6.4060e-01,  3.8325e-01,  3.3775e-01,  ...,  6.3452e-01,\n",
      "          -1.1398e+00, -1.3287e+00],\n",
      "         ...,\n",
      "         [ 2.5933e-01,  2.4548e-01,  8.4985e-02,  ..., -1.0247e-01,\n",
      "          -2.1902e-02, -6.2762e-02],\n",
      "         [ 2.5933e-01,  2.4548e-01,  8.4984e-02,  ..., -1.0247e-01,\n",
      "          -2.1902e-02, -6.2762e-02],\n",
      "         [ 2.5933e-01,  2.4548e-01,  8.4984e-02,  ..., -1.0247e-01,\n",
      "          -2.1902e-02, -6.2762e-02]],\n",
      "\n",
      "        [[-2.2863e+00, -1.1255e+00, -2.8306e-01,  ..., -1.7566e-01,\n",
      "          -5.9237e-01,  1.5993e-01],\n",
      "         [-2.5688e-02, -1.5726e+00,  1.9511e+00,  ...,  1.3059e+00,\n",
      "          -8.9100e-01,  1.5101e-01],\n",
      "         [ 1.6275e+00,  2.0970e+00,  1.0202e+00,  ..., -6.6726e-01,\n",
      "          -6.8367e-01,  2.3683e-01],\n",
      "         ...,\n",
      "         [-1.0688e-01,  2.6086e-01, -1.0773e-01,  ...,  1.8034e-01,\n",
      "           2.8018e-01,  8.4903e-02],\n",
      "         [-1.0688e-01,  2.6086e-01, -1.0773e-01,  ...,  1.8034e-01,\n",
      "           2.8018e-01,  8.4903e-02],\n",
      "         [-1.0688e-01,  2.6086e-01, -1.0773e-01,  ...,  1.8034e-01,\n",
      "           2.8018e-01,  8.4903e-02]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 260, 384])\n",
      "= output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 260, 384]) None None\n",
      "layer output layer_out (tensor([[[ 0.4296,  0.1353, -0.5252,  ..., -1.8847,  0.0889,  0.8300],\n",
      "         [ 0.4338,  0.8388,  1.6282,  ...,  0.7551,  1.4383,  0.1585],\n",
      "         [-0.0628, -0.2635, -0.1655,  ..., -0.2263,  1.2300,  0.1413],\n",
      "         ...,\n",
      "         [-0.2316, -0.1160,  0.2694,  ..., -0.2740, -0.0693, -0.2216],\n",
      "         [-0.2316, -0.1160,  0.2694,  ..., -0.2740, -0.0693, -0.2216],\n",
      "         [-0.2316, -0.1160,  0.2694,  ..., -0.2740, -0.0693, -0.2216]],\n",
      "\n",
      "        [[ 0.8388,  0.0943,  0.3519,  ...,  0.0093,  1.0383,  0.2711],\n",
      "         [-0.1355,  0.5624,  1.3239,  ...,  1.8442,  0.4142, -0.5636],\n",
      "         [-0.8731,  0.3451, -0.1627,  ...,  0.9911,  0.2512,  0.1075],\n",
      "         ...,\n",
      "         [ 0.1120, -0.0495,  0.1477,  ...,  0.1463,  0.2488, -0.2656],\n",
      "         [ 0.1120, -0.0495,  0.1477,  ...,  0.1463,  0.2488, -0.2656],\n",
      "         [ 0.1120, -0.0495,  0.1477,  ...,  0.1463,  0.2488, -0.2656]],\n",
      "\n",
      "        [[ 0.9265,  1.2000,  0.4483,  ...,  0.9921, -0.9353, -1.1415],\n",
      "         [-2.0023,  1.3690, -0.0583,  ...,  0.8552, -0.2333,  1.0902],\n",
      "         [-1.0380,  0.0676, -1.1302,  ...,  0.6901,  0.0708, -0.4148],\n",
      "         ...,\n",
      "         [-0.1343, -0.1812,  0.1399,  ..., -0.3023,  0.1056, -0.5047],\n",
      "         [-0.1343, -0.1812,  0.1399,  ..., -0.3023,  0.1056, -0.5047],\n",
      "         [-0.1343, -0.1812,  0.1399,  ..., -0.3023,  0.1056, -0.5047]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4729, -1.2229,  0.5083,  ..., -1.2556,  1.0819,  1.3141],\n",
      "         [ 0.7975,  0.0146, -0.7088,  ..., -0.9289, -2.1055,  0.2270],\n",
      "         [-0.8636,  0.8991,  0.1414,  ..., -1.8906,  0.2632, -0.1958],\n",
      "         ...,\n",
      "         [-0.2397, -0.0145,  0.3538,  ...,  0.2654,  0.3587, -0.2916],\n",
      "         [-0.2397, -0.0145,  0.3538,  ...,  0.2654,  0.3587, -0.2916],\n",
      "         [-0.2397, -0.0145,  0.3538,  ...,  0.2654,  0.3587, -0.2916]],\n",
      "\n",
      "        [[-1.2882,  1.0411,  0.1831,  ..., -1.5484, -0.4995,  1.1299],\n",
      "         [ 0.2998, -0.6059, -0.1033,  ...,  0.6868,  1.5828, -0.3209],\n",
      "         [-0.8058,  0.4863,  0.1655,  ...,  0.9124, -1.2898, -1.5426],\n",
      "         ...,\n",
      "         [ 0.4108,  0.1314,  0.1694,  ..., -0.2414, -0.1059, -0.0072],\n",
      "         [ 0.4108,  0.1314,  0.1694,  ..., -0.2414, -0.1059, -0.0072],\n",
      "         [ 0.4108,  0.1314,  0.1694,  ..., -0.2414, -0.1059, -0.0072]],\n",
      "\n",
      "        [[-2.0915, -1.3176, -0.3752,  ..., -0.2394, -0.7532, -0.1036],\n",
      "         [ 0.0898, -1.7782,  1.9012,  ...,  1.5051, -0.7024, -0.2021],\n",
      "         [ 2.0118,  1.8888,  0.8305,  ..., -0.8331, -0.6905,  0.0511],\n",
      "         ...,\n",
      "         [ 0.0153,  0.3895,  0.1409,  ...,  0.3458,  0.7681, -0.0611],\n",
      "         [ 0.0153,  0.3895,  0.1409,  ...,  0.3458,  0.7681, -0.0611],\n",
      "         [ 0.0153,  0.3895,  0.1409,  ...,  0.3458,  0.7681, -0.0611]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 260, 384])\n",
      "= output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 260, 384]) None None\n",
      "layer output layer_out (tensor([[[ 2.5386e-01, -9.9753e-03, -5.5272e-01,  ..., -2.0537e+00,\n",
      "          -1.9729e-01,  9.9626e-01],\n",
      "         [ 3.6315e-01,  9.3808e-01,  1.9990e+00,  ...,  9.9347e-01,\n",
      "           1.2220e+00,  1.2633e-01],\n",
      "         [-4.1801e-01, -1.9402e-01, -7.2671e-02,  ...,  2.7717e-01,\n",
      "           1.5314e+00,  3.2378e-01],\n",
      "         ...,\n",
      "         [-4.6974e-01, -1.6660e-03,  3.2856e-01,  ..., -4.1675e-02,\n",
      "          -7.4575e-02, -1.0312e-01],\n",
      "         [-4.6974e-01, -1.6659e-03,  3.2856e-01,  ..., -4.1675e-02,\n",
      "          -7.4574e-02, -1.0312e-01],\n",
      "         [-4.6974e-01, -1.6659e-03,  3.2856e-01,  ..., -4.1675e-02,\n",
      "          -7.4574e-02, -1.0312e-01]],\n",
      "\n",
      "        [[ 9.3600e-01,  3.9264e-01,  4.9812e-01,  ...,  4.0087e-01,\n",
      "           1.2007e+00,  5.0320e-02],\n",
      "         [-3.4374e-01,  8.2332e-01,  1.4888e+00,  ...,  1.9983e+00,\n",
      "           6.2903e-01, -6.7231e-01],\n",
      "         [-9.8020e-01,  4.2509e-01, -3.8519e-03,  ...,  1.1668e+00,\n",
      "           7.8347e-02, -1.6600e-01],\n",
      "         ...,\n",
      "         [-8.4359e-02,  4.2400e-01,  2.8005e-03,  ...,  1.7347e-01,\n",
      "           1.9797e-01, -2.6006e-01],\n",
      "         [-8.4359e-02,  4.2400e-01,  2.8005e-03,  ...,  1.7347e-01,\n",
      "           1.9797e-01, -2.6006e-01],\n",
      "         [-8.4359e-02,  4.2400e-01,  2.8005e-03,  ...,  1.7347e-01,\n",
      "           1.9797e-01, -2.6006e-01]],\n",
      "\n",
      "        [[ 6.8830e-01,  1.1041e+00,  5.1618e-01,  ...,  1.0816e+00,\n",
      "          -1.1710e+00, -7.6387e-01],\n",
      "         [-1.8272e+00,  1.3806e+00,  7.5533e-02,  ...,  1.0269e+00,\n",
      "           9.4316e-03,  1.0211e+00],\n",
      "         [-1.2820e+00, -2.4347e-02, -1.0861e+00,  ...,  1.0029e+00,\n",
      "           4.7684e-01, -2.8322e-01],\n",
      "         ...,\n",
      "         [-2.8126e-01, -9.6660e-02,  2.0493e-01,  ...,  7.5627e-02,\n",
      "          -8.0211e-03, -5.5795e-01],\n",
      "         [-2.8126e-01, -9.6660e-02,  2.0493e-01,  ...,  7.5627e-02,\n",
      "          -8.0210e-03, -5.5795e-01],\n",
      "         [-2.8126e-01, -9.6660e-02,  2.0493e-01,  ...,  7.5627e-02,\n",
      "          -8.0210e-03, -5.5795e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6088e-01, -1.4187e+00,  4.5402e-01,  ..., -1.2930e+00,\n",
      "           9.0330e-01,  1.1732e+00],\n",
      "         [ 7.1320e-01,  5.0065e-02, -1.0051e+00,  ..., -1.1846e+00,\n",
      "          -1.9844e+00,  2.0773e-01],\n",
      "         [-7.9967e-01,  9.3540e-01,  8.7377e-02,  ..., -1.9903e+00,\n",
      "          -8.0738e-02, -1.9427e-01],\n",
      "         ...,\n",
      "         [-6.3306e-01,  1.9642e-01,  2.1754e-02,  ...,  2.6331e-01,\n",
      "           3.3554e-01, -4.3629e-01],\n",
      "         [-6.3306e-01,  1.9642e-01,  2.1754e-02,  ...,  2.6331e-01,\n",
      "           3.3554e-01, -4.3629e-01],\n",
      "         [-6.3306e-01,  1.9642e-01,  2.1754e-02,  ...,  2.6331e-01,\n",
      "           3.3554e-01, -4.3629e-01]],\n",
      "\n",
      "        [[-1.2163e+00,  1.3911e+00,  5.3528e-01,  ..., -1.4724e+00,\n",
      "          -7.1342e-01,  9.8185e-01],\n",
      "         [ 3.0159e-01, -7.4739e-01,  2.2800e-01,  ...,  7.9235e-01,\n",
      "           1.7592e+00, -4.5216e-01],\n",
      "         [-9.1913e-01,  4.7198e-01,  4.0934e-01,  ...,  1.3245e+00,\n",
      "          -1.0777e+00, -1.5253e+00],\n",
      "         ...,\n",
      "         [ 7.5321e-01,  1.0226e-01,  5.2748e-01,  ..., -5.6841e-02,\n",
      "          -1.0515e-02,  9.5731e-02],\n",
      "         [ 7.5321e-01,  1.0226e-01,  5.2748e-01,  ..., -5.6841e-02,\n",
      "          -1.0515e-02,  9.5731e-02],\n",
      "         [ 7.5321e-01,  1.0226e-01,  5.2748e-01,  ..., -5.6841e-02,\n",
      "          -1.0515e-02,  9.5731e-02]],\n",
      "\n",
      "        [[-2.4183e+00, -1.1577e+00,  2.1049e-02,  ..., -3.0268e-01,\n",
      "          -8.8770e-01, -1.7940e-01],\n",
      "         [-1.2712e-01, -1.8893e+00,  1.9383e+00,  ...,  1.4918e+00,\n",
      "          -7.0939e-01, -1.7696e-02],\n",
      "         [ 2.1589e+00,  2.0049e+00,  1.1032e+00,  ..., -8.3876e-01,\n",
      "          -2.9063e-01,  2.3893e-01],\n",
      "         ...,\n",
      "         [ 1.7632e-01,  3.4091e-01,  7.1772e-02,  ...,  3.6397e-01,\n",
      "           1.0308e+00, -3.2898e-01],\n",
      "         [ 1.7632e-01,  3.4091e-01,  7.1772e-02,  ...,  3.6397e-01,\n",
      "           1.0308e+00, -3.2898e-01],\n",
      "         [ 1.7632e-01,  3.4091e-01,  7.1772e-02,  ...,  3.6397e-01,\n",
      "           1.0308e+00, -3.2898e-01]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 260, 384])\n",
      "= output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 260, 384]) None None\n",
      "layer output layer_out (tensor([[[ 0.1744, -0.3252, -0.3958,  ..., -1.7219, -0.3683,  1.2379],\n",
      "         [ 0.3419,  0.5613,  1.9020,  ...,  1.7024,  0.9054, -0.0844],\n",
      "         [-0.2252, -0.5410, -0.0428,  ...,  0.5686,  1.6003,  0.4166],\n",
      "         ...,\n",
      "         [-0.3828, -0.5329,  0.2879,  ...,  0.2218, -0.1216, -0.0460],\n",
      "         [-0.3828, -0.5329,  0.2879,  ...,  0.2218, -0.1216, -0.0460],\n",
      "         [-0.3828, -0.5329,  0.2879,  ...,  0.2218, -0.1216, -0.0460]],\n",
      "\n",
      "        [[ 1.2113,  0.1095, -0.0462,  ...,  0.4179,  0.9610,  0.0693],\n",
      "         [-0.0279,  0.5223,  1.2775,  ...,  1.9534, -0.0138, -0.5752],\n",
      "         [-1.1405, -0.1208, -0.1572,  ...,  1.3239,  0.1152, -0.1319],\n",
      "         ...,\n",
      "         [ 0.1974,  0.0176, -0.0326,  ...,  0.1230,  0.2116, -0.1285],\n",
      "         [ 0.1974,  0.0176, -0.0326,  ...,  0.1230,  0.2116, -0.1285],\n",
      "         [ 0.1974,  0.0176, -0.0326,  ...,  0.1230,  0.2116, -0.1285]],\n",
      "\n",
      "        [[ 0.7358,  1.1249,  0.4191,  ...,  1.2169, -1.5906, -0.5551],\n",
      "         [-1.7683,  1.3829,  0.0768,  ...,  1.0901,  0.3508,  1.2279],\n",
      "         [-1.1829, -0.1362, -1.2291,  ...,  0.9300,  0.3982, -0.3182],\n",
      "         ...,\n",
      "         [-0.3953, -0.4843,  0.0249,  ...,  0.3477,  0.0440, -0.9608],\n",
      "         [-0.3953, -0.4843,  0.0249,  ...,  0.3477,  0.0440, -0.9608],\n",
      "         [-0.3953, -0.4843,  0.0249,  ...,  0.3477,  0.0440, -0.9608]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4713, -1.7014,  0.5051,  ..., -0.7549,  0.9477,  1.5897],\n",
      "         [ 0.8012, -0.4302, -1.0852,  ..., -0.9765, -1.9752,  0.2702],\n",
      "         [-0.7693,  0.7762,  0.0585,  ..., -2.0776, -0.3422, -0.4018],\n",
      "         ...,\n",
      "         [-0.5869, -0.1231,  0.0764,  ...,  0.6963,  0.4590, -0.3767],\n",
      "         [-0.5869, -0.1231,  0.0764,  ...,  0.6963,  0.4590, -0.3767],\n",
      "         [-0.5869, -0.1231,  0.0764,  ...,  0.6963,  0.4590, -0.3767]],\n",
      "\n",
      "        [[-1.4217,  1.3336,  0.2986,  ..., -1.4871, -0.7118,  1.0522],\n",
      "         [ 0.6308, -1.1197,  0.1034,  ...,  1.1493,  1.8745, -0.5262],\n",
      "         [-0.5601,  0.1092,  0.4357,  ...,  1.5484, -0.9248, -1.7007],\n",
      "         ...,\n",
      "         [ 0.9981, -0.3031,  0.3504,  ..., -0.1816, -0.0571,  0.4883],\n",
      "         [ 0.9981, -0.3031,  0.3504,  ..., -0.1816, -0.0571,  0.4883],\n",
      "         [ 0.9981, -0.3031,  0.3504,  ..., -0.1816, -0.0571,  0.4883]],\n",
      "\n",
      "        [[-2.0526, -1.0482,  0.0491,  ...,  0.0177, -0.9384,  0.2247],\n",
      "         [ 0.1779, -1.8789,  1.6068,  ...,  1.5286, -0.7824, -0.0221],\n",
      "         [ 2.4808,  1.6974,  1.0428,  ..., -0.8131, -0.4017,  0.4284],\n",
      "         ...,\n",
      "         [ 0.2603,  0.1464, -0.2367,  ...,  0.4553,  1.0583, -0.0640],\n",
      "         [ 0.2603,  0.1464, -0.2367,  ...,  0.4553,  1.0583, -0.0640],\n",
      "         [ 0.2603,  0.1464, -0.2367,  ...,  0.4553,  1.0583, -0.0640]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 260, 384])\n",
      "= output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 260, 384]) None None\n",
      "layer output layer_out (tensor([[[ 0.0827, -0.1493, -0.1438,  ..., -1.4115, -0.3948,  0.8846],\n",
      "         [ 0.3470,  0.5264,  1.9793,  ...,  1.7582,  0.9213, -0.1927],\n",
      "         [-0.2020, -0.6907, -0.1976,  ...,  0.6132,  1.6704,  0.1396],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[ 1.4511,  0.4284, -0.1696,  ...,  0.4964,  0.8990, -0.0828],\n",
      "         [-0.2406,  0.8769,  1.2657,  ...,  2.1083,  0.0458, -0.5356],\n",
      "         [-1.1401,  0.1153, -0.2817,  ...,  1.3225,  0.0725, -0.1781],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[ 0.6973,  1.1262,  0.1847,  ...,  1.2101, -1.6068, -1.0582],\n",
      "         [-1.5239,  1.4582, -0.1421,  ...,  1.3071,  0.5460,  1.2950],\n",
      "         [-1.2470, -0.1437, -1.0276,  ...,  0.7935,  0.5159, -0.3733],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5426, -1.8234,  0.6185,  ..., -0.7155,  0.9185,  1.2955],\n",
      "         [ 0.8220, -0.4614, -0.7317,  ..., -0.8614, -1.7707,  0.0032],\n",
      "         [-0.6590,  0.5159,  0.0607,  ..., -1.8608, -0.3253, -0.8912],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[-1.3108,  1.3203,  0.1412,  ..., -1.6375, -0.4339,  0.9566],\n",
      "         [ 0.7461, -0.9906,  0.6153,  ...,  1.2110,  1.8885, -0.8060],\n",
      "         [-0.7439,  0.0281,  0.7341,  ...,  1.2383, -0.7653, -1.8834],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[-2.1072, -0.5750,  0.0894,  ...,  0.0613, -0.9114,  0.2572],\n",
      "         [ 0.2880, -1.6951,  1.4627,  ...,  1.7263, -0.6327, -0.0311],\n",
      "         [ 2.4120,  1.5194,  1.3535,  ..., -0.8291, -0.3962,  0.4219],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 260, 384])\n",
      "= output cat_x torch.Size([32, 260, 384])\n",
      "\n",
      "self.split_x input cat_x torch.Size([32, 260, 384])\n",
      "self.split_x output x torch.Size([32, 196, 384])\n",
      "group_token torch.Size([32, 64, 384])\n",
      "\n",
      "attention = None\n",
      "\n",
      "self.downsample input x torch.Size([32, 196, 384]) group_token tensor([[[-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "self.split_x output x torch.Size([32, 64, 384]) attention torch.Size([32, 64, 196])\n",
      "\n",
      "= input x torch.Size([32, 64, 384]) group_token tensor([[[-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "= output outputs (tensor([[[-4.3626e-01, -2.3018e+00,  9.7527e-01,  ...,  2.1156e-01,\n",
      "           6.0662e-01, -4.9928e-01],\n",
      "         [-4.2386e-01, -2.2182e+00,  9.5649e-01,  ...,  4.2517e-01,\n",
      "           7.6385e-01, -3.7428e-01],\n",
      "         [ 5.3852e-01,  1.9011e+00, -5.3166e-01,  ..., -6.8861e-02,\n",
      "          -3.6535e-01,  1.0354e+00],\n",
      "         ...,\n",
      "         [-4.3924e-01, -2.2990e+00,  1.0060e+00,  ...,  1.1516e-01,\n",
      "           6.6356e-01, -4.7503e-01],\n",
      "         [-4.7746e-01, -8.7078e-01,  8.8662e-01,  ..., -2.4822e-01,\n",
      "           7.4797e-02, -7.5947e-01],\n",
      "         [-2.1842e-01, -1.7358e+00,  7.0334e-01,  ...,  7.1917e-01,\n",
      "           8.6305e-01,  1.9747e-01]],\n",
      "\n",
      "        [[-5.7568e-01,  1.0596e-01,  1.3799e-01,  ...,  4.2550e-02,\n",
      "           3.9809e-01,  5.3815e-02],\n",
      "         [-3.6686e-01,  2.8751e-01,  6.2892e-01,  ...,  3.1220e-01,\n",
      "           3.6637e-01,  4.5292e-01],\n",
      "         [ 9.9382e-01,  1.2502e-01,  4.4348e-01,  ..., -2.0507e-01,\n",
      "          -5.5755e-01,  2.4661e-01],\n",
      "         ...,\n",
      "         [-7.0978e-01,  6.9703e-02,  1.2618e-01,  ...,  3.0985e-03,\n",
      "           4.2132e-01, -2.8642e-02],\n",
      "         [-8.1810e-01, -2.2198e-01, -5.8070e-01,  ..., -3.3696e-01,\n",
      "           3.0205e-01, -7.8667e-01],\n",
      "         [ 2.1910e-01,  6.7398e-01,  1.2403e+00,  ...,  5.9747e-01,\n",
      "           2.7271e-01,  9.9901e-01]],\n",
      "\n",
      "        [[-2.8700e-01, -7.9350e-01,  4.6270e-01,  ...,  5.8172e-01,\n",
      "           6.8643e-01, -3.3274e+00],\n",
      "         [ 1.2067e-01, -3.9684e-01,  9.4758e-01,  ...,  8.9757e-01,\n",
      "           8.9176e-01, -4.8129e+00],\n",
      "         [ 3.4788e-01,  1.0281e+00,  6.2660e-01,  ..., -9.2050e-01,\n",
      "          -4.9468e-01,  3.0017e+00],\n",
      "         ...,\n",
      "         [-2.6405e-01, -8.9511e-01,  3.5011e-01,  ...,  4.6955e-01,\n",
      "           5.9926e-01, -3.3329e+00],\n",
      "         [-8.9508e-01, -7.6916e-01, -5.6990e-01,  ..., -8.8688e-03,\n",
      "           2.4543e-01,  8.3116e-02],\n",
      "         [ 6.3303e-01, -6.8778e-02,  1.3499e+00,  ...,  8.7378e-01,\n",
      "           8.8885e-01, -4.4931e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9410e+00, -3.0644e-01,  1.4439e-01,  ...,  1.4399e+00,\n",
      "           1.3537e+00, -2.1022e+00],\n",
      "         [-2.2140e+00, -7.1635e-02,  4.1298e-01,  ..., -1.8784e-01,\n",
      "           2.5472e-01, -2.4628e+00],\n",
      "         [ 1.4258e+00,  9.1588e-01,  4.0732e-01,  ..., -1.8895e+00,\n",
      "          -1.6048e+00,  2.2437e+00],\n",
      "         ...,\n",
      "         [-1.6725e+00, -2.5664e-01, -1.6287e-02,  ...,  1.7337e+00,\n",
      "           1.4513e+00, -2.1567e+00],\n",
      "         [-1.5960e-01, -3.7264e-01, -3.6138e-01,  ...,  3.3912e+00,\n",
      "           2.4804e+00, -6.1017e-01],\n",
      "         [-2.0587e+00,  4.2933e-01,  8.0779e-01,  ..., -2.2442e+00,\n",
      "          -1.3507e+00, -2.0408e+00]],\n",
      "\n",
      "        [[ 1.5099e+00, -5.7556e-01,  8.5707e-01,  ..., -1.3370e+00,\n",
      "           7.5983e-01,  8.6677e-01],\n",
      "         [ 5.6939e-02, -4.2866e-01,  1.0132e+00,  ..., -1.1783e+00,\n",
      "           8.6405e-01,  7.9072e-01],\n",
      "         [-1.5017e+00,  1.4194e+00, -5.2937e-01,  ...,  8.3594e-01,\n",
      "           2.3391e-02, -9.9991e-01],\n",
      "         ...,\n",
      "         [ 1.5197e+00, -6.6674e-01,  8.7495e-01,  ..., -1.2485e+00,\n",
      "           7.3519e-01,  9.7399e-01],\n",
      "         [ 3.0519e+00, -6.7277e-01,  3.4313e-01,  ..., -8.4936e-01,\n",
      "          -3.2734e-02,  8.1304e-01],\n",
      "         [-1.7106e+00,  7.0434e-02,  1.0012e+00,  ..., -8.8759e-01,\n",
      "           9.4478e-01,  3.8784e-01]],\n",
      "\n",
      "        [[ 2.8405e-01,  7.7092e-01, -7.5718e-01,  ...,  1.5070e+00,\n",
      "           1.8289e+00,  2.0512e-01],\n",
      "         [ 5.1227e-01,  7.1680e-01, -2.6229e-01,  ...,  6.3357e-01,\n",
      "          -3.9181e-01,  3.8209e-01],\n",
      "         [-1.2126e-01, -7.3892e-01,  1.0977e+00,  ..., -1.2331e+00,\n",
      "          -2.3222e+00,  1.8062e-01],\n",
      "         ...,\n",
      "         [ 1.4999e-01,  8.6894e-01, -7.0896e-01,  ...,  1.7260e+00,\n",
      "           1.8832e+00,  1.6248e-01],\n",
      "         [-5.1832e-01,  4.9899e-01, -9.2183e-01,  ...,  1.8654e+00,\n",
      "           4.3273e+00, -2.8366e-01],\n",
      "         [ 9.6009e-01,  4.3814e-01,  4.7576e-01,  ..., -7.7323e-01,\n",
      "          -2.8565e+00,  6.5326e-01]]], grad_fn=<AddBackward0>), tensor([[[-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<SliceBackward0>))\n",
      "\n",
      "+= input outputs (tensor([[[-4.3626e-01, -2.3018e+00,  9.7527e-01,  ...,  2.1156e-01,\n",
      "           6.0662e-01, -4.9928e-01],\n",
      "         [-4.2386e-01, -2.2182e+00,  9.5649e-01,  ...,  4.2517e-01,\n",
      "           7.6385e-01, -3.7428e-01],\n",
      "         [ 5.3852e-01,  1.9011e+00, -5.3166e-01,  ..., -6.8861e-02,\n",
      "          -3.6535e-01,  1.0354e+00],\n",
      "         ...,\n",
      "         [-4.3924e-01, -2.2990e+00,  1.0060e+00,  ...,  1.1516e-01,\n",
      "           6.6356e-01, -4.7503e-01],\n",
      "         [-4.7746e-01, -8.7078e-01,  8.8662e-01,  ..., -2.4822e-01,\n",
      "           7.4797e-02, -7.5947e-01],\n",
      "         [-2.1842e-01, -1.7358e+00,  7.0334e-01,  ...,  7.1917e-01,\n",
      "           8.6305e-01,  1.9747e-01]],\n",
      "\n",
      "        [[-5.7568e-01,  1.0596e-01,  1.3799e-01,  ...,  4.2550e-02,\n",
      "           3.9809e-01,  5.3815e-02],\n",
      "         [-3.6686e-01,  2.8751e-01,  6.2892e-01,  ...,  3.1220e-01,\n",
      "           3.6637e-01,  4.5292e-01],\n",
      "         [ 9.9382e-01,  1.2502e-01,  4.4348e-01,  ..., -2.0507e-01,\n",
      "          -5.5755e-01,  2.4661e-01],\n",
      "         ...,\n",
      "         [-7.0978e-01,  6.9703e-02,  1.2618e-01,  ...,  3.0985e-03,\n",
      "           4.2132e-01, -2.8642e-02],\n",
      "         [-8.1810e-01, -2.2198e-01, -5.8070e-01,  ..., -3.3696e-01,\n",
      "           3.0205e-01, -7.8667e-01],\n",
      "         [ 2.1910e-01,  6.7398e-01,  1.2403e+00,  ...,  5.9747e-01,\n",
      "           2.7271e-01,  9.9901e-01]],\n",
      "\n",
      "        [[-2.8700e-01, -7.9350e-01,  4.6270e-01,  ...,  5.8172e-01,\n",
      "           6.8643e-01, -3.3274e+00],\n",
      "         [ 1.2067e-01, -3.9684e-01,  9.4758e-01,  ...,  8.9757e-01,\n",
      "           8.9176e-01, -4.8129e+00],\n",
      "         [ 3.4788e-01,  1.0281e+00,  6.2660e-01,  ..., -9.2050e-01,\n",
      "          -4.9468e-01,  3.0017e+00],\n",
      "         ...,\n",
      "         [-2.6405e-01, -8.9511e-01,  3.5011e-01,  ...,  4.6955e-01,\n",
      "           5.9926e-01, -3.3329e+00],\n",
      "         [-8.9508e-01, -7.6916e-01, -5.6990e-01,  ..., -8.8688e-03,\n",
      "           2.4543e-01,  8.3116e-02],\n",
      "         [ 6.3303e-01, -6.8778e-02,  1.3499e+00,  ...,  8.7378e-01,\n",
      "           8.8885e-01, -4.4931e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9410e+00, -3.0644e-01,  1.4439e-01,  ...,  1.4399e+00,\n",
      "           1.3537e+00, -2.1022e+00],\n",
      "         [-2.2140e+00, -7.1635e-02,  4.1298e-01,  ..., -1.8784e-01,\n",
      "           2.5472e-01, -2.4628e+00],\n",
      "         [ 1.4258e+00,  9.1588e-01,  4.0732e-01,  ..., -1.8895e+00,\n",
      "          -1.6048e+00,  2.2437e+00],\n",
      "         ...,\n",
      "         [-1.6725e+00, -2.5664e-01, -1.6287e-02,  ...,  1.7337e+00,\n",
      "           1.4513e+00, -2.1567e+00],\n",
      "         [-1.5960e-01, -3.7264e-01, -3.6138e-01,  ...,  3.3912e+00,\n",
      "           2.4804e+00, -6.1017e-01],\n",
      "         [-2.0587e+00,  4.2933e-01,  8.0779e-01,  ..., -2.2442e+00,\n",
      "          -1.3507e+00, -2.0408e+00]],\n",
      "\n",
      "        [[ 1.5099e+00, -5.7556e-01,  8.5707e-01,  ..., -1.3370e+00,\n",
      "           7.5983e-01,  8.6677e-01],\n",
      "         [ 5.6939e-02, -4.2866e-01,  1.0132e+00,  ..., -1.1783e+00,\n",
      "           8.6405e-01,  7.9072e-01],\n",
      "         [-1.5017e+00,  1.4194e+00, -5.2937e-01,  ...,  8.3594e-01,\n",
      "           2.3391e-02, -9.9991e-01],\n",
      "         ...,\n",
      "         [ 1.5197e+00, -6.6674e-01,  8.7495e-01,  ..., -1.2485e+00,\n",
      "           7.3519e-01,  9.7399e-01],\n",
      "         [ 3.0519e+00, -6.7277e-01,  3.4313e-01,  ..., -8.4936e-01,\n",
      "          -3.2734e-02,  8.1304e-01],\n",
      "         [-1.7106e+00,  7.0434e-02,  1.0012e+00,  ..., -8.8759e-01,\n",
      "           9.4478e-01,  3.8784e-01]],\n",
      "\n",
      "        [[ 2.8405e-01,  7.7092e-01, -7.5718e-01,  ...,  1.5070e+00,\n",
      "           1.8289e+00,  2.0512e-01],\n",
      "         [ 5.1227e-01,  7.1680e-01, -2.6229e-01,  ...,  6.3357e-01,\n",
      "          -3.9181e-01,  3.8209e-01],\n",
      "         [-1.2126e-01, -7.3892e-01,  1.0977e+00,  ..., -1.2331e+00,\n",
      "          -2.3222e+00,  1.8062e-01],\n",
      "         ...,\n",
      "         [ 1.4999e-01,  8.6894e-01, -7.0896e-01,  ...,  1.7260e+00,\n",
      "           1.8832e+00,  1.6248e-01],\n",
      "         [-5.1832e-01,  4.9899e-01, -9.2183e-01,  ...,  1.8654e+00,\n",
      "           4.3273e+00, -2.8366e-01],\n",
      "         [ 9.6009e-01,  4.3814e-01,  4.7576e-01,  ..., -7.7323e-01,\n",
      "          -2.8565e+00,  6.5326e-01]]], grad_fn=<AddBackward0>), tensor([[[-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<SliceBackward0>)) attention tensor([[[0.0170, 0.0161, 0.0188,  ..., 0.0148, 0.0117, 0.0158],\n",
      "         [0.0173, 0.0148, 0.0195,  ..., 0.0139, 0.0113, 0.0153],\n",
      "         [0.0138, 0.0150, 0.0117,  ..., 0.0166, 0.0211, 0.0152],\n",
      "         ...,\n",
      "         [0.0170, 0.0161, 0.0187,  ..., 0.0149, 0.0118, 0.0158],\n",
      "         [0.0158, 0.0177, 0.0153,  ..., 0.0169, 0.0146, 0.0169],\n",
      "         [0.0168, 0.0138, 0.0191,  ..., 0.0133, 0.0120, 0.0146]],\n",
      "\n",
      "        [[0.0177, 0.0151, 0.0146,  ..., 0.0149, 0.0182, 0.0149],\n",
      "         [0.0187, 0.0154, 0.0151,  ..., 0.0140, 0.0176, 0.0151],\n",
      "         [0.0131, 0.0164, 0.0168,  ..., 0.0165, 0.0121, 0.0168],\n",
      "         ...,\n",
      "         [0.0177, 0.0151, 0.0146,  ..., 0.0150, 0.0183, 0.0149],\n",
      "         [0.0147, 0.0150, 0.0147,  ..., 0.0167, 0.0177, 0.0146],\n",
      "         [0.0182, 0.0154, 0.0156,  ..., 0.0135, 0.0157, 0.0158]],\n",
      "\n",
      "        [[0.0168, 0.0109, 0.0142,  ..., 0.0150, 0.0161, 0.0109],\n",
      "         [0.0149, 0.0114, 0.0136,  ..., 0.0155, 0.0164, 0.0128],\n",
      "         [0.0135, 0.0222, 0.0175,  ..., 0.0164, 0.0149, 0.0220],\n",
      "         ...,\n",
      "         [0.0170, 0.0109, 0.0143,  ..., 0.0150, 0.0161, 0.0108],\n",
      "         [0.0195, 0.0123, 0.0159,  ..., 0.0146, 0.0156, 0.0103],\n",
      "         [0.0127, 0.0139, 0.0136,  ..., 0.0164, 0.0167, 0.0167]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0147, 0.0150, 0.0150,  ..., 0.0153, 0.0141, 0.0121],\n",
      "         [0.0140, 0.0151, 0.0155,  ..., 0.0167, 0.0130, 0.0126],\n",
      "         [0.0167, 0.0165, 0.0165,  ..., 0.0162, 0.0175, 0.0209],\n",
      "         ...,\n",
      "         [0.0148, 0.0150, 0.0150,  ..., 0.0152, 0.0142, 0.0120],\n",
      "         [0.0163, 0.0155, 0.0144,  ..., 0.0134, 0.0167, 0.0123],\n",
      "         [0.0134, 0.0151, 0.0158,  ..., 0.0184, 0.0126, 0.0145]],\n",
      "\n",
      "        [[0.0151, 0.0161, 0.0187,  ..., 0.0158, 0.0141, 0.0159],\n",
      "         [0.0165, 0.0152, 0.0198,  ..., 0.0173, 0.0144, 0.0152],\n",
      "         [0.0161, 0.0147, 0.0119,  ..., 0.0156, 0.0177, 0.0151],\n",
      "         ...,\n",
      "         [0.0150, 0.0162, 0.0185,  ..., 0.0156, 0.0141, 0.0160],\n",
      "         [0.0135, 0.0177, 0.0148,  ..., 0.0129, 0.0144, 0.0171],\n",
      "         [0.0181, 0.0138, 0.0195,  ..., 0.0191, 0.0149, 0.0142]],\n",
      "\n",
      "        [[0.0112, 0.0149, 0.0134,  ..., 0.0118, 0.0123, 0.0120],\n",
      "         [0.0128, 0.0151, 0.0135,  ..., 0.0114, 0.0126, 0.0125],\n",
      "         [0.0216, 0.0167, 0.0188,  ..., 0.0211, 0.0206, 0.0209],\n",
      "         ...,\n",
      "         [0.0111, 0.0149, 0.0133,  ..., 0.0118, 0.0123, 0.0120],\n",
      "         [0.0111, 0.0149, 0.0141,  ..., 0.0143, 0.0132, 0.0128],\n",
      "         [0.0163, 0.0155, 0.0149,  ..., 0.0122, 0.0138, 0.0142]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "+= output outputs (tensor([[[-4.3626e-01, -2.3018e+00,  9.7527e-01,  ...,  2.1156e-01,\n",
      "           6.0662e-01, -4.9928e-01],\n",
      "         [-4.2386e-01, -2.2182e+00,  9.5649e-01,  ...,  4.2517e-01,\n",
      "           7.6385e-01, -3.7428e-01],\n",
      "         [ 5.3852e-01,  1.9011e+00, -5.3166e-01,  ..., -6.8861e-02,\n",
      "          -3.6535e-01,  1.0354e+00],\n",
      "         ...,\n",
      "         [-4.3924e-01, -2.2990e+00,  1.0060e+00,  ...,  1.1516e-01,\n",
      "           6.6356e-01, -4.7503e-01],\n",
      "         [-4.7746e-01, -8.7078e-01,  8.8662e-01,  ..., -2.4822e-01,\n",
      "           7.4797e-02, -7.5947e-01],\n",
      "         [-2.1842e-01, -1.7358e+00,  7.0334e-01,  ...,  7.1917e-01,\n",
      "           8.6305e-01,  1.9747e-01]],\n",
      "\n",
      "        [[-5.7568e-01,  1.0596e-01,  1.3799e-01,  ...,  4.2550e-02,\n",
      "           3.9809e-01,  5.3815e-02],\n",
      "         [-3.6686e-01,  2.8751e-01,  6.2892e-01,  ...,  3.1220e-01,\n",
      "           3.6637e-01,  4.5292e-01],\n",
      "         [ 9.9382e-01,  1.2502e-01,  4.4348e-01,  ..., -2.0507e-01,\n",
      "          -5.5755e-01,  2.4661e-01],\n",
      "         ...,\n",
      "         [-7.0978e-01,  6.9703e-02,  1.2618e-01,  ...,  3.0985e-03,\n",
      "           4.2132e-01, -2.8642e-02],\n",
      "         [-8.1810e-01, -2.2198e-01, -5.8070e-01,  ..., -3.3696e-01,\n",
      "           3.0205e-01, -7.8667e-01],\n",
      "         [ 2.1910e-01,  6.7398e-01,  1.2403e+00,  ...,  5.9747e-01,\n",
      "           2.7271e-01,  9.9901e-01]],\n",
      "\n",
      "        [[-2.8700e-01, -7.9350e-01,  4.6270e-01,  ...,  5.8172e-01,\n",
      "           6.8643e-01, -3.3274e+00],\n",
      "         [ 1.2067e-01, -3.9684e-01,  9.4758e-01,  ...,  8.9757e-01,\n",
      "           8.9176e-01, -4.8129e+00],\n",
      "         [ 3.4788e-01,  1.0281e+00,  6.2660e-01,  ..., -9.2050e-01,\n",
      "          -4.9468e-01,  3.0017e+00],\n",
      "         ...,\n",
      "         [-2.6405e-01, -8.9511e-01,  3.5011e-01,  ...,  4.6955e-01,\n",
      "           5.9926e-01, -3.3329e+00],\n",
      "         [-8.9508e-01, -7.6916e-01, -5.6990e-01,  ..., -8.8688e-03,\n",
      "           2.4543e-01,  8.3116e-02],\n",
      "         [ 6.3303e-01, -6.8778e-02,  1.3499e+00,  ...,  8.7378e-01,\n",
      "           8.8885e-01, -4.4931e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9410e+00, -3.0644e-01,  1.4439e-01,  ...,  1.4399e+00,\n",
      "           1.3537e+00, -2.1022e+00],\n",
      "         [-2.2140e+00, -7.1635e-02,  4.1298e-01,  ..., -1.8784e-01,\n",
      "           2.5472e-01, -2.4628e+00],\n",
      "         [ 1.4258e+00,  9.1588e-01,  4.0732e-01,  ..., -1.8895e+00,\n",
      "          -1.6048e+00,  2.2437e+00],\n",
      "         ...,\n",
      "         [-1.6725e+00, -2.5664e-01, -1.6287e-02,  ...,  1.7337e+00,\n",
      "           1.4513e+00, -2.1567e+00],\n",
      "         [-1.5960e-01, -3.7264e-01, -3.6138e-01,  ...,  3.3912e+00,\n",
      "           2.4804e+00, -6.1017e-01],\n",
      "         [-2.0587e+00,  4.2933e-01,  8.0779e-01,  ..., -2.2442e+00,\n",
      "          -1.3507e+00, -2.0408e+00]],\n",
      "\n",
      "        [[ 1.5099e+00, -5.7556e-01,  8.5707e-01,  ..., -1.3370e+00,\n",
      "           7.5983e-01,  8.6677e-01],\n",
      "         [ 5.6939e-02, -4.2866e-01,  1.0132e+00,  ..., -1.1783e+00,\n",
      "           8.6405e-01,  7.9072e-01],\n",
      "         [-1.5017e+00,  1.4194e+00, -5.2937e-01,  ...,  8.3594e-01,\n",
      "           2.3391e-02, -9.9991e-01],\n",
      "         ...,\n",
      "         [ 1.5197e+00, -6.6674e-01,  8.7495e-01,  ..., -1.2485e+00,\n",
      "           7.3519e-01,  9.7399e-01],\n",
      "         [ 3.0519e+00, -6.7277e-01,  3.4313e-01,  ..., -8.4936e-01,\n",
      "          -3.2734e-02,  8.1304e-01],\n",
      "         [-1.7106e+00,  7.0434e-02,  1.0012e+00,  ..., -8.8759e-01,\n",
      "           9.4478e-01,  3.8784e-01]],\n",
      "\n",
      "        [[ 2.8405e-01,  7.7092e-01, -7.5718e-01,  ...,  1.5070e+00,\n",
      "           1.8289e+00,  2.0512e-01],\n",
      "         [ 5.1227e-01,  7.1680e-01, -2.6229e-01,  ...,  6.3357e-01,\n",
      "          -3.9181e-01,  3.8209e-01],\n",
      "         [-1.2126e-01, -7.3892e-01,  1.0977e+00,  ..., -1.2331e+00,\n",
      "          -2.3222e+00,  1.8062e-01],\n",
      "         ...,\n",
      "         [ 1.4999e-01,  8.6894e-01, -7.0896e-01,  ...,  1.7260e+00,\n",
      "           1.8832e+00,  1.6248e-01],\n",
      "         [-5.1832e-01,  4.9899e-01, -9.2183e-01,  ...,  1.8654e+00,\n",
      "           4.3273e+00, -2.8366e-01],\n",
      "         [ 9.6009e-01,  4.3814e-01,  4.7576e-01,  ..., -7.7323e-01,\n",
      "          -2.8565e+00,  6.5326e-01]]], grad_fn=<AddBackward0>), tensor([[[-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<SliceBackward0>), tensor([[[0.0170, 0.0161, 0.0188,  ..., 0.0148, 0.0117, 0.0158],\n",
      "         [0.0173, 0.0148, 0.0195,  ..., 0.0139, 0.0113, 0.0153],\n",
      "         [0.0138, 0.0150, 0.0117,  ..., 0.0166, 0.0211, 0.0152],\n",
      "         ...,\n",
      "         [0.0170, 0.0161, 0.0187,  ..., 0.0149, 0.0118, 0.0158],\n",
      "         [0.0158, 0.0177, 0.0153,  ..., 0.0169, 0.0146, 0.0169],\n",
      "         [0.0168, 0.0138, 0.0191,  ..., 0.0133, 0.0120, 0.0146]],\n",
      "\n",
      "        [[0.0177, 0.0151, 0.0146,  ..., 0.0149, 0.0182, 0.0149],\n",
      "         [0.0187, 0.0154, 0.0151,  ..., 0.0140, 0.0176, 0.0151],\n",
      "         [0.0131, 0.0164, 0.0168,  ..., 0.0165, 0.0121, 0.0168],\n",
      "         ...,\n",
      "         [0.0177, 0.0151, 0.0146,  ..., 0.0150, 0.0183, 0.0149],\n",
      "         [0.0147, 0.0150, 0.0147,  ..., 0.0167, 0.0177, 0.0146],\n",
      "         [0.0182, 0.0154, 0.0156,  ..., 0.0135, 0.0157, 0.0158]],\n",
      "\n",
      "        [[0.0168, 0.0109, 0.0142,  ..., 0.0150, 0.0161, 0.0109],\n",
      "         [0.0149, 0.0114, 0.0136,  ..., 0.0155, 0.0164, 0.0128],\n",
      "         [0.0135, 0.0222, 0.0175,  ..., 0.0164, 0.0149, 0.0220],\n",
      "         ...,\n",
      "         [0.0170, 0.0109, 0.0143,  ..., 0.0150, 0.0161, 0.0108],\n",
      "         [0.0195, 0.0123, 0.0159,  ..., 0.0146, 0.0156, 0.0103],\n",
      "         [0.0127, 0.0139, 0.0136,  ..., 0.0164, 0.0167, 0.0167]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0147, 0.0150, 0.0150,  ..., 0.0153, 0.0141, 0.0121],\n",
      "         [0.0140, 0.0151, 0.0155,  ..., 0.0167, 0.0130, 0.0126],\n",
      "         [0.0167, 0.0165, 0.0165,  ..., 0.0162, 0.0175, 0.0209],\n",
      "         ...,\n",
      "         [0.0148, 0.0150, 0.0150,  ..., 0.0152, 0.0142, 0.0120],\n",
      "         [0.0163, 0.0155, 0.0144,  ..., 0.0134, 0.0167, 0.0123],\n",
      "         [0.0134, 0.0151, 0.0158,  ..., 0.0184, 0.0126, 0.0145]],\n",
      "\n",
      "        [[0.0151, 0.0161, 0.0187,  ..., 0.0158, 0.0141, 0.0159],\n",
      "         [0.0165, 0.0152, 0.0198,  ..., 0.0173, 0.0144, 0.0152],\n",
      "         [0.0161, 0.0147, 0.0119,  ..., 0.0156, 0.0177, 0.0151],\n",
      "         ...,\n",
      "         [0.0150, 0.0162, 0.0185,  ..., 0.0156, 0.0141, 0.0160],\n",
      "         [0.0135, 0.0177, 0.0148,  ..., 0.0129, 0.0144, 0.0171],\n",
      "         [0.0181, 0.0138, 0.0195,  ..., 0.0191, 0.0149, 0.0142]],\n",
      "\n",
      "        [[0.0112, 0.0149, 0.0134,  ..., 0.0118, 0.0123, 0.0120],\n",
      "         [0.0128, 0.0151, 0.0135,  ..., 0.0114, 0.0126, 0.0125],\n",
      "         [0.0216, 0.0167, 0.0188,  ..., 0.0211, 0.0206, 0.0209],\n",
      "         ...,\n",
      "         [0.0111, 0.0149, 0.0133,  ..., 0.0118, 0.0123, 0.0120],\n",
      "         [0.0111, 0.0149, 0.0141,  ..., 0.0143, 0.0132, 0.0128],\n",
      "         [0.0163, 0.0155, 0.0149,  ..., 0.0122, 0.0138, 0.0142]]],\n",
      "       grad_fn=<SoftmaxBackward0>))\n",
      "\n",
      "all_output (tensor([[[-4.3626e-01, -2.3018e+00,  9.7527e-01,  ...,  2.1156e-01,\n",
      "           6.0662e-01, -4.9928e-01],\n",
      "         [-4.2386e-01, -2.2182e+00,  9.5649e-01,  ...,  4.2517e-01,\n",
      "           7.6385e-01, -3.7428e-01],\n",
      "         [ 5.3852e-01,  1.9011e+00, -5.3166e-01,  ..., -6.8861e-02,\n",
      "          -3.6535e-01,  1.0354e+00],\n",
      "         ...,\n",
      "         [-4.3924e-01, -2.2990e+00,  1.0060e+00,  ...,  1.1516e-01,\n",
      "           6.6356e-01, -4.7503e-01],\n",
      "         [-4.7746e-01, -8.7078e-01,  8.8662e-01,  ..., -2.4822e-01,\n",
      "           7.4797e-02, -7.5947e-01],\n",
      "         [-2.1842e-01, -1.7358e+00,  7.0334e-01,  ...,  7.1917e-01,\n",
      "           8.6305e-01,  1.9747e-01]],\n",
      "\n",
      "        [[-5.7568e-01,  1.0596e-01,  1.3799e-01,  ...,  4.2550e-02,\n",
      "           3.9809e-01,  5.3815e-02],\n",
      "         [-3.6686e-01,  2.8751e-01,  6.2892e-01,  ...,  3.1220e-01,\n",
      "           3.6637e-01,  4.5292e-01],\n",
      "         [ 9.9382e-01,  1.2502e-01,  4.4348e-01,  ..., -2.0507e-01,\n",
      "          -5.5755e-01,  2.4661e-01],\n",
      "         ...,\n",
      "         [-7.0978e-01,  6.9703e-02,  1.2618e-01,  ...,  3.0985e-03,\n",
      "           4.2132e-01, -2.8642e-02],\n",
      "         [-8.1810e-01, -2.2198e-01, -5.8070e-01,  ..., -3.3696e-01,\n",
      "           3.0205e-01, -7.8667e-01],\n",
      "         [ 2.1910e-01,  6.7398e-01,  1.2403e+00,  ...,  5.9747e-01,\n",
      "           2.7271e-01,  9.9901e-01]],\n",
      "\n",
      "        [[-2.8700e-01, -7.9350e-01,  4.6270e-01,  ...,  5.8172e-01,\n",
      "           6.8643e-01, -3.3274e+00],\n",
      "         [ 1.2067e-01, -3.9684e-01,  9.4758e-01,  ...,  8.9757e-01,\n",
      "           8.9176e-01, -4.8129e+00],\n",
      "         [ 3.4788e-01,  1.0281e+00,  6.2660e-01,  ..., -9.2050e-01,\n",
      "          -4.9468e-01,  3.0017e+00],\n",
      "         ...,\n",
      "         [-2.6405e-01, -8.9511e-01,  3.5011e-01,  ...,  4.6955e-01,\n",
      "           5.9926e-01, -3.3329e+00],\n",
      "         [-8.9508e-01, -7.6916e-01, -5.6990e-01,  ..., -8.8688e-03,\n",
      "           2.4543e-01,  8.3116e-02],\n",
      "         [ 6.3303e-01, -6.8778e-02,  1.3499e+00,  ...,  8.7378e-01,\n",
      "           8.8885e-01, -4.4931e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9410e+00, -3.0644e-01,  1.4439e-01,  ...,  1.4399e+00,\n",
      "           1.3537e+00, -2.1022e+00],\n",
      "         [-2.2140e+00, -7.1635e-02,  4.1298e-01,  ..., -1.8784e-01,\n",
      "           2.5472e-01, -2.4628e+00],\n",
      "         [ 1.4258e+00,  9.1588e-01,  4.0732e-01,  ..., -1.8895e+00,\n",
      "          -1.6048e+00,  2.2437e+00],\n",
      "         ...,\n",
      "         [-1.6725e+00, -2.5664e-01, -1.6287e-02,  ...,  1.7337e+00,\n",
      "           1.4513e+00, -2.1567e+00],\n",
      "         [-1.5960e-01, -3.7264e-01, -3.6138e-01,  ...,  3.3912e+00,\n",
      "           2.4804e+00, -6.1017e-01],\n",
      "         [-2.0587e+00,  4.2933e-01,  8.0779e-01,  ..., -2.2442e+00,\n",
      "          -1.3507e+00, -2.0408e+00]],\n",
      "\n",
      "        [[ 1.5099e+00, -5.7556e-01,  8.5707e-01,  ..., -1.3370e+00,\n",
      "           7.5983e-01,  8.6677e-01],\n",
      "         [ 5.6939e-02, -4.2866e-01,  1.0132e+00,  ..., -1.1783e+00,\n",
      "           8.6405e-01,  7.9072e-01],\n",
      "         [-1.5017e+00,  1.4194e+00, -5.2937e-01,  ...,  8.3594e-01,\n",
      "           2.3391e-02, -9.9991e-01],\n",
      "         ...,\n",
      "         [ 1.5197e+00, -6.6674e-01,  8.7495e-01,  ..., -1.2485e+00,\n",
      "           7.3519e-01,  9.7399e-01],\n",
      "         [ 3.0519e+00, -6.7277e-01,  3.4313e-01,  ..., -8.4936e-01,\n",
      "          -3.2734e-02,  8.1304e-01],\n",
      "         [-1.7106e+00,  7.0434e-02,  1.0012e+00,  ..., -8.8759e-01,\n",
      "           9.4478e-01,  3.8784e-01]],\n",
      "\n",
      "        [[ 2.8405e-01,  7.7092e-01, -7.5718e-01,  ...,  1.5070e+00,\n",
      "           1.8289e+00,  2.0512e-01],\n",
      "         [ 5.1227e-01,  7.1680e-01, -2.6229e-01,  ...,  6.3357e-01,\n",
      "          -3.9181e-01,  3.8209e-01],\n",
      "         [-1.2126e-01, -7.3892e-01,  1.0977e+00,  ..., -1.2331e+00,\n",
      "          -2.3222e+00,  1.8062e-01],\n",
      "         ...,\n",
      "         [ 1.4999e-01,  8.6894e-01, -7.0896e-01,  ...,  1.7260e+00,\n",
      "           1.8832e+00,  1.6248e-01],\n",
      "         [-5.1832e-01,  4.9899e-01, -9.2183e-01,  ...,  1.8654e+00,\n",
      "           4.3273e+00, -2.8366e-01],\n",
      "         [ 9.6009e-01,  4.3814e-01,  4.7576e-01,  ..., -7.7323e-01,\n",
      "          -2.8565e+00,  6.5326e-01]]], grad_fn=<AddBackward0>), tensor([[[-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         ...,\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854],\n",
      "         [-0.4928, -0.7118,  0.2758,  ...,  0.0214,  0.1900, -0.2854]],\n",
      "\n",
      "        [[-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         ...,\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334],\n",
      "         [-0.1312, -0.0783,  0.0265,  ...,  0.0529,  0.2577, -0.0334]],\n",
      "\n",
      "        [[-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         ...,\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215],\n",
      "         [-0.1718, -0.3754, -0.0772,  ...,  0.2582,  0.2481, -1.2215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         ...,\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976],\n",
      "         [-0.7026, -0.2040, -0.0576,  ...,  1.0744,  0.8866, -0.7976]],\n",
      "\n",
      "        [[ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         ...,\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002],\n",
      "         [ 0.8795, -0.2274,  0.3597,  ..., -0.4406,  0.0097,  0.5002]],\n",
      "\n",
      "        [[ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         ...,\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679],\n",
      "         [ 0.1109,  0.4274, -0.2283,  ...,  0.7243,  1.1348,  0.1679]]],\n",
      "       grad_fn=<SliceBackward0>), tensor([[[0.0170, 0.0161, 0.0188,  ..., 0.0148, 0.0117, 0.0158],\n",
      "         [0.0173, 0.0148, 0.0195,  ..., 0.0139, 0.0113, 0.0153],\n",
      "         [0.0138, 0.0150, 0.0117,  ..., 0.0166, 0.0211, 0.0152],\n",
      "         ...,\n",
      "         [0.0170, 0.0161, 0.0187,  ..., 0.0149, 0.0118, 0.0158],\n",
      "         [0.0158, 0.0177, 0.0153,  ..., 0.0169, 0.0146, 0.0169],\n",
      "         [0.0168, 0.0138, 0.0191,  ..., 0.0133, 0.0120, 0.0146]],\n",
      "\n",
      "        [[0.0177, 0.0151, 0.0146,  ..., 0.0149, 0.0182, 0.0149],\n",
      "         [0.0187, 0.0154, 0.0151,  ..., 0.0140, 0.0176, 0.0151],\n",
      "         [0.0131, 0.0164, 0.0168,  ..., 0.0165, 0.0121, 0.0168],\n",
      "         ...,\n",
      "         [0.0177, 0.0151, 0.0146,  ..., 0.0150, 0.0183, 0.0149],\n",
      "         [0.0147, 0.0150, 0.0147,  ..., 0.0167, 0.0177, 0.0146],\n",
      "         [0.0182, 0.0154, 0.0156,  ..., 0.0135, 0.0157, 0.0158]],\n",
      "\n",
      "        [[0.0168, 0.0109, 0.0142,  ..., 0.0150, 0.0161, 0.0109],\n",
      "         [0.0149, 0.0114, 0.0136,  ..., 0.0155, 0.0164, 0.0128],\n",
      "         [0.0135, 0.0222, 0.0175,  ..., 0.0164, 0.0149, 0.0220],\n",
      "         ...,\n",
      "         [0.0170, 0.0109, 0.0143,  ..., 0.0150, 0.0161, 0.0108],\n",
      "         [0.0195, 0.0123, 0.0159,  ..., 0.0146, 0.0156, 0.0103],\n",
      "         [0.0127, 0.0139, 0.0136,  ..., 0.0164, 0.0167, 0.0167]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0147, 0.0150, 0.0150,  ..., 0.0153, 0.0141, 0.0121],\n",
      "         [0.0140, 0.0151, 0.0155,  ..., 0.0167, 0.0130, 0.0126],\n",
      "         [0.0167, 0.0165, 0.0165,  ..., 0.0162, 0.0175, 0.0209],\n",
      "         ...,\n",
      "         [0.0148, 0.0150, 0.0150,  ..., 0.0152, 0.0142, 0.0120],\n",
      "         [0.0163, 0.0155, 0.0144,  ..., 0.0134, 0.0167, 0.0123],\n",
      "         [0.0134, 0.0151, 0.0158,  ..., 0.0184, 0.0126, 0.0145]],\n",
      "\n",
      "        [[0.0151, 0.0161, 0.0187,  ..., 0.0158, 0.0141, 0.0159],\n",
      "         [0.0165, 0.0152, 0.0198,  ..., 0.0173, 0.0144, 0.0152],\n",
      "         [0.0161, 0.0147, 0.0119,  ..., 0.0156, 0.0177, 0.0151],\n",
      "         ...,\n",
      "         [0.0150, 0.0162, 0.0185,  ..., 0.0156, 0.0141, 0.0160],\n",
      "         [0.0135, 0.0177, 0.0148,  ..., 0.0129, 0.0144, 0.0171],\n",
      "         [0.0181, 0.0138, 0.0195,  ..., 0.0191, 0.0149, 0.0142]],\n",
      "\n",
      "        [[0.0112, 0.0149, 0.0134,  ..., 0.0118, 0.0123, 0.0120],\n",
      "         [0.0128, 0.0151, 0.0135,  ..., 0.0114, 0.0126, 0.0125],\n",
      "         [0.0216, 0.0167, 0.0188,  ..., 0.0211, 0.0206, 0.0209],\n",
      "         ...,\n",
      "         [0.0111, 0.0149, 0.0133,  ..., 0.0118, 0.0123, 0.0120],\n",
      "         [0.0111, 0.0149, 0.0141,  ..., 0.0143, 0.0132, 0.0128],\n",
      "         [0.0163, 0.0155, 0.0149,  ..., 0.0122, 0.0138, 0.0142]]],\n",
      "       grad_fn=<SoftmaxBackward0>))\n",
      "all_input hidden_states torch.Size([32, 64, 384]) output_attentions True\n",
      "prev_group_token torch.Size([32, 64, 384])\n",
      "\n",
      ".expand(hidden_states.size(0), -1, -1) input self.group_token torch.Size([1, 8, 384])\n",
      ".expand(hidden_states.size(0), -1, -1) output group_token torch.Size([32, 8, 384])\n",
      "\n",
      "self.group_projector input prev_group_token torch.Size([32, 64, 384])\n",
      "self.group_projector output temp torch.Size([32, 8, 384])\n",
      "\n",
      "+= input group_token torch.Size([32, 8, 384]) temp torch.Size([32, 8, 384])\n",
      "+= output group_token torch.Size([32, 8, 384])\n",
      "\n",
      "= input hidden_states torch.Size([32, 64, 384])\n",
      "= output x torch.Size([32, 64, 384])\n",
      "\n",
      "self.concat_x input x torch.Size([32, 64, 384])\n",
      "group_token torch.Size([32, 8, 384])\n",
      "self.concat_x output cat_x torch.Size([32, 72, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 72, 384]) None None\n",
      "layer output layer_out (tensor([[[-3.1393e-01, -2.3621e+00,  1.2451e+00,  ...,  4.2409e-01,\n",
      "           7.9355e-01, -6.8526e-01],\n",
      "         [-5.1386e-02, -2.0853e+00,  1.2267e+00,  ...,  6.9139e-01,\n",
      "           9.2860e-01, -6.0512e-01],\n",
      "         [ 4.4031e-01,  2.0744e+00, -4.8090e-01,  ..., -1.5523e-02,\n",
      "          -6.5917e-01,  1.1862e+00],\n",
      "         ...,\n",
      "         [ 2.5688e-01,  2.0457e-01,  3.8329e-01,  ...,  1.4449e-02,\n",
      "          -1.4937e-01, -2.6719e-01],\n",
      "         [-9.6844e-02,  5.2273e-02,  3.4562e-01,  ...,  5.4013e-02,\n",
      "          -6.2185e-02, -1.1457e-01],\n",
      "         [-1.1334e-02,  2.0659e-01,  3.2145e-01,  ..., -1.5743e-02,\n",
      "          -1.6205e-01, -1.0878e-01]],\n",
      "\n",
      "        [[-3.1954e-01,  5.2159e-01,  1.0622e-02,  ...,  2.8150e-02,\n",
      "           4.8739e-01,  1.4614e-01],\n",
      "         [-1.2730e-01,  8.1590e-01,  4.9615e-01,  ...,  3.9214e-01,\n",
      "           5.7714e-01,  5.5308e-01],\n",
      "         [ 9.1041e-01,  2.0732e-01,  6.0336e-01,  ...,  1.0925e-01,\n",
      "          -5.7774e-01,  3.9983e-01],\n",
      "         ...,\n",
      "         [ 5.0032e-02,  8.2003e-02, -7.1139e-02,  ..., -5.7787e-02,\n",
      "          -1.0167e-02, -4.9555e-02],\n",
      "         [ 1.2793e-01,  2.0821e-01,  2.2021e-02,  ..., -6.0895e-02,\n",
      "          -1.2801e-01, -2.4885e-02],\n",
      "         [ 9.7333e-02,  1.7395e-01,  4.5209e-02,  ..., -1.6100e-02,\n",
      "          -9.7430e-02, -5.8263e-02]],\n",
      "\n",
      "        [[-4.2760e-01, -3.1109e-01,  6.9889e-01,  ...,  7.5490e-01,\n",
      "           9.1191e-01, -3.4432e+00],\n",
      "         [ 5.2035e-03,  3.0157e-02,  1.0552e+00,  ...,  1.0336e+00,\n",
      "           1.1418e+00, -5.2031e+00],\n",
      "         [ 2.5893e-01,  9.6911e-01,  6.3533e-01,  ..., -1.0179e+00,\n",
      "          -3.6523e-01,  3.2683e+00],\n",
      "         ...,\n",
      "         [ 1.3654e-01, -7.9236e-02,  1.3622e-01,  ..., -1.2659e-01,\n",
      "          -7.6108e-02, -5.6832e-01],\n",
      "         [-5.0511e-04,  2.7892e-01,  9.8636e-02,  ..., -3.8926e-02,\n",
      "          -1.5720e-01, -2.0745e-01],\n",
      "         [ 7.9132e-02,  9.0163e-02, -3.1930e-03,  ..., -2.6380e-02,\n",
      "          -1.3584e-01, -2.7295e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9560e+00, -7.9286e-02,  5.2809e-03,  ...,  1.6642e+00,\n",
      "           1.5227e+00, -1.8350e+00],\n",
      "         [-2.2123e+00,  1.1122e-01,  3.0082e-01,  ..., -5.6061e-02,\n",
      "           3.5797e-01, -2.2544e+00],\n",
      "         [ 1.3438e+00,  8.8196e-01,  4.6446e-01,  ..., -1.9700e+00,\n",
      "          -1.5273e+00,  2.1742e+00],\n",
      "         ...,\n",
      "         [ 3.1296e-02,  1.2781e-01,  1.8677e-01,  ..., -1.5298e-01,\n",
      "          -3.7734e-02, -3.0351e-01],\n",
      "         [ 8.1362e-02,  1.6476e-01,  4.3461e-02,  ...,  1.6859e-01,\n",
      "           1.9681e-01, -5.5239e-02],\n",
      "         [ 9.6037e-02,  1.8237e-01,  1.6921e-01,  ...,  3.1787e-02,\n",
      "           6.6878e-02, -1.4672e-01]],\n",
      "\n",
      "        [[ 1.7009e+00, -3.6061e-01,  9.4295e-01,  ..., -1.4087e+00,\n",
      "           1.1204e+00,  5.8390e-01],\n",
      "         [ 2.1205e-01, -1.5891e-01,  9.5530e-01,  ..., -1.2211e+00,\n",
      "           1.1069e+00,  6.3178e-01],\n",
      "         [-1.7212e+00,  1.3995e+00, -4.4232e-01,  ...,  8.8750e-01,\n",
      "          -4.1836e-01, -4.9304e-01],\n",
      "         ...,\n",
      "         [ 2.1081e-01,  2.0591e-01,  1.6595e-02,  ..., -1.8261e-01,\n",
      "          -1.5426e-01, -1.3989e-01],\n",
      "         [ 2.5675e-01,  2.2624e-01,  1.5755e-01,  ..., -5.9937e-02,\n",
      "           7.9946e-02, -2.5722e-01],\n",
      "         [ 1.4907e-01,  1.8903e-01,  5.4651e-02,  ..., -7.3258e-02,\n",
      "          -1.3943e-01, -2.1386e-01]],\n",
      "\n",
      "        [[ 5.0062e-01,  1.0301e+00, -1.0055e+00,  ...,  1.6423e+00,\n",
      "           2.0551e+00,  4.6720e-01],\n",
      "         [ 7.2134e-01,  9.9385e-01, -5.6540e-01,  ...,  8.3650e-01,\n",
      "          -1.4293e-01,  5.0636e-01],\n",
      "         [-1.5798e-01, -9.2440e-01,  1.4646e+00,  ..., -1.4947e+00,\n",
      "          -2.2661e+00,  3.3567e-01],\n",
      "         ...,\n",
      "         [ 2.4571e-01, -9.6904e-03,  5.1588e-02,  ...,  5.1549e-02,\n",
      "          -2.8688e-01, -2.1787e-01],\n",
      "         [ 1.0223e-01,  8.8182e-02, -3.7555e-02,  ...,  1.2366e-02,\n",
      "           3.6142e-02, -1.7270e-01],\n",
      "         [ 9.3999e-02,  4.0519e-03,  9.2677e-02,  ..., -2.0208e-02,\n",
      "          -1.0052e-01, -2.5077e-01]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 72, 384])\n",
      "= output cat_x torch.Size([32, 72, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 72, 384]) None None\n",
      "layer output layer_out (tensor([[[-1.8544e-01, -2.1838e+00,  1.3118e+00,  ...,  5.8456e-01,\n",
      "           9.4977e-01, -5.4677e-01],\n",
      "         [ 2.3393e-01, -1.8796e+00,  1.3026e+00,  ...,  7.0042e-01,\n",
      "           1.0465e+00, -4.5446e-01],\n",
      "         [ 5.5006e-01,  1.8225e+00, -3.8580e-01,  ..., -3.3504e-01,\n",
      "          -5.4194e-01,  9.5882e-01],\n",
      "         ...,\n",
      "         [ 7.1678e-01,  1.7617e-01,  8.6905e-01,  ...,  1.6063e-02,\n",
      "           8.1384e-02, -1.7013e-01],\n",
      "         [ 2.4290e-01,  1.1499e-01,  6.7412e-01,  ...,  6.8992e-02,\n",
      "           1.8734e-01,  1.4330e-01],\n",
      "         [ 3.4997e-01,  2.7540e-01,  6.6468e-01,  ..., -3.5706e-02,\n",
      "           1.5876e-01,  8.0264e-02]],\n",
      "\n",
      "        [[-1.1475e-01,  6.5663e-01, -2.6148e-01,  ...,  1.6517e-02,\n",
      "           5.1332e-01,  8.4631e-02],\n",
      "         [ 1.6948e-01,  8.6820e-01,  2.5334e-01,  ...,  3.6232e-01,\n",
      "           5.3353e-01,  5.4190e-01],\n",
      "         [ 1.3010e+00,  9.5751e-02,  3.4671e-01,  ...,  1.7707e-01,\n",
      "          -6.3590e-01,  7.1850e-01],\n",
      "         ...,\n",
      "         [ 6.8189e-01, -1.9444e-01,  1.1285e-01,  ...,  2.7114e-01,\n",
      "           4.2720e-01, -7.6824e-02],\n",
      "         [ 3.5846e-01,  2.8121e-03,  1.5945e-01,  ...,  2.8985e-01,\n",
      "           1.2588e-01, -9.0044e-02],\n",
      "         [ 4.1971e-01, -5.2117e-02,  2.6520e-01,  ...,  3.4093e-01,\n",
      "           2.6441e-01, -1.7636e-02]],\n",
      "\n",
      "        [[-2.4208e-01, -5.3381e-01,  7.5507e-01,  ...,  8.9377e-01,\n",
      "           8.9013e-01, -3.3028e+00],\n",
      "         [ 2.6737e-01, -1.6997e-01,  1.1803e+00,  ...,  1.1420e+00,\n",
      "           9.0824e-01, -4.9320e+00],\n",
      "         [ 4.9809e-01,  9.7664e-01,  4.3415e-01,  ..., -1.1042e+00,\n",
      "          -4.4553e-01,  3.1575e+00],\n",
      "         ...,\n",
      "         [ 4.5693e-01, -2.9558e-01,  4.2899e-01,  ...,  1.5578e-01,\n",
      "           3.7914e-01, -5.7836e-01],\n",
      "         [ 9.4220e-02,  6.4254e-02,  3.7936e-01,  ...,  1.6737e-01,\n",
      "           3.1818e-01, -2.3471e-01],\n",
      "         [ 2.7460e-01, -7.8603e-02,  2.9832e-01,  ...,  1.9395e-01,\n",
      "           3.4041e-01, -4.5120e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8955e+00, -1.3828e-01,  7.8480e-02,  ...,  1.7131e+00,\n",
      "           1.6865e+00, -1.7154e+00],\n",
      "         [-1.9805e+00, -5.7266e-02,  3.0670e-01,  ...,  4.7319e-02,\n",
      "           6.2237e-01, -2.2181e+00],\n",
      "         [ 1.5878e+00,  8.0448e-01,  4.1977e-01,  ..., -2.3444e+00,\n",
      "          -1.9634e+00,  2.1159e+00],\n",
      "         ...,\n",
      "         [ 2.8519e-01, -2.9718e-01,  3.9914e-01,  ..., -2.3021e-01,\n",
      "           2.2723e-01, -5.0326e-01],\n",
      "         [ 1.6002e-01, -9.2296e-02,  2.4188e-01,  ...,  1.6889e-01,\n",
      "           3.5579e-01, -6.3889e-02],\n",
      "         [ 2.5708e-01, -1.7562e-01,  3.7466e-01,  ...,  3.8535e-03,\n",
      "           3.0790e-01, -3.0479e-01]],\n",
      "\n",
      "        [[ 1.8532e+00, -1.0489e-01,  8.8726e-01,  ..., -1.3863e+00,\n",
      "           1.3175e+00,  8.9536e-01],\n",
      "         [ 2.3364e-01,  1.0202e-01,  8.4658e-01,  ..., -1.2504e+00,\n",
      "           1.4383e+00,  1.0155e+00],\n",
      "         [-1.2213e+00,  1.3061e+00, -5.3531e-01,  ...,  1.0782e+00,\n",
      "          -3.5252e-01, -4.5021e-01],\n",
      "         ...,\n",
      "         [ 4.2728e-01,  6.4192e-01,  1.2771e-01,  ..., -3.1242e-01,\n",
      "           3.7125e-01, -3.6579e-02],\n",
      "         [ 4.3767e-01,  4.2986e-01,  2.1757e-01,  ..., -3.4430e-01,\n",
      "           2.1006e-01, -3.2035e-02],\n",
      "         [ 3.6307e-01,  4.7153e-01,  2.0497e-01,  ..., -3.1976e-01,\n",
      "           1.6510e-01, -5.1711e-02]],\n",
      "\n",
      "        [[ 6.3112e-01,  9.9576e-01, -1.0550e+00,  ...,  1.9163e+00,\n",
      "           2.4026e+00,  9.4417e-01],\n",
      "         [ 8.7165e-01,  9.5245e-01, -5.1887e-01,  ...,  9.3383e-01,\n",
      "           1.2779e-01,  9.9131e-01],\n",
      "         [-9.7646e-02, -8.3841e-01,  1.4859e+00,  ..., -1.3557e+00,\n",
      "          -2.5620e+00,  3.7052e-01],\n",
      "         ...,\n",
      "         [ 3.8463e-01,  1.8033e-01,  3.3388e-01,  ...,  3.1189e-02,\n",
      "          -2.9844e-01, -6.2999e-02],\n",
      "         [ 2.6791e-01,  1.7203e-01,  1.5489e-01,  ...,  2.5748e-02,\n",
      "           1.6971e-01,  1.8076e-02],\n",
      "         [ 2.3378e-01,  1.6874e-01,  3.5359e-01,  ..., -3.2793e-03,\n",
      "           1.2024e-02, -1.2867e-01]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 72, 384])\n",
      "= output cat_x torch.Size([32, 72, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 72, 384]) None None\n",
      "layer output layer_out (tensor([[[-1.1866e-01, -2.0317e+00,  1.5035e+00,  ...,  5.0016e-01,\n",
      "           9.8199e-01, -4.7281e-01],\n",
      "         [ 2.9944e-01, -1.7773e+00,  1.4819e+00,  ...,  5.7277e-01,\n",
      "           9.4392e-01, -5.0936e-01],\n",
      "         [ 3.6673e-01,  1.8094e+00, -2.2452e-01,  ..., -6.8347e-01,\n",
      "          -6.3731e-01,  8.8558e-01],\n",
      "         ...,\n",
      "         [ 7.8899e-01,  3.1872e-01,  7.8409e-01,  ..., -2.5379e-01,\n",
      "           2.9177e-01, -9.4997e-02],\n",
      "         [ 3.4880e-01,  2.6270e-01,  7.3132e-01,  ..., -2.8981e-01,\n",
      "           3.2289e-01,  3.8426e-01],\n",
      "         [ 5.0472e-01,  4.0079e-01,  6.5461e-01,  ..., -3.8255e-01,\n",
      "           4.0389e-01,  2.1591e-01]],\n",
      "\n",
      "        [[-1.1350e-01,  5.4611e-01, -2.2039e-01,  ..., -1.2001e-01,\n",
      "           6.4300e-01,  1.3679e-02],\n",
      "         [ 1.5426e-01,  7.3309e-01,  3.5800e-01,  ...,  3.6276e-01,\n",
      "           4.1538e-01,  4.8570e-01],\n",
      "         [ 1.1393e+00,  4.8831e-01,  6.6681e-01,  ...,  2.7255e-01,\n",
      "          -5.5334e-01,  7.9628e-01],\n",
      "         ...,\n",
      "         [ 4.6286e-01,  1.5685e-01,  1.5849e-01,  ...,  3.5633e-01,\n",
      "           5.5084e-01,  2.1803e-01],\n",
      "         [ 2.6322e-01,  4.8171e-01,  2.0349e-01,  ...,  3.5059e-01,\n",
      "           4.3455e-01,  9.2082e-02],\n",
      "         [ 3.1243e-01,  3.6842e-01,  3.3671e-01,  ...,  5.0134e-01,\n",
      "           5.4317e-01,  8.6611e-02]],\n",
      "\n",
      "        [[-5.3395e-01, -4.6924e-01,  8.6476e-01,  ...,  5.6911e-01,\n",
      "           7.7444e-01, -3.1207e+00],\n",
      "         [ 1.9631e-01, -1.6328e-01,  1.3580e+00,  ...,  7.9741e-01,\n",
      "           7.0462e-01, -4.8023e+00],\n",
      "         [ 5.1062e-01,  1.2286e+00,  2.8414e-01,  ..., -1.1316e+00,\n",
      "          -8.7723e-02,  2.8377e+00],\n",
      "         ...,\n",
      "         [ 5.1914e-01, -1.9071e-02,  5.5422e-01,  ..., -1.8406e-01,\n",
      "           5.0503e-01, -4.3749e-01],\n",
      "         [-1.5101e-01,  5.3759e-01,  5.5875e-01,  ..., -1.4393e-01,\n",
      "           5.3255e-01, -1.6786e-01],\n",
      "         [ 1.9291e-01,  3.0107e-01,  5.2981e-01,  ..., -9.4157e-02,\n",
      "           5.2246e-01, -4.0039e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0758e+00, -2.8110e-01, -9.6799e-04,  ...,  1.7719e+00,\n",
      "           1.8603e+00, -1.7743e+00],\n",
      "         [-2.3537e+00, -2.2002e-01,  1.8094e-01,  ...,  5.3423e-02,\n",
      "           7.9321e-01, -2.2969e+00],\n",
      "         [ 1.5707e+00,  1.1593e+00,  3.4974e-01,  ..., -2.8533e+00,\n",
      "          -2.4165e+00,  2.1890e+00],\n",
      "         ...,\n",
      "         [ 7.3211e-02, -1.7870e-01,  2.8849e-01,  ..., -3.8257e-01,\n",
      "          -4.9452e-02, -4.3785e-01],\n",
      "         [-1.0009e-01, -1.1013e-01,  6.5394e-02,  ...,  1.9951e-01,\n",
      "           2.5954e-01,  1.0953e-01],\n",
      "         [ 5.5559e-02, -1.0348e-01,  2.1334e-01,  ...,  3.4810e-02,\n",
      "           1.8225e-01, -1.7393e-01]],\n",
      "\n",
      "        [[ 1.5409e+00,  1.1130e-01,  7.2708e-01,  ..., -1.3077e+00,\n",
      "           1.5259e+00,  8.9600e-01],\n",
      "         [-2.1475e-01,  2.6352e-01,  7.5387e-01,  ..., -1.1657e+00,\n",
      "           1.7699e+00,  1.0106e+00],\n",
      "         [-1.4400e+00,  9.7921e-01, -5.5867e-01,  ...,  8.0449e-01,\n",
      "          -2.1531e-01, -6.9949e-01],\n",
      "         ...,\n",
      "         [ 3.6015e-01,  7.5770e-01,  3.7437e-01,  ..., -5.6342e-01,\n",
      "           4.3159e-01, -1.6816e-01],\n",
      "         [ 3.2908e-01,  5.7570e-01,  3.9870e-01,  ..., -6.0687e-01,\n",
      "           4.4977e-01, -3.2908e-01],\n",
      "         [ 3.2019e-01,  6.6790e-01,  4.9567e-01,  ..., -6.3607e-01,\n",
      "           3.4622e-01, -3.3094e-01]],\n",
      "\n",
      "        [[ 4.6758e-01,  7.9727e-01, -7.7645e-01,  ...,  1.8512e+00,\n",
      "           2.1296e+00,  9.9505e-01],\n",
      "         [ 6.4607e-01,  8.4734e-01, -2.3256e-01,  ...,  7.7456e-01,\n",
      "          -9.0809e-03,  8.4600e-01],\n",
      "         [-2.9675e-03, -8.8407e-01,  1.1862e+00,  ..., -1.5151e+00,\n",
      "          -2.4303e+00,  3.0600e-01],\n",
      "         ...,\n",
      "         [ 2.3130e-01,  3.7051e-01,  4.8667e-01,  ..., -7.4302e-02,\n",
      "          -3.7595e-01,  7.7512e-03],\n",
      "         [ 1.0830e-01,  4.1176e-01,  2.5774e-01,  ..., -2.6188e-01,\n",
      "           1.7471e-01,  1.5062e-01],\n",
      "         [ 2.8180e-02,  4.7344e-01,  4.5556e-01,  ..., -2.5030e-01,\n",
      "           5.0971e-03,  2.0260e-03]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 72, 384])\n",
      "= output cat_x torch.Size([32, 72, 384])\n",
      "\n",
      "self.split_x input cat_x torch.Size([32, 72, 384])\n",
      "self.split_x output x torch.Size([32, 64, 384])\n",
      "group_token torch.Size([32, 8, 384])\n",
      "\n",
      "attention = None\n",
      "\n",
      "self.downsample input x torch.Size([32, 64, 384]) group_token tensor([[[ 0.6766,  0.3336,  0.4795,  ..., -0.4095,  0.4256, -0.1250],\n",
      "         [ 0.3422,  0.3756,  0.3731,  ..., -0.4178,  0.5023,  0.2104],\n",
      "         [ 0.7797,  0.3211,  0.7262,  ..., -0.3288,  0.3111, -0.0722],\n",
      "         ...,\n",
      "         [ 0.7890,  0.3187,  0.7841,  ..., -0.2538,  0.2918, -0.0950],\n",
      "         [ 0.3488,  0.2627,  0.7313,  ..., -0.2898,  0.3229,  0.3843],\n",
      "         [ 0.5047,  0.4008,  0.6546,  ..., -0.3826,  0.4039,  0.2159]],\n",
      "\n",
      "        [[ 0.3932,  0.1733,  0.2423,  ...,  0.3832,  0.8037,  0.1512],\n",
      "         [ 0.3524,  0.3532,  0.2672,  ...,  0.4764,  0.6773,  0.1662],\n",
      "         [ 0.4059,  0.2073,  0.1115,  ...,  0.3770,  0.6135,  0.1880],\n",
      "         ...,\n",
      "         [ 0.4629,  0.1569,  0.1585,  ...,  0.3563,  0.5508,  0.2180],\n",
      "         [ 0.2632,  0.4817,  0.2035,  ...,  0.3506,  0.4345,  0.0921],\n",
      "         [ 0.3124,  0.3684,  0.3367,  ...,  0.5013,  0.5432,  0.0866]],\n",
      "\n",
      "        [[ 0.5393, -0.1099,  0.4011,  ..., -0.1117,  0.4917, -0.4941],\n",
      "         [ 0.2340,  0.2061,  0.2708,  ..., -0.0699,  0.4359, -0.5056],\n",
      "         [ 0.5166, -0.0392,  0.5584,  ..., -0.1573,  0.5200, -0.4400],\n",
      "         ...,\n",
      "         [ 0.5191, -0.0191,  0.5542,  ..., -0.1841,  0.5050, -0.4375],\n",
      "         [-0.1510,  0.5376,  0.5587,  ..., -0.1439,  0.5325, -0.1679],\n",
      "         [ 0.1929,  0.3011,  0.5298,  ..., -0.0942,  0.5225, -0.4004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1707, -0.0354,  0.3046,  ..., -0.3113,  0.0119, -0.4208],\n",
      "         [ 0.2677,  0.0798,  0.2709,  ...,  0.0097,  0.1448, -0.1619],\n",
      "         [ 0.0864, -0.1681,  0.2610,  ..., -0.2998, -0.0295, -0.4104],\n",
      "         ...,\n",
      "         [ 0.0732, -0.1787,  0.2885,  ..., -0.3826, -0.0495, -0.4379],\n",
      "         [-0.1001, -0.1101,  0.0654,  ...,  0.1995,  0.2595,  0.1095],\n",
      "         [ 0.0556, -0.1035,  0.2133,  ...,  0.0348,  0.1822, -0.1739]],\n",
      "\n",
      "        [[ 0.5571,  0.7078,  0.4699,  ..., -0.4915,  0.2344, -0.1972],\n",
      "         [ 0.3755,  0.5304,  0.4036,  ..., -0.4384,  0.0101, -0.2532],\n",
      "         [ 0.4310,  0.8025,  0.4693,  ..., -0.5698,  0.3829, -0.1925],\n",
      "         ...,\n",
      "         [ 0.3601,  0.7577,  0.3744,  ..., -0.5634,  0.4316, -0.1682],\n",
      "         [ 0.3291,  0.5757,  0.3987,  ..., -0.6069,  0.4498, -0.3291],\n",
      "         [ 0.3202,  0.6679,  0.4957,  ..., -0.6361,  0.3462, -0.3309]],\n",
      "\n",
      "        [[ 0.0662,  0.4105,  0.7079,  ..., -0.1554, -0.2429, -0.1674],\n",
      "         [-0.1354,  0.5028,  0.5845,  ..., -0.2526,  0.0675, -0.1233],\n",
      "         [ 0.1868,  0.4378,  0.5267,  ..., -0.1141, -0.3215, -0.0418],\n",
      "         ...,\n",
      "         [ 0.2313,  0.3705,  0.4867,  ..., -0.0743, -0.3760,  0.0078],\n",
      "         [ 0.1083,  0.4118,  0.2577,  ..., -0.2619,  0.1747,  0.1506],\n",
      "         [ 0.0282,  0.4734,  0.4556,  ..., -0.2503,  0.0051,  0.0020]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "self.split_x output x torch.Size([32, 8, 384]) attention torch.Size([32, 8, 64])\n",
      "\n",
      "= input x torch.Size([32, 8, 384]) group_token tensor([[[ 0.6766,  0.3336,  0.4795,  ..., -0.4095,  0.4256, -0.1250],\n",
      "         [ 0.3422,  0.3756,  0.3731,  ..., -0.4178,  0.5023,  0.2104],\n",
      "         [ 0.7797,  0.3211,  0.7262,  ..., -0.3288,  0.3111, -0.0722],\n",
      "         ...,\n",
      "         [ 0.7890,  0.3187,  0.7841,  ..., -0.2538,  0.2918, -0.0950],\n",
      "         [ 0.3488,  0.2627,  0.7313,  ..., -0.2898,  0.3229,  0.3843],\n",
      "         [ 0.5047,  0.4008,  0.6546,  ..., -0.3826,  0.4039,  0.2159]],\n",
      "\n",
      "        [[ 0.3932,  0.1733,  0.2423,  ...,  0.3832,  0.8037,  0.1512],\n",
      "         [ 0.3524,  0.3532,  0.2672,  ...,  0.4764,  0.6773,  0.1662],\n",
      "         [ 0.4059,  0.2073,  0.1115,  ...,  0.3770,  0.6135,  0.1880],\n",
      "         ...,\n",
      "         [ 0.4629,  0.1569,  0.1585,  ...,  0.3563,  0.5508,  0.2180],\n",
      "         [ 0.2632,  0.4817,  0.2035,  ...,  0.3506,  0.4345,  0.0921],\n",
      "         [ 0.3124,  0.3684,  0.3367,  ...,  0.5013,  0.5432,  0.0866]],\n",
      "\n",
      "        [[ 0.5393, -0.1099,  0.4011,  ..., -0.1117,  0.4917, -0.4941],\n",
      "         [ 0.2340,  0.2061,  0.2708,  ..., -0.0699,  0.4359, -0.5056],\n",
      "         [ 0.5166, -0.0392,  0.5584,  ..., -0.1573,  0.5200, -0.4400],\n",
      "         ...,\n",
      "         [ 0.5191, -0.0191,  0.5542,  ..., -0.1841,  0.5050, -0.4375],\n",
      "         [-0.1510,  0.5376,  0.5587,  ..., -0.1439,  0.5325, -0.1679],\n",
      "         [ 0.1929,  0.3011,  0.5298,  ..., -0.0942,  0.5225, -0.4004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1707, -0.0354,  0.3046,  ..., -0.3113,  0.0119, -0.4208],\n",
      "         [ 0.2677,  0.0798,  0.2709,  ...,  0.0097,  0.1448, -0.1619],\n",
      "         [ 0.0864, -0.1681,  0.2610,  ..., -0.2998, -0.0295, -0.4104],\n",
      "         ...,\n",
      "         [ 0.0732, -0.1787,  0.2885,  ..., -0.3826, -0.0495, -0.4379],\n",
      "         [-0.1001, -0.1101,  0.0654,  ...,  0.1995,  0.2595,  0.1095],\n",
      "         [ 0.0556, -0.1035,  0.2133,  ...,  0.0348,  0.1822, -0.1739]],\n",
      "\n",
      "        [[ 0.5571,  0.7078,  0.4699,  ..., -0.4915,  0.2344, -0.1972],\n",
      "         [ 0.3755,  0.5304,  0.4036,  ..., -0.4384,  0.0101, -0.2532],\n",
      "         [ 0.4310,  0.8025,  0.4693,  ..., -0.5698,  0.3829, -0.1925],\n",
      "         ...,\n",
      "         [ 0.3601,  0.7577,  0.3744,  ..., -0.5634,  0.4316, -0.1682],\n",
      "         [ 0.3291,  0.5757,  0.3987,  ..., -0.6069,  0.4498, -0.3291],\n",
      "         [ 0.3202,  0.6679,  0.4957,  ..., -0.6361,  0.3462, -0.3309]],\n",
      "\n",
      "        [[ 0.0662,  0.4105,  0.7079,  ..., -0.1554, -0.2429, -0.1674],\n",
      "         [-0.1354,  0.5028,  0.5845,  ..., -0.2526,  0.0675, -0.1233],\n",
      "         [ 0.1868,  0.4378,  0.5267,  ..., -0.1141, -0.3215, -0.0418],\n",
      "         ...,\n",
      "         [ 0.2313,  0.3705,  0.4867,  ..., -0.0743, -0.3760,  0.0078],\n",
      "         [ 0.1083,  0.4118,  0.2577,  ..., -0.2619,  0.1747,  0.1506],\n",
      "         [ 0.0282,  0.4734,  0.4556,  ..., -0.2503,  0.0051,  0.0020]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "= output outputs (tensor([[[-1.6737e+00, -4.2574e-01, -1.3484e+00,  ...,  1.8625e+00,\n",
      "          -8.9482e-01,  1.6218e-02],\n",
      "         [ 6.7721e-01,  5.2524e-01,  1.4656e+00,  ..., -1.0143e+00,\n",
      "           4.9238e-01,  5.7811e-01],\n",
      "         [-1.4011e+00,  6.5544e-01, -9.8015e-01,  ...,  1.6932e-01,\n",
      "           1.0281e+00, -2.2329e-01],\n",
      "         ...,\n",
      "         [ 2.1939e+00,  2.0705e-01,  2.7165e+00,  ..., -2.1044e-01,\n",
      "           4.6835e-01,  5.0170e-01],\n",
      "         [ 1.9324e+00,  6.1273e-01,  3.0288e+00,  ..., -1.2688e+00,\n",
      "           8.3527e-01,  3.9033e-01],\n",
      "         [-1.4282e+00, -8.3125e-01, -1.3022e+00,  ...,  1.8573e+00,\n",
      "          -1.1446e+00, -4.0803e-01]],\n",
      "\n",
      "        [[-1.8493e+00, -5.5892e-01, -8.4111e-02,  ..., -3.5709e-01,\n",
      "          -3.4010e+00, -5.5246e-01],\n",
      "         [ 1.1157e+00,  1.1915e+00,  1.0722e+00,  ...,  1.0764e+00,\n",
      "           7.3745e-01,  1.2077e+00],\n",
      "         [ 2.5937e-02, -1.9195e-01,  1.2608e+00,  ...,  6.8623e-01,\n",
      "           7.3282e-01,  8.0911e-02],\n",
      "         ...,\n",
      "         [ 3.4716e-02,  1.3245e+00, -7.7263e-01,  ...,  6.1324e-01,\n",
      "           1.1284e+00, -6.3730e-01],\n",
      "         [ 1.6604e+00,  1.3521e+00,  9.3939e-01,  ...,  1.8103e+00,\n",
      "           2.0591e+00,  8.4936e-01],\n",
      "         [-1.6248e+00, -8.0330e-01, -5.2703e-01,  ..., -6.2102e-01,\n",
      "          -2.4400e+00, -5.0597e-01]],\n",
      "\n",
      "        [[-9.8393e-01, -4.3749e-02, -3.6822e-01,  ...,  1.3267e+00,\n",
      "          -1.7282e+00,  8.9377e-01],\n",
      "         [ 4.4975e-01,  1.4948e+00,  1.6369e+00,  ..., -4.1251e-01,\n",
      "           1.0194e+00, -1.3991e+00],\n",
      "         [ 6.5617e-01, -1.8850e-02, -1.3464e+00,  ..., -1.1377e-01,\n",
      "          -5.1295e-01,  2.6588e-01],\n",
      "         ...,\n",
      "         [-7.5476e-01,  4.3123e-01,  2.2688e+00,  ...,  3.9053e-01,\n",
      "           1.0745e+00,  5.2466e-01],\n",
      "         [ 6.7148e-01,  1.0501e+00,  2.0783e+00,  ..., -7.6045e-01,\n",
      "           1.8647e+00, -1.2109e+00],\n",
      "         [-9.9180e-01, -5.6313e-01, -5.8037e-01,  ...,  1.0183e+00,\n",
      "          -1.5183e+00,  1.4849e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9810e-01, -2.3077e-01, -5.1759e-01,  ...,  1.6643e+00,\n",
      "           5.6989e-05,  4.8064e-01],\n",
      "         [ 3.8337e-01,  4.1706e-01,  8.1536e-01,  ..., -6.1392e-01,\n",
      "           3.1309e-01, -7.1953e-01],\n",
      "         [ 7.8463e-01,  2.8225e-01,  2.7765e-01,  ..., -1.5607e-01,\n",
      "          -5.0440e-01,  2.6917e-01],\n",
      "         ...,\n",
      "         [-1.0335e+00, -9.5861e-01, -4.6956e-01,  ...,  1.6439e+00,\n",
      "           3.9715e-01,  1.2548e-01],\n",
      "         [ 1.8112e-01,  1.7488e-01,  5.8134e-01,  ..., -8.7004e-01,\n",
      "           1.3565e-02, -1.0348e+00],\n",
      "         [-6.6630e-01, -9.9602e-02, -8.4993e-01,  ...,  1.4646e+00,\n",
      "          -3.5578e-01,  9.1583e-01]],\n",
      "\n",
      "        [[-2.0704e+00, -1.8753e+00, -3.1550e-01,  ...,  4.4252e-01,\n",
      "          -2.0790e-01,  4.9932e-01],\n",
      "         [ 6.4748e-01,  7.1075e-01,  1.2811e+00,  ..., -1.6953e+00,\n",
      "           1.2276e+00, -8.8654e-01],\n",
      "         [-4.8667e-01, -1.2794e-01,  1.6510e-01,  ...,  1.4987e+00,\n",
      "          -2.1994e+00, -2.5282e-01],\n",
      "         ...,\n",
      "         [ 8.8613e-01,  2.3637e+00,  1.4388e+00,  ..., -1.1806e+00,\n",
      "           1.2172e+00, -2.7434e-01],\n",
      "         [ 1.4761e+00,  2.2917e+00,  1.8361e+00,  ..., -1.1541e+00,\n",
      "           1.4073e+00, -9.7508e-01],\n",
      "         [-1.3613e+00, -1.5479e+00, -9.1003e-01,  ...,  1.2876e+00,\n",
      "          -4.4465e-01,  6.8120e-01]],\n",
      "\n",
      "        [[-1.9890e-01, -7.8625e-01, -2.0259e+00,  ...,  1.0315e+00,\n",
      "           4.4467e-01,  7.7934e-01],\n",
      "         [ 8.5773e-01,  7.0451e-01,  9.6808e-01,  ..., -8.6379e-01,\n",
      "          -1.4219e-01,  3.0747e-01],\n",
      "         [-1.2819e+00, -2.6984e-01,  2.1523e+00,  ..., -4.6351e-01,\n",
      "          -2.2628e-01, -1.2240e+00],\n",
      "         ...,\n",
      "         [ 6.3994e-01,  1.6149e+00,  8.6649e-01,  ...,  4.9381e-01,\n",
      "           8.0326e-01,  5.4325e-01],\n",
      "         [ 6.0514e-01,  1.2362e+00,  1.7909e+00,  ..., -7.0366e-01,\n",
      "          -4.9815e-01,  5.2944e-02],\n",
      "         [-2.5250e-01, -1.1664e+00, -1.8056e+00,  ...,  8.6710e-01,\n",
      "           6.2511e-01,  4.6215e-01]]], grad_fn=<AddBackward0>), tensor([[[ 0.6766,  0.3336,  0.4795,  ..., -0.4095,  0.4256, -0.1250],\n",
      "         [ 0.3422,  0.3756,  0.3731,  ..., -0.4178,  0.5023,  0.2104],\n",
      "         [ 0.7797,  0.3211,  0.7262,  ..., -0.3288,  0.3111, -0.0722],\n",
      "         ...,\n",
      "         [ 0.7890,  0.3187,  0.7841,  ..., -0.2538,  0.2918, -0.0950],\n",
      "         [ 0.3488,  0.2627,  0.7313,  ..., -0.2898,  0.3229,  0.3843],\n",
      "         [ 0.5047,  0.4008,  0.6546,  ..., -0.3826,  0.4039,  0.2159]],\n",
      "\n",
      "        [[ 0.3932,  0.1733,  0.2423,  ...,  0.3832,  0.8037,  0.1512],\n",
      "         [ 0.3524,  0.3532,  0.2672,  ...,  0.4764,  0.6773,  0.1662],\n",
      "         [ 0.4059,  0.2073,  0.1115,  ...,  0.3770,  0.6135,  0.1880],\n",
      "         ...,\n",
      "         [ 0.4629,  0.1569,  0.1585,  ...,  0.3563,  0.5508,  0.2180],\n",
      "         [ 0.2632,  0.4817,  0.2035,  ...,  0.3506,  0.4345,  0.0921],\n",
      "         [ 0.3124,  0.3684,  0.3367,  ...,  0.5013,  0.5432,  0.0866]],\n",
      "\n",
      "        [[ 0.5393, -0.1099,  0.4011,  ..., -0.1117,  0.4917, -0.4941],\n",
      "         [ 0.2340,  0.2061,  0.2708,  ..., -0.0699,  0.4359, -0.5056],\n",
      "         [ 0.5166, -0.0392,  0.5584,  ..., -0.1573,  0.5200, -0.4400],\n",
      "         ...,\n",
      "         [ 0.5191, -0.0191,  0.5542,  ..., -0.1841,  0.5050, -0.4375],\n",
      "         [-0.1510,  0.5376,  0.5587,  ..., -0.1439,  0.5325, -0.1679],\n",
      "         [ 0.1929,  0.3011,  0.5298,  ..., -0.0942,  0.5225, -0.4004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1707, -0.0354,  0.3046,  ..., -0.3113,  0.0119, -0.4208],\n",
      "         [ 0.2677,  0.0798,  0.2709,  ...,  0.0097,  0.1448, -0.1619],\n",
      "         [ 0.0864, -0.1681,  0.2610,  ..., -0.2998, -0.0295, -0.4104],\n",
      "         ...,\n",
      "         [ 0.0732, -0.1787,  0.2885,  ..., -0.3826, -0.0495, -0.4379],\n",
      "         [-0.1001, -0.1101,  0.0654,  ...,  0.1995,  0.2595,  0.1095],\n",
      "         [ 0.0556, -0.1035,  0.2133,  ...,  0.0348,  0.1822, -0.1739]],\n",
      "\n",
      "        [[ 0.5571,  0.7078,  0.4699,  ..., -0.4915,  0.2344, -0.1972],\n",
      "         [ 0.3755,  0.5304,  0.4036,  ..., -0.4384,  0.0101, -0.2532],\n",
      "         [ 0.4310,  0.8025,  0.4693,  ..., -0.5698,  0.3829, -0.1925],\n",
      "         ...,\n",
      "         [ 0.3601,  0.7577,  0.3744,  ..., -0.5634,  0.4316, -0.1682],\n",
      "         [ 0.3291,  0.5757,  0.3987,  ..., -0.6069,  0.4498, -0.3291],\n",
      "         [ 0.3202,  0.6679,  0.4957,  ..., -0.6361,  0.3462, -0.3309]],\n",
      "\n",
      "        [[ 0.0662,  0.4105,  0.7079,  ..., -0.1554, -0.2429, -0.1674],\n",
      "         [-0.1354,  0.5028,  0.5845,  ..., -0.2526,  0.0675, -0.1233],\n",
      "         [ 0.1868,  0.4378,  0.5267,  ..., -0.1141, -0.3215, -0.0418],\n",
      "         ...,\n",
      "         [ 0.2313,  0.3705,  0.4867,  ..., -0.0743, -0.3760,  0.0078],\n",
      "         [ 0.1083,  0.4118,  0.2577,  ..., -0.2619,  0.1747,  0.1506],\n",
      "         [ 0.0282,  0.4734,  0.4556,  ..., -0.2503,  0.0051,  0.0020]]],\n",
      "       grad_fn=<SliceBackward0>))\n",
      "\n",
      "+= input outputs (tensor([[[-1.6737e+00, -4.2574e-01, -1.3484e+00,  ...,  1.8625e+00,\n",
      "          -8.9482e-01,  1.6218e-02],\n",
      "         [ 6.7721e-01,  5.2524e-01,  1.4656e+00,  ..., -1.0143e+00,\n",
      "           4.9238e-01,  5.7811e-01],\n",
      "         [-1.4011e+00,  6.5544e-01, -9.8015e-01,  ...,  1.6932e-01,\n",
      "           1.0281e+00, -2.2329e-01],\n",
      "         ...,\n",
      "         [ 2.1939e+00,  2.0705e-01,  2.7165e+00,  ..., -2.1044e-01,\n",
      "           4.6835e-01,  5.0170e-01],\n",
      "         [ 1.9324e+00,  6.1273e-01,  3.0288e+00,  ..., -1.2688e+00,\n",
      "           8.3527e-01,  3.9033e-01],\n",
      "         [-1.4282e+00, -8.3125e-01, -1.3022e+00,  ...,  1.8573e+00,\n",
      "          -1.1446e+00, -4.0803e-01]],\n",
      "\n",
      "        [[-1.8493e+00, -5.5892e-01, -8.4111e-02,  ..., -3.5709e-01,\n",
      "          -3.4010e+00, -5.5246e-01],\n",
      "         [ 1.1157e+00,  1.1915e+00,  1.0722e+00,  ...,  1.0764e+00,\n",
      "           7.3745e-01,  1.2077e+00],\n",
      "         [ 2.5937e-02, -1.9195e-01,  1.2608e+00,  ...,  6.8623e-01,\n",
      "           7.3282e-01,  8.0911e-02],\n",
      "         ...,\n",
      "         [ 3.4716e-02,  1.3245e+00, -7.7263e-01,  ...,  6.1324e-01,\n",
      "           1.1284e+00, -6.3730e-01],\n",
      "         [ 1.6604e+00,  1.3521e+00,  9.3939e-01,  ...,  1.8103e+00,\n",
      "           2.0591e+00,  8.4936e-01],\n",
      "         [-1.6248e+00, -8.0330e-01, -5.2703e-01,  ..., -6.2102e-01,\n",
      "          -2.4400e+00, -5.0597e-01]],\n",
      "\n",
      "        [[-9.8393e-01, -4.3749e-02, -3.6822e-01,  ...,  1.3267e+00,\n",
      "          -1.7282e+00,  8.9377e-01],\n",
      "         [ 4.4975e-01,  1.4948e+00,  1.6369e+00,  ..., -4.1251e-01,\n",
      "           1.0194e+00, -1.3991e+00],\n",
      "         [ 6.5617e-01, -1.8850e-02, -1.3464e+00,  ..., -1.1377e-01,\n",
      "          -5.1295e-01,  2.6588e-01],\n",
      "         ...,\n",
      "         [-7.5476e-01,  4.3123e-01,  2.2688e+00,  ...,  3.9053e-01,\n",
      "           1.0745e+00,  5.2466e-01],\n",
      "         [ 6.7148e-01,  1.0501e+00,  2.0783e+00,  ..., -7.6045e-01,\n",
      "           1.8647e+00, -1.2109e+00],\n",
      "         [-9.9180e-01, -5.6313e-01, -5.8037e-01,  ...,  1.0183e+00,\n",
      "          -1.5183e+00,  1.4849e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9810e-01, -2.3077e-01, -5.1759e-01,  ...,  1.6643e+00,\n",
      "           5.6989e-05,  4.8064e-01],\n",
      "         [ 3.8337e-01,  4.1706e-01,  8.1536e-01,  ..., -6.1392e-01,\n",
      "           3.1309e-01, -7.1953e-01],\n",
      "         [ 7.8463e-01,  2.8225e-01,  2.7765e-01,  ..., -1.5607e-01,\n",
      "          -5.0440e-01,  2.6917e-01],\n",
      "         ...,\n",
      "         [-1.0335e+00, -9.5861e-01, -4.6956e-01,  ...,  1.6439e+00,\n",
      "           3.9715e-01,  1.2548e-01],\n",
      "         [ 1.8112e-01,  1.7488e-01,  5.8134e-01,  ..., -8.7004e-01,\n",
      "           1.3565e-02, -1.0348e+00],\n",
      "         [-6.6630e-01, -9.9602e-02, -8.4993e-01,  ...,  1.4646e+00,\n",
      "          -3.5578e-01,  9.1583e-01]],\n",
      "\n",
      "        [[-2.0704e+00, -1.8753e+00, -3.1550e-01,  ...,  4.4252e-01,\n",
      "          -2.0790e-01,  4.9932e-01],\n",
      "         [ 6.4748e-01,  7.1075e-01,  1.2811e+00,  ..., -1.6953e+00,\n",
      "           1.2276e+00, -8.8654e-01],\n",
      "         [-4.8667e-01, -1.2794e-01,  1.6510e-01,  ...,  1.4987e+00,\n",
      "          -2.1994e+00, -2.5282e-01],\n",
      "         ...,\n",
      "         [ 8.8613e-01,  2.3637e+00,  1.4388e+00,  ..., -1.1806e+00,\n",
      "           1.2172e+00, -2.7434e-01],\n",
      "         [ 1.4761e+00,  2.2917e+00,  1.8361e+00,  ..., -1.1541e+00,\n",
      "           1.4073e+00, -9.7508e-01],\n",
      "         [-1.3613e+00, -1.5479e+00, -9.1003e-01,  ...,  1.2876e+00,\n",
      "          -4.4465e-01,  6.8120e-01]],\n",
      "\n",
      "        [[-1.9890e-01, -7.8625e-01, -2.0259e+00,  ...,  1.0315e+00,\n",
      "           4.4467e-01,  7.7934e-01],\n",
      "         [ 8.5773e-01,  7.0451e-01,  9.6808e-01,  ..., -8.6379e-01,\n",
      "          -1.4219e-01,  3.0747e-01],\n",
      "         [-1.2819e+00, -2.6984e-01,  2.1523e+00,  ..., -4.6351e-01,\n",
      "          -2.2628e-01, -1.2240e+00],\n",
      "         ...,\n",
      "         [ 6.3994e-01,  1.6149e+00,  8.6649e-01,  ...,  4.9381e-01,\n",
      "           8.0326e-01,  5.4325e-01],\n",
      "         [ 6.0514e-01,  1.2362e+00,  1.7909e+00,  ..., -7.0366e-01,\n",
      "          -4.9815e-01,  5.2944e-02],\n",
      "         [-2.5250e-01, -1.1664e+00, -1.8056e+00,  ...,  8.6710e-01,\n",
      "           6.2511e-01,  4.6215e-01]]], grad_fn=<AddBackward0>), tensor([[[ 0.6766,  0.3336,  0.4795,  ..., -0.4095,  0.4256, -0.1250],\n",
      "         [ 0.3422,  0.3756,  0.3731,  ..., -0.4178,  0.5023,  0.2104],\n",
      "         [ 0.7797,  0.3211,  0.7262,  ..., -0.3288,  0.3111, -0.0722],\n",
      "         ...,\n",
      "         [ 0.7890,  0.3187,  0.7841,  ..., -0.2538,  0.2918, -0.0950],\n",
      "         [ 0.3488,  0.2627,  0.7313,  ..., -0.2898,  0.3229,  0.3843],\n",
      "         [ 0.5047,  0.4008,  0.6546,  ..., -0.3826,  0.4039,  0.2159]],\n",
      "\n",
      "        [[ 0.3932,  0.1733,  0.2423,  ...,  0.3832,  0.8037,  0.1512],\n",
      "         [ 0.3524,  0.3532,  0.2672,  ...,  0.4764,  0.6773,  0.1662],\n",
      "         [ 0.4059,  0.2073,  0.1115,  ...,  0.3770,  0.6135,  0.1880],\n",
      "         ...,\n",
      "         [ 0.4629,  0.1569,  0.1585,  ...,  0.3563,  0.5508,  0.2180],\n",
      "         [ 0.2632,  0.4817,  0.2035,  ...,  0.3506,  0.4345,  0.0921],\n",
      "         [ 0.3124,  0.3684,  0.3367,  ...,  0.5013,  0.5432,  0.0866]],\n",
      "\n",
      "        [[ 0.5393, -0.1099,  0.4011,  ..., -0.1117,  0.4917, -0.4941],\n",
      "         [ 0.2340,  0.2061,  0.2708,  ..., -0.0699,  0.4359, -0.5056],\n",
      "         [ 0.5166, -0.0392,  0.5584,  ..., -0.1573,  0.5200, -0.4400],\n",
      "         ...,\n",
      "         [ 0.5191, -0.0191,  0.5542,  ..., -0.1841,  0.5050, -0.4375],\n",
      "         [-0.1510,  0.5376,  0.5587,  ..., -0.1439,  0.5325, -0.1679],\n",
      "         [ 0.1929,  0.3011,  0.5298,  ..., -0.0942,  0.5225, -0.4004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1707, -0.0354,  0.3046,  ..., -0.3113,  0.0119, -0.4208],\n",
      "         [ 0.2677,  0.0798,  0.2709,  ...,  0.0097,  0.1448, -0.1619],\n",
      "         [ 0.0864, -0.1681,  0.2610,  ..., -0.2998, -0.0295, -0.4104],\n",
      "         ...,\n",
      "         [ 0.0732, -0.1787,  0.2885,  ..., -0.3826, -0.0495, -0.4379],\n",
      "         [-0.1001, -0.1101,  0.0654,  ...,  0.1995,  0.2595,  0.1095],\n",
      "         [ 0.0556, -0.1035,  0.2133,  ...,  0.0348,  0.1822, -0.1739]],\n",
      "\n",
      "        [[ 0.5571,  0.7078,  0.4699,  ..., -0.4915,  0.2344, -0.1972],\n",
      "         [ 0.3755,  0.5304,  0.4036,  ..., -0.4384,  0.0101, -0.2532],\n",
      "         [ 0.4310,  0.8025,  0.4693,  ..., -0.5698,  0.3829, -0.1925],\n",
      "         ...,\n",
      "         [ 0.3601,  0.7577,  0.3744,  ..., -0.5634,  0.4316, -0.1682],\n",
      "         [ 0.3291,  0.5757,  0.3987,  ..., -0.6069,  0.4498, -0.3291],\n",
      "         [ 0.3202,  0.6679,  0.4957,  ..., -0.6361,  0.3462, -0.3309]],\n",
      "\n",
      "        [[ 0.0662,  0.4105,  0.7079,  ..., -0.1554, -0.2429, -0.1674],\n",
      "         [-0.1354,  0.5028,  0.5845,  ..., -0.2526,  0.0675, -0.1233],\n",
      "         [ 0.1868,  0.4378,  0.5267,  ..., -0.1141, -0.3215, -0.0418],\n",
      "         ...,\n",
      "         [ 0.2313,  0.3705,  0.4867,  ..., -0.0743, -0.3760,  0.0078],\n",
      "         [ 0.1083,  0.4118,  0.2577,  ..., -0.2619,  0.1747,  0.1506],\n",
      "         [ 0.0282,  0.4734,  0.4556,  ..., -0.2503,  0.0051,  0.0020]]],\n",
      "       grad_fn=<SliceBackward0>)) attention tensor([[[0.1293, 0.1233, 0.1146,  ..., 0.1312, 0.1437, 0.1164],\n",
      "         [0.1203, 0.1300, 0.1350,  ..., 0.1199, 0.1035, 0.1376],\n",
      "         [0.1417, 0.1366, 0.1182,  ..., 0.1409, 0.1353, 0.1310],\n",
      "         ...,\n",
      "         [0.1189, 0.1166, 0.1239,  ..., 0.1178, 0.1242, 0.1157],\n",
      "         [0.1172, 0.1294, 0.1392,  ..., 0.1154, 0.0971, 0.1427],\n",
      "         [0.1320, 0.1272, 0.1154,  ..., 0.1335, 0.1432, 0.1205]],\n",
      "\n",
      "        [[0.1696, 0.1664, 0.0877,  ..., 0.1683, 0.1525, 0.1509],\n",
      "         [0.1016, 0.1009, 0.1405,  ..., 0.1019, 0.1115, 0.1076],\n",
      "         [0.0881, 0.0938, 0.1873,  ..., 0.0886, 0.0996, 0.1100],\n",
      "         ...,\n",
      "         [0.1316, 0.1287, 0.1009,  ..., 0.1315, 0.1359, 0.1229],\n",
      "         [0.0969, 0.0946, 0.1442,  ..., 0.0983, 0.1141, 0.0997],\n",
      "         [0.1649, 0.1642, 0.0919,  ..., 0.1656, 0.1513, 0.1514]],\n",
      "\n",
      "        [[0.1218, 0.1331, 0.1252,  ..., 0.1200, 0.1077, 0.1441],\n",
      "         [0.1148, 0.1091, 0.1325,  ..., 0.1150, 0.1212, 0.1090],\n",
      "         [0.1426, 0.1394, 0.1187,  ..., 0.1431, 0.1433, 0.1302],\n",
      "         ...,\n",
      "         [0.1364, 0.1351, 0.1125,  ..., 0.1379, 0.1376, 0.1274],\n",
      "         [0.1212, 0.1148, 0.1265,  ..., 0.1219, 0.1287, 0.1121],\n",
      "         [0.1227, 0.1356, 0.1298,  ..., 0.1215, 0.1098, 0.1487]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1414, 0.1519, 0.1167,  ..., 0.1399, 0.1227, 0.1595],\n",
      "         [0.1102, 0.1051, 0.1252,  ..., 0.1106, 0.1236, 0.1006],\n",
      "         [0.1614, 0.1483, 0.1001,  ..., 0.1641, 0.1558, 0.1209],\n",
      "         ...,\n",
      "         [0.1050, 0.1041, 0.1506,  ..., 0.1037, 0.1136, 0.1123],\n",
      "         [0.1090, 0.1021, 0.1300,  ..., 0.1093, 0.1266, 0.0969],\n",
      "         [0.1529, 0.1558, 0.1119,  ..., 0.1514, 0.1383, 0.1541]],\n",
      "\n",
      "        [[0.0998, 0.1117, 0.1561,  ..., 0.1002, 0.0903, 0.1286],\n",
      "         [0.1596, 0.1514, 0.0953,  ..., 0.1561, 0.1556, 0.1376],\n",
      "         [0.1232, 0.1109, 0.1159,  ..., 0.1277, 0.1476, 0.1018],\n",
      "         ...,\n",
      "         [0.1024, 0.1097, 0.1424,  ..., 0.1031, 0.1021, 0.1175],\n",
      "         [0.1546, 0.1464, 0.0956,  ..., 0.1526, 0.1533, 0.1332],\n",
      "         [0.0952, 0.1077, 0.1579,  ..., 0.0970, 0.0876, 0.1255]],\n",
      "\n",
      "        [[0.1474, 0.1456, 0.1032,  ..., 0.1481, 0.1534, 0.1374],\n",
      "         [0.1121, 0.1107, 0.1373,  ..., 0.1109, 0.1118, 0.1124],\n",
      "         [0.1047, 0.1039, 0.1349,  ..., 0.1040, 0.1069, 0.1098],\n",
      "         ...,\n",
      "         [0.1399, 0.1448, 0.1168,  ..., 0.1426, 0.1299, 0.1449],\n",
      "         [0.1064, 0.1071, 0.1503,  ..., 0.1059, 0.1058, 0.1129],\n",
      "         [0.1387, 0.1372, 0.1069,  ..., 0.1393, 0.1498, 0.1335]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "+= output outputs (tensor([[[-1.6737e+00, -4.2574e-01, -1.3484e+00,  ...,  1.8625e+00,\n",
      "          -8.9482e-01,  1.6218e-02],\n",
      "         [ 6.7721e-01,  5.2524e-01,  1.4656e+00,  ..., -1.0143e+00,\n",
      "           4.9238e-01,  5.7811e-01],\n",
      "         [-1.4011e+00,  6.5544e-01, -9.8015e-01,  ...,  1.6932e-01,\n",
      "           1.0281e+00, -2.2329e-01],\n",
      "         ...,\n",
      "         [ 2.1939e+00,  2.0705e-01,  2.7165e+00,  ..., -2.1044e-01,\n",
      "           4.6835e-01,  5.0170e-01],\n",
      "         [ 1.9324e+00,  6.1273e-01,  3.0288e+00,  ..., -1.2688e+00,\n",
      "           8.3527e-01,  3.9033e-01],\n",
      "         [-1.4282e+00, -8.3125e-01, -1.3022e+00,  ...,  1.8573e+00,\n",
      "          -1.1446e+00, -4.0803e-01]],\n",
      "\n",
      "        [[-1.8493e+00, -5.5892e-01, -8.4111e-02,  ..., -3.5709e-01,\n",
      "          -3.4010e+00, -5.5246e-01],\n",
      "         [ 1.1157e+00,  1.1915e+00,  1.0722e+00,  ...,  1.0764e+00,\n",
      "           7.3745e-01,  1.2077e+00],\n",
      "         [ 2.5937e-02, -1.9195e-01,  1.2608e+00,  ...,  6.8623e-01,\n",
      "           7.3282e-01,  8.0911e-02],\n",
      "         ...,\n",
      "         [ 3.4716e-02,  1.3245e+00, -7.7263e-01,  ...,  6.1324e-01,\n",
      "           1.1284e+00, -6.3730e-01],\n",
      "         [ 1.6604e+00,  1.3521e+00,  9.3939e-01,  ...,  1.8103e+00,\n",
      "           2.0591e+00,  8.4936e-01],\n",
      "         [-1.6248e+00, -8.0330e-01, -5.2703e-01,  ..., -6.2102e-01,\n",
      "          -2.4400e+00, -5.0597e-01]],\n",
      "\n",
      "        [[-9.8393e-01, -4.3749e-02, -3.6822e-01,  ...,  1.3267e+00,\n",
      "          -1.7282e+00,  8.9377e-01],\n",
      "         [ 4.4975e-01,  1.4948e+00,  1.6369e+00,  ..., -4.1251e-01,\n",
      "           1.0194e+00, -1.3991e+00],\n",
      "         [ 6.5617e-01, -1.8850e-02, -1.3464e+00,  ..., -1.1377e-01,\n",
      "          -5.1295e-01,  2.6588e-01],\n",
      "         ...,\n",
      "         [-7.5476e-01,  4.3123e-01,  2.2688e+00,  ...,  3.9053e-01,\n",
      "           1.0745e+00,  5.2466e-01],\n",
      "         [ 6.7148e-01,  1.0501e+00,  2.0783e+00,  ..., -7.6045e-01,\n",
      "           1.8647e+00, -1.2109e+00],\n",
      "         [-9.9180e-01, -5.6313e-01, -5.8037e-01,  ...,  1.0183e+00,\n",
      "          -1.5183e+00,  1.4849e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9810e-01, -2.3077e-01, -5.1759e-01,  ...,  1.6643e+00,\n",
      "           5.6989e-05,  4.8064e-01],\n",
      "         [ 3.8337e-01,  4.1706e-01,  8.1536e-01,  ..., -6.1392e-01,\n",
      "           3.1309e-01, -7.1953e-01],\n",
      "         [ 7.8463e-01,  2.8225e-01,  2.7765e-01,  ..., -1.5607e-01,\n",
      "          -5.0440e-01,  2.6917e-01],\n",
      "         ...,\n",
      "         [-1.0335e+00, -9.5861e-01, -4.6956e-01,  ...,  1.6439e+00,\n",
      "           3.9715e-01,  1.2548e-01],\n",
      "         [ 1.8112e-01,  1.7488e-01,  5.8134e-01,  ..., -8.7004e-01,\n",
      "           1.3565e-02, -1.0348e+00],\n",
      "         [-6.6630e-01, -9.9602e-02, -8.4993e-01,  ...,  1.4646e+00,\n",
      "          -3.5578e-01,  9.1583e-01]],\n",
      "\n",
      "        [[-2.0704e+00, -1.8753e+00, -3.1550e-01,  ...,  4.4252e-01,\n",
      "          -2.0790e-01,  4.9932e-01],\n",
      "         [ 6.4748e-01,  7.1075e-01,  1.2811e+00,  ..., -1.6953e+00,\n",
      "           1.2276e+00, -8.8654e-01],\n",
      "         [-4.8667e-01, -1.2794e-01,  1.6510e-01,  ...,  1.4987e+00,\n",
      "          -2.1994e+00, -2.5282e-01],\n",
      "         ...,\n",
      "         [ 8.8613e-01,  2.3637e+00,  1.4388e+00,  ..., -1.1806e+00,\n",
      "           1.2172e+00, -2.7434e-01],\n",
      "         [ 1.4761e+00,  2.2917e+00,  1.8361e+00,  ..., -1.1541e+00,\n",
      "           1.4073e+00, -9.7508e-01],\n",
      "         [-1.3613e+00, -1.5479e+00, -9.1003e-01,  ...,  1.2876e+00,\n",
      "          -4.4465e-01,  6.8120e-01]],\n",
      "\n",
      "        [[-1.9890e-01, -7.8625e-01, -2.0259e+00,  ...,  1.0315e+00,\n",
      "           4.4467e-01,  7.7934e-01],\n",
      "         [ 8.5773e-01,  7.0451e-01,  9.6808e-01,  ..., -8.6379e-01,\n",
      "          -1.4219e-01,  3.0747e-01],\n",
      "         [-1.2819e+00, -2.6984e-01,  2.1523e+00,  ..., -4.6351e-01,\n",
      "          -2.2628e-01, -1.2240e+00],\n",
      "         ...,\n",
      "         [ 6.3994e-01,  1.6149e+00,  8.6649e-01,  ...,  4.9381e-01,\n",
      "           8.0326e-01,  5.4325e-01],\n",
      "         [ 6.0514e-01,  1.2362e+00,  1.7909e+00,  ..., -7.0366e-01,\n",
      "          -4.9815e-01,  5.2944e-02],\n",
      "         [-2.5250e-01, -1.1664e+00, -1.8056e+00,  ...,  8.6710e-01,\n",
      "           6.2511e-01,  4.6215e-01]]], grad_fn=<AddBackward0>), tensor([[[ 0.6766,  0.3336,  0.4795,  ..., -0.4095,  0.4256, -0.1250],\n",
      "         [ 0.3422,  0.3756,  0.3731,  ..., -0.4178,  0.5023,  0.2104],\n",
      "         [ 0.7797,  0.3211,  0.7262,  ..., -0.3288,  0.3111, -0.0722],\n",
      "         ...,\n",
      "         [ 0.7890,  0.3187,  0.7841,  ..., -0.2538,  0.2918, -0.0950],\n",
      "         [ 0.3488,  0.2627,  0.7313,  ..., -0.2898,  0.3229,  0.3843],\n",
      "         [ 0.5047,  0.4008,  0.6546,  ..., -0.3826,  0.4039,  0.2159]],\n",
      "\n",
      "        [[ 0.3932,  0.1733,  0.2423,  ...,  0.3832,  0.8037,  0.1512],\n",
      "         [ 0.3524,  0.3532,  0.2672,  ...,  0.4764,  0.6773,  0.1662],\n",
      "         [ 0.4059,  0.2073,  0.1115,  ...,  0.3770,  0.6135,  0.1880],\n",
      "         ...,\n",
      "         [ 0.4629,  0.1569,  0.1585,  ...,  0.3563,  0.5508,  0.2180],\n",
      "         [ 0.2632,  0.4817,  0.2035,  ...,  0.3506,  0.4345,  0.0921],\n",
      "         [ 0.3124,  0.3684,  0.3367,  ...,  0.5013,  0.5432,  0.0866]],\n",
      "\n",
      "        [[ 0.5393, -0.1099,  0.4011,  ..., -0.1117,  0.4917, -0.4941],\n",
      "         [ 0.2340,  0.2061,  0.2708,  ..., -0.0699,  0.4359, -0.5056],\n",
      "         [ 0.5166, -0.0392,  0.5584,  ..., -0.1573,  0.5200, -0.4400],\n",
      "         ...,\n",
      "         [ 0.5191, -0.0191,  0.5542,  ..., -0.1841,  0.5050, -0.4375],\n",
      "         [-0.1510,  0.5376,  0.5587,  ..., -0.1439,  0.5325, -0.1679],\n",
      "         [ 0.1929,  0.3011,  0.5298,  ..., -0.0942,  0.5225, -0.4004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1707, -0.0354,  0.3046,  ..., -0.3113,  0.0119, -0.4208],\n",
      "         [ 0.2677,  0.0798,  0.2709,  ...,  0.0097,  0.1448, -0.1619],\n",
      "         [ 0.0864, -0.1681,  0.2610,  ..., -0.2998, -0.0295, -0.4104],\n",
      "         ...,\n",
      "         [ 0.0732, -0.1787,  0.2885,  ..., -0.3826, -0.0495, -0.4379],\n",
      "         [-0.1001, -0.1101,  0.0654,  ...,  0.1995,  0.2595,  0.1095],\n",
      "         [ 0.0556, -0.1035,  0.2133,  ...,  0.0348,  0.1822, -0.1739]],\n",
      "\n",
      "        [[ 0.5571,  0.7078,  0.4699,  ..., -0.4915,  0.2344, -0.1972],\n",
      "         [ 0.3755,  0.5304,  0.4036,  ..., -0.4384,  0.0101, -0.2532],\n",
      "         [ 0.4310,  0.8025,  0.4693,  ..., -0.5698,  0.3829, -0.1925],\n",
      "         ...,\n",
      "         [ 0.3601,  0.7577,  0.3744,  ..., -0.5634,  0.4316, -0.1682],\n",
      "         [ 0.3291,  0.5757,  0.3987,  ..., -0.6069,  0.4498, -0.3291],\n",
      "         [ 0.3202,  0.6679,  0.4957,  ..., -0.6361,  0.3462, -0.3309]],\n",
      "\n",
      "        [[ 0.0662,  0.4105,  0.7079,  ..., -0.1554, -0.2429, -0.1674],\n",
      "         [-0.1354,  0.5028,  0.5845,  ..., -0.2526,  0.0675, -0.1233],\n",
      "         [ 0.1868,  0.4378,  0.5267,  ..., -0.1141, -0.3215, -0.0418],\n",
      "         ...,\n",
      "         [ 0.2313,  0.3705,  0.4867,  ..., -0.0743, -0.3760,  0.0078],\n",
      "         [ 0.1083,  0.4118,  0.2577,  ..., -0.2619,  0.1747,  0.1506],\n",
      "         [ 0.0282,  0.4734,  0.4556,  ..., -0.2503,  0.0051,  0.0020]]],\n",
      "       grad_fn=<SliceBackward0>), tensor([[[0.1293, 0.1233, 0.1146,  ..., 0.1312, 0.1437, 0.1164],\n",
      "         [0.1203, 0.1300, 0.1350,  ..., 0.1199, 0.1035, 0.1376],\n",
      "         [0.1417, 0.1366, 0.1182,  ..., 0.1409, 0.1353, 0.1310],\n",
      "         ...,\n",
      "         [0.1189, 0.1166, 0.1239,  ..., 0.1178, 0.1242, 0.1157],\n",
      "         [0.1172, 0.1294, 0.1392,  ..., 0.1154, 0.0971, 0.1427],\n",
      "         [0.1320, 0.1272, 0.1154,  ..., 0.1335, 0.1432, 0.1205]],\n",
      "\n",
      "        [[0.1696, 0.1664, 0.0877,  ..., 0.1683, 0.1525, 0.1509],\n",
      "         [0.1016, 0.1009, 0.1405,  ..., 0.1019, 0.1115, 0.1076],\n",
      "         [0.0881, 0.0938, 0.1873,  ..., 0.0886, 0.0996, 0.1100],\n",
      "         ...,\n",
      "         [0.1316, 0.1287, 0.1009,  ..., 0.1315, 0.1359, 0.1229],\n",
      "         [0.0969, 0.0946, 0.1442,  ..., 0.0983, 0.1141, 0.0997],\n",
      "         [0.1649, 0.1642, 0.0919,  ..., 0.1656, 0.1513, 0.1514]],\n",
      "\n",
      "        [[0.1218, 0.1331, 0.1252,  ..., 0.1200, 0.1077, 0.1441],\n",
      "         [0.1148, 0.1091, 0.1325,  ..., 0.1150, 0.1212, 0.1090],\n",
      "         [0.1426, 0.1394, 0.1187,  ..., 0.1431, 0.1433, 0.1302],\n",
      "         ...,\n",
      "         [0.1364, 0.1351, 0.1125,  ..., 0.1379, 0.1376, 0.1274],\n",
      "         [0.1212, 0.1148, 0.1265,  ..., 0.1219, 0.1287, 0.1121],\n",
      "         [0.1227, 0.1356, 0.1298,  ..., 0.1215, 0.1098, 0.1487]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1414, 0.1519, 0.1167,  ..., 0.1399, 0.1227, 0.1595],\n",
      "         [0.1102, 0.1051, 0.1252,  ..., 0.1106, 0.1236, 0.1006],\n",
      "         [0.1614, 0.1483, 0.1001,  ..., 0.1641, 0.1558, 0.1209],\n",
      "         ...,\n",
      "         [0.1050, 0.1041, 0.1506,  ..., 0.1037, 0.1136, 0.1123],\n",
      "         [0.1090, 0.1021, 0.1300,  ..., 0.1093, 0.1266, 0.0969],\n",
      "         [0.1529, 0.1558, 0.1119,  ..., 0.1514, 0.1383, 0.1541]],\n",
      "\n",
      "        [[0.0998, 0.1117, 0.1561,  ..., 0.1002, 0.0903, 0.1286],\n",
      "         [0.1596, 0.1514, 0.0953,  ..., 0.1561, 0.1556, 0.1376],\n",
      "         [0.1232, 0.1109, 0.1159,  ..., 0.1277, 0.1476, 0.1018],\n",
      "         ...,\n",
      "         [0.1024, 0.1097, 0.1424,  ..., 0.1031, 0.1021, 0.1175],\n",
      "         [0.1546, 0.1464, 0.0956,  ..., 0.1526, 0.1533, 0.1332],\n",
      "         [0.0952, 0.1077, 0.1579,  ..., 0.0970, 0.0876, 0.1255]],\n",
      "\n",
      "        [[0.1474, 0.1456, 0.1032,  ..., 0.1481, 0.1534, 0.1374],\n",
      "         [0.1121, 0.1107, 0.1373,  ..., 0.1109, 0.1118, 0.1124],\n",
      "         [0.1047, 0.1039, 0.1349,  ..., 0.1040, 0.1069, 0.1098],\n",
      "         ...,\n",
      "         [0.1399, 0.1448, 0.1168,  ..., 0.1426, 0.1299, 0.1449],\n",
      "         [0.1064, 0.1071, 0.1503,  ..., 0.1059, 0.1058, 0.1129],\n",
      "         [0.1387, 0.1372, 0.1069,  ..., 0.1393, 0.1498, 0.1335]]],\n",
      "       grad_fn=<SoftmaxBackward0>))\n",
      "\n",
      "all_output (tensor([[[-1.6737e+00, -4.2574e-01, -1.3484e+00,  ...,  1.8625e+00,\n",
      "          -8.9482e-01,  1.6218e-02],\n",
      "         [ 6.7721e-01,  5.2524e-01,  1.4656e+00,  ..., -1.0143e+00,\n",
      "           4.9238e-01,  5.7811e-01],\n",
      "         [-1.4011e+00,  6.5544e-01, -9.8015e-01,  ...,  1.6932e-01,\n",
      "           1.0281e+00, -2.2329e-01],\n",
      "         ...,\n",
      "         [ 2.1939e+00,  2.0705e-01,  2.7165e+00,  ..., -2.1044e-01,\n",
      "           4.6835e-01,  5.0170e-01],\n",
      "         [ 1.9324e+00,  6.1273e-01,  3.0288e+00,  ..., -1.2688e+00,\n",
      "           8.3527e-01,  3.9033e-01],\n",
      "         [-1.4282e+00, -8.3125e-01, -1.3022e+00,  ...,  1.8573e+00,\n",
      "          -1.1446e+00, -4.0803e-01]],\n",
      "\n",
      "        [[-1.8493e+00, -5.5892e-01, -8.4111e-02,  ..., -3.5709e-01,\n",
      "          -3.4010e+00, -5.5246e-01],\n",
      "         [ 1.1157e+00,  1.1915e+00,  1.0722e+00,  ...,  1.0764e+00,\n",
      "           7.3745e-01,  1.2077e+00],\n",
      "         [ 2.5937e-02, -1.9195e-01,  1.2608e+00,  ...,  6.8623e-01,\n",
      "           7.3282e-01,  8.0911e-02],\n",
      "         ...,\n",
      "         [ 3.4716e-02,  1.3245e+00, -7.7263e-01,  ...,  6.1324e-01,\n",
      "           1.1284e+00, -6.3730e-01],\n",
      "         [ 1.6604e+00,  1.3521e+00,  9.3939e-01,  ...,  1.8103e+00,\n",
      "           2.0591e+00,  8.4936e-01],\n",
      "         [-1.6248e+00, -8.0330e-01, -5.2703e-01,  ..., -6.2102e-01,\n",
      "          -2.4400e+00, -5.0597e-01]],\n",
      "\n",
      "        [[-9.8393e-01, -4.3749e-02, -3.6822e-01,  ...,  1.3267e+00,\n",
      "          -1.7282e+00,  8.9377e-01],\n",
      "         [ 4.4975e-01,  1.4948e+00,  1.6369e+00,  ..., -4.1251e-01,\n",
      "           1.0194e+00, -1.3991e+00],\n",
      "         [ 6.5617e-01, -1.8850e-02, -1.3464e+00,  ..., -1.1377e-01,\n",
      "          -5.1295e-01,  2.6588e-01],\n",
      "         ...,\n",
      "         [-7.5476e-01,  4.3123e-01,  2.2688e+00,  ...,  3.9053e-01,\n",
      "           1.0745e+00,  5.2466e-01],\n",
      "         [ 6.7148e-01,  1.0501e+00,  2.0783e+00,  ..., -7.6045e-01,\n",
      "           1.8647e+00, -1.2109e+00],\n",
      "         [-9.9180e-01, -5.6313e-01, -5.8037e-01,  ...,  1.0183e+00,\n",
      "          -1.5183e+00,  1.4849e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9810e-01, -2.3077e-01, -5.1759e-01,  ...,  1.6643e+00,\n",
      "           5.6989e-05,  4.8064e-01],\n",
      "         [ 3.8337e-01,  4.1706e-01,  8.1536e-01,  ..., -6.1392e-01,\n",
      "           3.1309e-01, -7.1953e-01],\n",
      "         [ 7.8463e-01,  2.8225e-01,  2.7765e-01,  ..., -1.5607e-01,\n",
      "          -5.0440e-01,  2.6917e-01],\n",
      "         ...,\n",
      "         [-1.0335e+00, -9.5861e-01, -4.6956e-01,  ...,  1.6439e+00,\n",
      "           3.9715e-01,  1.2548e-01],\n",
      "         [ 1.8112e-01,  1.7488e-01,  5.8134e-01,  ..., -8.7004e-01,\n",
      "           1.3565e-02, -1.0348e+00],\n",
      "         [-6.6630e-01, -9.9602e-02, -8.4993e-01,  ...,  1.4646e+00,\n",
      "          -3.5578e-01,  9.1583e-01]],\n",
      "\n",
      "        [[-2.0704e+00, -1.8753e+00, -3.1550e-01,  ...,  4.4252e-01,\n",
      "          -2.0790e-01,  4.9932e-01],\n",
      "         [ 6.4748e-01,  7.1075e-01,  1.2811e+00,  ..., -1.6953e+00,\n",
      "           1.2276e+00, -8.8654e-01],\n",
      "         [-4.8667e-01, -1.2794e-01,  1.6510e-01,  ...,  1.4987e+00,\n",
      "          -2.1994e+00, -2.5282e-01],\n",
      "         ...,\n",
      "         [ 8.8613e-01,  2.3637e+00,  1.4388e+00,  ..., -1.1806e+00,\n",
      "           1.2172e+00, -2.7434e-01],\n",
      "         [ 1.4761e+00,  2.2917e+00,  1.8361e+00,  ..., -1.1541e+00,\n",
      "           1.4073e+00, -9.7508e-01],\n",
      "         [-1.3613e+00, -1.5479e+00, -9.1003e-01,  ...,  1.2876e+00,\n",
      "          -4.4465e-01,  6.8120e-01]],\n",
      "\n",
      "        [[-1.9890e-01, -7.8625e-01, -2.0259e+00,  ...,  1.0315e+00,\n",
      "           4.4467e-01,  7.7934e-01],\n",
      "         [ 8.5773e-01,  7.0451e-01,  9.6808e-01,  ..., -8.6379e-01,\n",
      "          -1.4219e-01,  3.0747e-01],\n",
      "         [-1.2819e+00, -2.6984e-01,  2.1523e+00,  ..., -4.6351e-01,\n",
      "          -2.2628e-01, -1.2240e+00],\n",
      "         ...,\n",
      "         [ 6.3994e-01,  1.6149e+00,  8.6649e-01,  ...,  4.9381e-01,\n",
      "           8.0326e-01,  5.4325e-01],\n",
      "         [ 6.0514e-01,  1.2362e+00,  1.7909e+00,  ..., -7.0366e-01,\n",
      "          -4.9815e-01,  5.2944e-02],\n",
      "         [-2.5250e-01, -1.1664e+00, -1.8056e+00,  ...,  8.6710e-01,\n",
      "           6.2511e-01,  4.6215e-01]]], grad_fn=<AddBackward0>), tensor([[[ 0.6766,  0.3336,  0.4795,  ..., -0.4095,  0.4256, -0.1250],\n",
      "         [ 0.3422,  0.3756,  0.3731,  ..., -0.4178,  0.5023,  0.2104],\n",
      "         [ 0.7797,  0.3211,  0.7262,  ..., -0.3288,  0.3111, -0.0722],\n",
      "         ...,\n",
      "         [ 0.7890,  0.3187,  0.7841,  ..., -0.2538,  0.2918, -0.0950],\n",
      "         [ 0.3488,  0.2627,  0.7313,  ..., -0.2898,  0.3229,  0.3843],\n",
      "         [ 0.5047,  0.4008,  0.6546,  ..., -0.3826,  0.4039,  0.2159]],\n",
      "\n",
      "        [[ 0.3932,  0.1733,  0.2423,  ...,  0.3832,  0.8037,  0.1512],\n",
      "         [ 0.3524,  0.3532,  0.2672,  ...,  0.4764,  0.6773,  0.1662],\n",
      "         [ 0.4059,  0.2073,  0.1115,  ...,  0.3770,  0.6135,  0.1880],\n",
      "         ...,\n",
      "         [ 0.4629,  0.1569,  0.1585,  ...,  0.3563,  0.5508,  0.2180],\n",
      "         [ 0.2632,  0.4817,  0.2035,  ...,  0.3506,  0.4345,  0.0921],\n",
      "         [ 0.3124,  0.3684,  0.3367,  ...,  0.5013,  0.5432,  0.0866]],\n",
      "\n",
      "        [[ 0.5393, -0.1099,  0.4011,  ..., -0.1117,  0.4917, -0.4941],\n",
      "         [ 0.2340,  0.2061,  0.2708,  ..., -0.0699,  0.4359, -0.5056],\n",
      "         [ 0.5166, -0.0392,  0.5584,  ..., -0.1573,  0.5200, -0.4400],\n",
      "         ...,\n",
      "         [ 0.5191, -0.0191,  0.5542,  ..., -0.1841,  0.5050, -0.4375],\n",
      "         [-0.1510,  0.5376,  0.5587,  ..., -0.1439,  0.5325, -0.1679],\n",
      "         [ 0.1929,  0.3011,  0.5298,  ..., -0.0942,  0.5225, -0.4004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1707, -0.0354,  0.3046,  ..., -0.3113,  0.0119, -0.4208],\n",
      "         [ 0.2677,  0.0798,  0.2709,  ...,  0.0097,  0.1448, -0.1619],\n",
      "         [ 0.0864, -0.1681,  0.2610,  ..., -0.2998, -0.0295, -0.4104],\n",
      "         ...,\n",
      "         [ 0.0732, -0.1787,  0.2885,  ..., -0.3826, -0.0495, -0.4379],\n",
      "         [-0.1001, -0.1101,  0.0654,  ...,  0.1995,  0.2595,  0.1095],\n",
      "         [ 0.0556, -0.1035,  0.2133,  ...,  0.0348,  0.1822, -0.1739]],\n",
      "\n",
      "        [[ 0.5571,  0.7078,  0.4699,  ..., -0.4915,  0.2344, -0.1972],\n",
      "         [ 0.3755,  0.5304,  0.4036,  ..., -0.4384,  0.0101, -0.2532],\n",
      "         [ 0.4310,  0.8025,  0.4693,  ..., -0.5698,  0.3829, -0.1925],\n",
      "         ...,\n",
      "         [ 0.3601,  0.7577,  0.3744,  ..., -0.5634,  0.4316, -0.1682],\n",
      "         [ 0.3291,  0.5757,  0.3987,  ..., -0.6069,  0.4498, -0.3291],\n",
      "         [ 0.3202,  0.6679,  0.4957,  ..., -0.6361,  0.3462, -0.3309]],\n",
      "\n",
      "        [[ 0.0662,  0.4105,  0.7079,  ..., -0.1554, -0.2429, -0.1674],\n",
      "         [-0.1354,  0.5028,  0.5845,  ..., -0.2526,  0.0675, -0.1233],\n",
      "         [ 0.1868,  0.4378,  0.5267,  ..., -0.1141, -0.3215, -0.0418],\n",
      "         ...,\n",
      "         [ 0.2313,  0.3705,  0.4867,  ..., -0.0743, -0.3760,  0.0078],\n",
      "         [ 0.1083,  0.4118,  0.2577,  ..., -0.2619,  0.1747,  0.1506],\n",
      "         [ 0.0282,  0.4734,  0.4556,  ..., -0.2503,  0.0051,  0.0020]]],\n",
      "       grad_fn=<SliceBackward0>), tensor([[[0.1293, 0.1233, 0.1146,  ..., 0.1312, 0.1437, 0.1164],\n",
      "         [0.1203, 0.1300, 0.1350,  ..., 0.1199, 0.1035, 0.1376],\n",
      "         [0.1417, 0.1366, 0.1182,  ..., 0.1409, 0.1353, 0.1310],\n",
      "         ...,\n",
      "         [0.1189, 0.1166, 0.1239,  ..., 0.1178, 0.1242, 0.1157],\n",
      "         [0.1172, 0.1294, 0.1392,  ..., 0.1154, 0.0971, 0.1427],\n",
      "         [0.1320, 0.1272, 0.1154,  ..., 0.1335, 0.1432, 0.1205]],\n",
      "\n",
      "        [[0.1696, 0.1664, 0.0877,  ..., 0.1683, 0.1525, 0.1509],\n",
      "         [0.1016, 0.1009, 0.1405,  ..., 0.1019, 0.1115, 0.1076],\n",
      "         [0.0881, 0.0938, 0.1873,  ..., 0.0886, 0.0996, 0.1100],\n",
      "         ...,\n",
      "         [0.1316, 0.1287, 0.1009,  ..., 0.1315, 0.1359, 0.1229],\n",
      "         [0.0969, 0.0946, 0.1442,  ..., 0.0983, 0.1141, 0.0997],\n",
      "         [0.1649, 0.1642, 0.0919,  ..., 0.1656, 0.1513, 0.1514]],\n",
      "\n",
      "        [[0.1218, 0.1331, 0.1252,  ..., 0.1200, 0.1077, 0.1441],\n",
      "         [0.1148, 0.1091, 0.1325,  ..., 0.1150, 0.1212, 0.1090],\n",
      "         [0.1426, 0.1394, 0.1187,  ..., 0.1431, 0.1433, 0.1302],\n",
      "         ...,\n",
      "         [0.1364, 0.1351, 0.1125,  ..., 0.1379, 0.1376, 0.1274],\n",
      "         [0.1212, 0.1148, 0.1265,  ..., 0.1219, 0.1287, 0.1121],\n",
      "         [0.1227, 0.1356, 0.1298,  ..., 0.1215, 0.1098, 0.1487]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1414, 0.1519, 0.1167,  ..., 0.1399, 0.1227, 0.1595],\n",
      "         [0.1102, 0.1051, 0.1252,  ..., 0.1106, 0.1236, 0.1006],\n",
      "         [0.1614, 0.1483, 0.1001,  ..., 0.1641, 0.1558, 0.1209],\n",
      "         ...,\n",
      "         [0.1050, 0.1041, 0.1506,  ..., 0.1037, 0.1136, 0.1123],\n",
      "         [0.1090, 0.1021, 0.1300,  ..., 0.1093, 0.1266, 0.0969],\n",
      "         [0.1529, 0.1558, 0.1119,  ..., 0.1514, 0.1383, 0.1541]],\n",
      "\n",
      "        [[0.0998, 0.1117, 0.1561,  ..., 0.1002, 0.0903, 0.1286],\n",
      "         [0.1596, 0.1514, 0.0953,  ..., 0.1561, 0.1556, 0.1376],\n",
      "         [0.1232, 0.1109, 0.1159,  ..., 0.1277, 0.1476, 0.1018],\n",
      "         ...,\n",
      "         [0.1024, 0.1097, 0.1424,  ..., 0.1031, 0.1021, 0.1175],\n",
      "         [0.1546, 0.1464, 0.0956,  ..., 0.1526, 0.1533, 0.1332],\n",
      "         [0.0952, 0.1077, 0.1579,  ..., 0.0970, 0.0876, 0.1255]],\n",
      "\n",
      "        [[0.1474, 0.1456, 0.1032,  ..., 0.1481, 0.1534, 0.1374],\n",
      "         [0.1121, 0.1107, 0.1373,  ..., 0.1109, 0.1118, 0.1124],\n",
      "         [0.1047, 0.1039, 0.1349,  ..., 0.1040, 0.1069, 0.1098],\n",
      "         ...,\n",
      "         [0.1399, 0.1448, 0.1168,  ..., 0.1426, 0.1299, 0.1449],\n",
      "         [0.1064, 0.1071, 0.1503,  ..., 0.1059, 0.1058, 0.1129],\n",
      "         [0.1387, 0.1372, 0.1069,  ..., 0.1393, 0.1498, 0.1335]]],\n",
      "       grad_fn=<SoftmaxBackward0>))\n",
      "all_input hidden_states torch.Size([32, 8, 384]) output_attentions True\n",
      "prev_group_token torch.Size([32, 8, 384])\n",
      "\n",
      "group_token = None\n",
      "\n",
      "= input hidden_states torch.Size([32, 8, 384])\n",
      "= output x torch.Size([32, 8, 384])\n",
      "\n",
      "self.concat_x input x torch.Size([32, 8, 384])\n",
      "group_token None\n",
      "self.concat_x output cat_x torch.Size([32, 8, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 8, 384]) None None\n",
      "layer output layer_out (tensor([[[-1.8270, -0.7049, -1.4366,  ...,  1.4857, -0.6563, -0.4099],\n",
      "         [ 0.7755,  0.6517,  1.6269,  ..., -0.7657,  0.8310,  0.7434],\n",
      "         [-1.5148,  0.7148, -0.9633,  ..., -0.0479,  1.1206,  0.2555],\n",
      "         ...,\n",
      "         [ 2.2017,  0.1841,  2.8216,  ..., -0.3301,  0.9685,  0.4639],\n",
      "         [ 2.0916,  0.7636,  3.2673,  ..., -1.0754,  1.2378,  0.4696],\n",
      "         [-1.6621, -1.0125, -1.5143,  ...,  1.4153, -0.9715, -0.6574]],\n",
      "\n",
      "        [[-1.9622, -0.6436, -0.3282,  ..., -0.7350, -3.2166, -0.4383],\n",
      "         [ 1.1618,  1.1409,  0.9465,  ...,  0.9537,  0.7148,  1.3847],\n",
      "         [ 0.2231, -0.3133,  1.0755,  ...,  0.8048,  0.5761,  0.4479],\n",
      "         ...,\n",
      "         [-0.0881,  1.0450, -0.9371,  ...,  0.1891,  1.1342, -0.8267],\n",
      "         [ 1.7578,  1.3443,  0.8346,  ...,  1.8218,  1.9750,  1.0123],\n",
      "         [-1.6114, -1.0119, -0.7374,  ..., -0.9020, -2.2279, -0.4159]],\n",
      "\n",
      "        [[-1.2711, -0.3503, -0.4583,  ...,  1.1326, -1.2918,  0.9349],\n",
      "         [ 0.3345,  1.4719,  1.5403,  ..., -0.4486,  0.8690, -1.1656],\n",
      "         [ 0.6565, -0.1836, -1.3638,  ..., -0.2963, -0.4291,  0.6426],\n",
      "         ...,\n",
      "         [-0.8124,  0.1044,  2.4388,  ...,  0.2127,  1.0180,  0.3707],\n",
      "         [ 0.7523,  1.0934,  1.9994,  ..., -0.6704,  1.7133, -0.9935],\n",
      "         [-1.1007, -0.7341, -0.6894,  ...,  0.7584, -1.1732,  1.4723]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5381, -0.4409, -0.4868,  ...,  1.2758,  0.2653,  0.6039],\n",
      "         [ 0.3243,  0.5386,  0.6266,  ..., -0.7636,  0.7304, -0.6538],\n",
      "         [ 0.6205,  0.0802,  0.4905,  ..., -0.2654, -0.6136,  0.5800],\n",
      "         ...,\n",
      "         [-1.1414, -1.0533, -0.2263,  ...,  1.3445,  0.7569,  0.0371],\n",
      "         [ 0.0506,  0.4286,  0.5419,  ..., -0.9432,  0.3530, -0.9516],\n",
      "         [-0.6786, -0.3024, -0.6464,  ...,  1.1605, -0.1143,  1.0734]],\n",
      "\n",
      "        [[-2.2843, -1.7792, -0.5356,  ...,  0.2328, -0.1220,  0.4076],\n",
      "         [ 0.2218,  0.5183,  1.2759,  ..., -1.9302,  1.4532, -0.6215],\n",
      "         [-0.5575, -0.1410,  0.2910,  ...,  1.5721, -2.2426, -0.0284],\n",
      "         ...,\n",
      "         [ 0.8315,  2.0998,  1.2054,  ..., -1.1463,  1.0109, -0.2580],\n",
      "         [ 1.1609,  2.0898,  1.7077,  ..., -1.1886,  1.5015, -0.7585],\n",
      "         [-1.4881, -1.3511, -1.0761,  ...,  1.1024, -0.3879,  0.5545]],\n",
      "\n",
      "        [[-0.2858, -0.9852, -1.7659,  ...,  0.9005,  0.7525,  0.6117],\n",
      "         [ 1.0173,  0.7374,  0.9764,  ..., -0.7901,  0.3367,  0.4989],\n",
      "         [-1.4702, -0.1895,  2.0285,  ..., -0.5811, -0.2142, -1.0722],\n",
      "         ...,\n",
      "         [ 0.5916,  1.4262,  1.0032,  ...,  0.2393,  0.9211,  0.6589],\n",
      "         [ 0.7359,  1.2076,  1.7897,  ..., -0.7109, -0.1455,  0.2814],\n",
      "         [-0.4344, -1.3113, -1.6238,  ...,  0.6848,  0.7564,  0.4668]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 8, 384])\n",
      "= output cat_x torch.Size([32, 8, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 8, 384]) None None\n",
      "layer output layer_out (tensor([[[-1.7300e+00, -7.1358e-01, -1.0674e+00,  ...,  1.4424e+00,\n",
      "          -9.8397e-01, -3.0524e-01],\n",
      "         [ 6.4485e-01,  2.9728e-01,  1.4840e+00,  ..., -3.9443e-01,\n",
      "           1.0179e+00,  1.3035e+00],\n",
      "         [-1.5568e+00,  7.9272e-01, -1.1422e+00,  ...,  2.5694e-01,\n",
      "           1.2841e+00,  4.1194e-01],\n",
      "         ...,\n",
      "         [ 2.1184e+00,  3.1023e-01,  3.0400e+00,  ..., -1.2467e-01,\n",
      "           7.8278e-01,  6.6716e-01],\n",
      "         [ 1.8441e+00,  5.4935e-01,  3.0581e+00,  ..., -6.9645e-01,\n",
      "           1.4950e+00,  9.3432e-01],\n",
      "         [-1.6541e+00, -8.9837e-01, -1.2188e+00,  ...,  1.3064e+00,\n",
      "          -1.1734e+00, -6.2878e-01]],\n",
      "\n",
      "        [[-2.0860e+00, -4.9977e-01, -5.1628e-01,  ..., -6.2161e-01,\n",
      "          -3.1080e+00, -2.7085e-01],\n",
      "         [ 1.1641e+00,  8.5963e-01,  8.5678e-01,  ...,  1.3061e+00,\n",
      "           7.0634e-01,  1.9881e+00],\n",
      "         [ 5.2270e-01, -1.5340e-01,  1.0701e+00,  ...,  6.0128e-01,\n",
      "           5.3651e-01,  6.1310e-01],\n",
      "         ...,\n",
      "         [-2.0219e-01,  1.1652e+00, -1.1729e+00,  ...,  4.7963e-01,\n",
      "           9.6581e-01, -6.8347e-01],\n",
      "         [ 1.6874e+00,  1.1357e+00,  6.4497e-01,  ...,  2.2428e+00,\n",
      "           1.8765e+00,  1.4465e+00],\n",
      "         [-1.6479e+00, -8.6506e-01, -8.9765e-01,  ..., -8.0207e-01,\n",
      "          -2.1894e+00, -2.8002e-01]],\n",
      "\n",
      "        [[-1.4664e+00, -6.5706e-02, -3.9640e-01,  ...,  1.0704e+00,\n",
      "          -1.3732e+00,  1.1880e+00],\n",
      "         [ 3.8430e-01,  1.2033e+00,  1.2155e+00,  ..., -3.7795e-01,\n",
      "           8.3830e-01, -7.1920e-01],\n",
      "         [ 6.6370e-01, -5.4641e-02, -1.2942e+00,  ..., -3.0318e-01,\n",
      "          -4.4170e-01,  1.0145e+00],\n",
      "         ...,\n",
      "         [-8.6152e-01,  5.9076e-01,  2.5415e+00,  ...,  2.3227e-01,\n",
      "           8.6708e-01,  3.1336e-01],\n",
      "         [ 6.7906e-01,  9.3007e-01,  1.7371e+00,  ..., -6.2785e-01,\n",
      "           1.7292e+00, -7.1679e-01],\n",
      "         [-1.2908e+00, -4.7255e-01, -4.6029e-01,  ...,  7.3530e-01,\n",
      "          -1.3275e+00,  1.7461e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.3747e-01, -2.2916e-01, -1.9272e-01,  ...,  1.2761e+00,\n",
      "           2.0524e-01,  8.1296e-01],\n",
      "         [ 2.7015e-01,  3.0662e-01,  4.5681e-01,  ..., -1.9918e-01,\n",
      "           1.0269e+00, -4.7674e-01],\n",
      "         [ 3.4057e-01,  1.7796e-01,  7.3069e-01,  ..., -3.9097e-01,\n",
      "          -5.4817e-01,  7.3836e-01],\n",
      "         ...,\n",
      "         [-1.4247e+00, -8.3482e-01, -1.3425e-01,  ...,  1.6210e+00,\n",
      "           6.2947e-01,  3.5111e-01],\n",
      "         [-1.2809e-01,  3.1298e-01,  3.7799e-01,  ..., -5.4610e-01,\n",
      "           6.6039e-01, -7.6232e-01],\n",
      "         [-7.6424e-01, -8.5726e-02, -2.9340e-01,  ...,  9.5653e-01,\n",
      "          -1.9625e-02,  1.3285e+00]],\n",
      "\n",
      "        [[-1.9726e+00, -1.5566e+00, -2.3124e-01,  ...,  3.8194e-01,\n",
      "          -1.2228e-01,  6.2835e-01],\n",
      "         [ 4.1966e-01,  5.7102e-01,  1.3496e+00,  ..., -1.5363e+00,\n",
      "           1.3505e+00, -7.1471e-02],\n",
      "         [-6.7169e-01,  1.1435e-04,  3.7660e-01,  ...,  1.5698e+00,\n",
      "          -2.3834e+00, -2.2314e-01],\n",
      "         ...,\n",
      "         [ 8.8166e-01,  2.2479e+00,  1.4123e+00,  ..., -1.0652e+00,\n",
      "           1.0665e+00, -2.6192e-01],\n",
      "         [ 1.2118e+00,  2.0185e+00,  1.8657e+00,  ..., -8.3451e-01,\n",
      "           1.4608e+00, -2.9925e-01],\n",
      "         [-1.1419e+00, -1.0200e+00, -8.8559e-01,  ...,  1.2142e+00,\n",
      "          -4.3257e-01,  6.9617e-01]],\n",
      "\n",
      "        [[-1.4111e-01, -7.7379e-01, -1.4600e+00,  ...,  1.0846e+00,\n",
      "           4.4812e-01,  4.3931e-01],\n",
      "         [ 8.6288e-01,  5.7986e-01,  9.2828e-01,  ..., -4.1773e-01,\n",
      "           3.2189e-01,  8.1890e-01],\n",
      "         [-1.7728e+00, -2.5384e-01,  1.8194e+00,  ..., -6.0583e-01,\n",
      "           5.1822e-02, -9.8406e-01],\n",
      "         ...,\n",
      "         [ 4.3867e-01,  1.1334e+00,  9.3584e-01,  ...,  4.2294e-01,\n",
      "           9.3697e-01,  4.4662e-01],\n",
      "         [ 5.2899e-01,  8.5917e-01,  1.7125e+00,  ..., -3.8362e-01,\n",
      "           5.2466e-02,  6.2319e-01],\n",
      "         [-3.3574e-01, -1.0906e+00, -1.4176e+00,  ...,  8.4518e-01,\n",
      "           6.8235e-01,  3.3238e-01]]], grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 8, 384])\n",
      "= output cat_x torch.Size([32, 8, 384])\n",
      "\n",
      "layer input cat_x torch.Size([32, 8, 384]) None None\n",
      "layer output layer_out (tensor([[[-1.8813, -0.9042, -1.3539,  ...,  1.3607, -0.9123, -0.2844],\n",
      "         [ 0.9312,  0.5110,  1.5855,  ..., -0.1380,  0.8588,  1.3339],\n",
      "         [-1.4198,  0.5177, -1.3163,  ...,  0.3885,  1.3246,  0.4021],\n",
      "         ...,\n",
      "         [ 2.1745,  0.4645,  2.6006,  ..., -0.3081,  0.7121,  0.5009],\n",
      "         [ 1.9166,  0.6316,  3.1090,  ..., -0.5055,  1.3145,  0.9914],\n",
      "         [-1.9530, -1.1701, -1.4682,  ...,  1.2063, -1.1428, -0.5825]],\n",
      "\n",
      "        [[-2.0246, -0.6932, -0.6081,  ..., -0.5520, -3.1941, -0.3383],\n",
      "         [ 1.3739,  0.8137,  0.8405,  ...,  1.4918,  0.5858,  2.0375],\n",
      "         [ 0.6680, -0.2720,  0.9638,  ...,  0.7812,  0.5519,  0.5819],\n",
      "         ...,\n",
      "         [-0.1931,  1.0423, -1.0534,  ...,  0.8078,  0.9389, -0.6681],\n",
      "         [ 1.9641,  1.0397,  0.6229,  ...,  2.5383,  1.8582,  1.5259],\n",
      "         [-1.6058, -1.0028, -0.9817,  ..., -0.8574, -2.1800, -0.3028]],\n",
      "\n",
      "        [[-1.3933,  0.1716, -0.4819,  ...,  0.9928, -1.1549,  0.9800],\n",
      "         [ 0.6302,  1.1618,  1.0299,  ..., -0.2671,  0.7761, -0.6280],\n",
      "         [ 0.7385, -0.1300, -1.1589,  ..., -0.1424, -0.4701,  0.9041],\n",
      "         ...,\n",
      "         [-0.8069,  0.5918,  2.3539,  ...,  0.0525,  0.7378,  0.4196],\n",
      "         [ 0.8717,  0.6494,  1.5160,  ..., -0.5992,  1.7090, -0.5724],\n",
      "         [-1.3702, -0.2982, -0.5076,  ...,  0.7278, -1.1074,  1.6528]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6667, -0.4479, -0.3939,  ...,  1.1735,  0.2087,  0.4800],\n",
      "         [ 0.3859,  0.3505,  0.5685,  ...,  0.0159,  1.0880, -0.7064],\n",
      "         [ 0.6366,  0.0852,  0.3407,  ..., -0.4668, -0.3346,  0.7905],\n",
      "         ...,\n",
      "         [-1.6370, -0.8545, -0.3602,  ...,  1.7173,  0.4300,  0.1202],\n",
      "         [-0.0372,  0.2513,  0.4286,  ..., -0.3100,  0.6134, -0.9012],\n",
      "         [-0.8872, -0.3469, -0.6334,  ...,  0.8480, -0.0067,  1.1340]],\n",
      "\n",
      "        [[-2.0081, -1.3071, -0.3744,  ...,  0.2975, -0.0624,  0.7230],\n",
      "         [ 0.6967,  0.5117,  1.0626,  ..., -1.2663,  1.5187, -0.2875],\n",
      "         [-0.6184, -0.2801,  0.5934,  ...,  1.7157, -2.5673, -0.3265],\n",
      "         ...,\n",
      "         [ 0.8673,  2.2486,  1.1244,  ..., -1.2121,  1.1983, -0.1831],\n",
      "         [ 1.3622,  1.9051,  1.6865,  ..., -0.6026,  1.5126, -0.4228],\n",
      "         [-1.2440, -0.8701, -0.9557,  ...,  1.0861, -0.3991,  0.8099]],\n",
      "\n",
      "        [[-0.3102, -0.7617, -1.4266,  ...,  1.1883,  0.2295,  0.4903],\n",
      "         [ 0.8137,  0.5887,  0.8587,  ..., -0.2271,  0.0606,  0.8889],\n",
      "         [-1.6856, -0.2705,  1.8404,  ..., -0.5777,  0.0534, -0.9785],\n",
      "         ...,\n",
      "         [ 0.5401,  1.3172,  1.0089,  ...,  0.5507,  0.7845,  0.4390],\n",
      "         [ 0.5559,  0.7803,  1.5476,  ..., -0.2226, -0.0289,  0.6780],\n",
      "         [-0.5018, -1.2135, -1.3466,  ...,  1.0426,  0.4904,  0.4175]]],\n",
      "       grad_fn=<AddBackward0>),)\n",
      "\n",
      "= input layer_out[0] torch.Size([32, 8, 384])\n",
      "= output cat_x torch.Size([32, 8, 384])\n",
      "\n",
      "self.split_x input cat_x torch.Size([32, 8, 384])\n",
      "self.split_x output x torch.Size([32, 8, 384])\n",
      "group_token None\n",
      "\n",
      "attention = None\n",
      "\n",
      "= input x torch.Size([32, 8, 384]) group_token None\n",
      "= output outputs (tensor([[[-1.8813, -0.9042, -1.3539,  ...,  1.3607, -0.9123, -0.2844],\n",
      "         [ 0.9312,  0.5110,  1.5855,  ..., -0.1380,  0.8588,  1.3339],\n",
      "         [-1.4198,  0.5177, -1.3163,  ...,  0.3885,  1.3246,  0.4021],\n",
      "         ...,\n",
      "         [ 2.1745,  0.4645,  2.6006,  ..., -0.3081,  0.7121,  0.5009],\n",
      "         [ 1.9166,  0.6316,  3.1090,  ..., -0.5055,  1.3145,  0.9914],\n",
      "         [-1.9530, -1.1701, -1.4682,  ...,  1.2063, -1.1428, -0.5825]],\n",
      "\n",
      "        [[-2.0246, -0.6932, -0.6081,  ..., -0.5520, -3.1941, -0.3383],\n",
      "         [ 1.3739,  0.8137,  0.8405,  ...,  1.4918,  0.5858,  2.0375],\n",
      "         [ 0.6680, -0.2720,  0.9638,  ...,  0.7812,  0.5519,  0.5819],\n",
      "         ...,\n",
      "         [-0.1931,  1.0423, -1.0534,  ...,  0.8078,  0.9389, -0.6681],\n",
      "         [ 1.9641,  1.0397,  0.6229,  ...,  2.5383,  1.8582,  1.5259],\n",
      "         [-1.6058, -1.0028, -0.9817,  ..., -0.8574, -2.1800, -0.3028]],\n",
      "\n",
      "        [[-1.3933,  0.1716, -0.4819,  ...,  0.9928, -1.1549,  0.9800],\n",
      "         [ 0.6302,  1.1618,  1.0299,  ..., -0.2671,  0.7761, -0.6280],\n",
      "         [ 0.7385, -0.1300, -1.1589,  ..., -0.1424, -0.4701,  0.9041],\n",
      "         ...,\n",
      "         [-0.8069,  0.5918,  2.3539,  ...,  0.0525,  0.7378,  0.4196],\n",
      "         [ 0.8717,  0.6494,  1.5160,  ..., -0.5992,  1.7090, -0.5724],\n",
      "         [-1.3702, -0.2982, -0.5076,  ...,  0.7278, -1.1074,  1.6528]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6667, -0.4479, -0.3939,  ...,  1.1735,  0.2087,  0.4800],\n",
      "         [ 0.3859,  0.3505,  0.5685,  ...,  0.0159,  1.0880, -0.7064],\n",
      "         [ 0.6366,  0.0852,  0.3407,  ..., -0.4668, -0.3346,  0.7905],\n",
      "         ...,\n",
      "         [-1.6370, -0.8545, -0.3602,  ...,  1.7173,  0.4300,  0.1202],\n",
      "         [-0.0372,  0.2513,  0.4286,  ..., -0.3100,  0.6134, -0.9012],\n",
      "         [-0.8872, -0.3469, -0.6334,  ...,  0.8480, -0.0067,  1.1340]],\n",
      "\n",
      "        [[-2.0081, -1.3071, -0.3744,  ...,  0.2975, -0.0624,  0.7230],\n",
      "         [ 0.6967,  0.5117,  1.0626,  ..., -1.2663,  1.5187, -0.2875],\n",
      "         [-0.6184, -0.2801,  0.5934,  ...,  1.7157, -2.5673, -0.3265],\n",
      "         ...,\n",
      "         [ 0.8673,  2.2486,  1.1244,  ..., -1.2121,  1.1983, -0.1831],\n",
      "         [ 1.3622,  1.9051,  1.6865,  ..., -0.6026,  1.5126, -0.4228],\n",
      "         [-1.2440, -0.8701, -0.9557,  ...,  1.0861, -0.3991,  0.8099]],\n",
      "\n",
      "        [[-0.3102, -0.7617, -1.4266,  ...,  1.1883,  0.2295,  0.4903],\n",
      "         [ 0.8137,  0.5887,  0.8587,  ..., -0.2271,  0.0606,  0.8889],\n",
      "         [-1.6856, -0.2705,  1.8404,  ..., -0.5777,  0.0534, -0.9785],\n",
      "         ...,\n",
      "         [ 0.5401,  1.3172,  1.0089,  ...,  0.5507,  0.7845,  0.4390],\n",
      "         [ 0.5559,  0.7803,  1.5476,  ..., -0.2226, -0.0289,  0.6780],\n",
      "         [-0.5018, -1.2135, -1.3466,  ...,  1.0426,  0.4904,  0.4175]]],\n",
      "       grad_fn=<AddBackward0>), None)\n",
      "\n",
      "+= input outputs (tensor([[[-1.8813, -0.9042, -1.3539,  ...,  1.3607, -0.9123, -0.2844],\n",
      "         [ 0.9312,  0.5110,  1.5855,  ..., -0.1380,  0.8588,  1.3339],\n",
      "         [-1.4198,  0.5177, -1.3163,  ...,  0.3885,  1.3246,  0.4021],\n",
      "         ...,\n",
      "         [ 2.1745,  0.4645,  2.6006,  ..., -0.3081,  0.7121,  0.5009],\n",
      "         [ 1.9166,  0.6316,  3.1090,  ..., -0.5055,  1.3145,  0.9914],\n",
      "         [-1.9530, -1.1701, -1.4682,  ...,  1.2063, -1.1428, -0.5825]],\n",
      "\n",
      "        [[-2.0246, -0.6932, -0.6081,  ..., -0.5520, -3.1941, -0.3383],\n",
      "         [ 1.3739,  0.8137,  0.8405,  ...,  1.4918,  0.5858,  2.0375],\n",
      "         [ 0.6680, -0.2720,  0.9638,  ...,  0.7812,  0.5519,  0.5819],\n",
      "         ...,\n",
      "         [-0.1931,  1.0423, -1.0534,  ...,  0.8078,  0.9389, -0.6681],\n",
      "         [ 1.9641,  1.0397,  0.6229,  ...,  2.5383,  1.8582,  1.5259],\n",
      "         [-1.6058, -1.0028, -0.9817,  ..., -0.8574, -2.1800, -0.3028]],\n",
      "\n",
      "        [[-1.3933,  0.1716, -0.4819,  ...,  0.9928, -1.1549,  0.9800],\n",
      "         [ 0.6302,  1.1618,  1.0299,  ..., -0.2671,  0.7761, -0.6280],\n",
      "         [ 0.7385, -0.1300, -1.1589,  ..., -0.1424, -0.4701,  0.9041],\n",
      "         ...,\n",
      "         [-0.8069,  0.5918,  2.3539,  ...,  0.0525,  0.7378,  0.4196],\n",
      "         [ 0.8717,  0.6494,  1.5160,  ..., -0.5992,  1.7090, -0.5724],\n",
      "         [-1.3702, -0.2982, -0.5076,  ...,  0.7278, -1.1074,  1.6528]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6667, -0.4479, -0.3939,  ...,  1.1735,  0.2087,  0.4800],\n",
      "         [ 0.3859,  0.3505,  0.5685,  ...,  0.0159,  1.0880, -0.7064],\n",
      "         [ 0.6366,  0.0852,  0.3407,  ..., -0.4668, -0.3346,  0.7905],\n",
      "         ...,\n",
      "         [-1.6370, -0.8545, -0.3602,  ...,  1.7173,  0.4300,  0.1202],\n",
      "         [-0.0372,  0.2513,  0.4286,  ..., -0.3100,  0.6134, -0.9012],\n",
      "         [-0.8872, -0.3469, -0.6334,  ...,  0.8480, -0.0067,  1.1340]],\n",
      "\n",
      "        [[-2.0081, -1.3071, -0.3744,  ...,  0.2975, -0.0624,  0.7230],\n",
      "         [ 0.6967,  0.5117,  1.0626,  ..., -1.2663,  1.5187, -0.2875],\n",
      "         [-0.6184, -0.2801,  0.5934,  ...,  1.7157, -2.5673, -0.3265],\n",
      "         ...,\n",
      "         [ 0.8673,  2.2486,  1.1244,  ..., -1.2121,  1.1983, -0.1831],\n",
      "         [ 1.3622,  1.9051,  1.6865,  ..., -0.6026,  1.5126, -0.4228],\n",
      "         [-1.2440, -0.8701, -0.9557,  ...,  1.0861, -0.3991,  0.8099]],\n",
      "\n",
      "        [[-0.3102, -0.7617, -1.4266,  ...,  1.1883,  0.2295,  0.4903],\n",
      "         [ 0.8137,  0.5887,  0.8587,  ..., -0.2271,  0.0606,  0.8889],\n",
      "         [-1.6856, -0.2705,  1.8404,  ..., -0.5777,  0.0534, -0.9785],\n",
      "         ...,\n",
      "         [ 0.5401,  1.3172,  1.0089,  ...,  0.5507,  0.7845,  0.4390],\n",
      "         [ 0.5559,  0.7803,  1.5476,  ..., -0.2226, -0.0289,  0.6780],\n",
      "         [-0.5018, -1.2135, -1.3466,  ...,  1.0426,  0.4904,  0.4175]]],\n",
      "       grad_fn=<AddBackward0>), None) attention None\n",
      "+= output outputs (tensor([[[-1.8813, -0.9042, -1.3539,  ...,  1.3607, -0.9123, -0.2844],\n",
      "         [ 0.9312,  0.5110,  1.5855,  ..., -0.1380,  0.8588,  1.3339],\n",
      "         [-1.4198,  0.5177, -1.3163,  ...,  0.3885,  1.3246,  0.4021],\n",
      "         ...,\n",
      "         [ 2.1745,  0.4645,  2.6006,  ..., -0.3081,  0.7121,  0.5009],\n",
      "         [ 1.9166,  0.6316,  3.1090,  ..., -0.5055,  1.3145,  0.9914],\n",
      "         [-1.9530, -1.1701, -1.4682,  ...,  1.2063, -1.1428, -0.5825]],\n",
      "\n",
      "        [[-2.0246, -0.6932, -0.6081,  ..., -0.5520, -3.1941, -0.3383],\n",
      "         [ 1.3739,  0.8137,  0.8405,  ...,  1.4918,  0.5858,  2.0375],\n",
      "         [ 0.6680, -0.2720,  0.9638,  ...,  0.7812,  0.5519,  0.5819],\n",
      "         ...,\n",
      "         [-0.1931,  1.0423, -1.0534,  ...,  0.8078,  0.9389, -0.6681],\n",
      "         [ 1.9641,  1.0397,  0.6229,  ...,  2.5383,  1.8582,  1.5259],\n",
      "         [-1.6058, -1.0028, -0.9817,  ..., -0.8574, -2.1800, -0.3028]],\n",
      "\n",
      "        [[-1.3933,  0.1716, -0.4819,  ...,  0.9928, -1.1549,  0.9800],\n",
      "         [ 0.6302,  1.1618,  1.0299,  ..., -0.2671,  0.7761, -0.6280],\n",
      "         [ 0.7385, -0.1300, -1.1589,  ..., -0.1424, -0.4701,  0.9041],\n",
      "         ...,\n",
      "         [-0.8069,  0.5918,  2.3539,  ...,  0.0525,  0.7378,  0.4196],\n",
      "         [ 0.8717,  0.6494,  1.5160,  ..., -0.5992,  1.7090, -0.5724],\n",
      "         [-1.3702, -0.2982, -0.5076,  ...,  0.7278, -1.1074,  1.6528]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6667, -0.4479, -0.3939,  ...,  1.1735,  0.2087,  0.4800],\n",
      "         [ 0.3859,  0.3505,  0.5685,  ...,  0.0159,  1.0880, -0.7064],\n",
      "         [ 0.6366,  0.0852,  0.3407,  ..., -0.4668, -0.3346,  0.7905],\n",
      "         ...,\n",
      "         [-1.6370, -0.8545, -0.3602,  ...,  1.7173,  0.4300,  0.1202],\n",
      "         [-0.0372,  0.2513,  0.4286,  ..., -0.3100,  0.6134, -0.9012],\n",
      "         [-0.8872, -0.3469, -0.6334,  ...,  0.8480, -0.0067,  1.1340]],\n",
      "\n",
      "        [[-2.0081, -1.3071, -0.3744,  ...,  0.2975, -0.0624,  0.7230],\n",
      "         [ 0.6967,  0.5117,  1.0626,  ..., -1.2663,  1.5187, -0.2875],\n",
      "         [-0.6184, -0.2801,  0.5934,  ...,  1.7157, -2.5673, -0.3265],\n",
      "         ...,\n",
      "         [ 0.8673,  2.2486,  1.1244,  ..., -1.2121,  1.1983, -0.1831],\n",
      "         [ 1.3622,  1.9051,  1.6865,  ..., -0.6026,  1.5126, -0.4228],\n",
      "         [-1.2440, -0.8701, -0.9557,  ...,  1.0861, -0.3991,  0.8099]],\n",
      "\n",
      "        [[-0.3102, -0.7617, -1.4266,  ...,  1.1883,  0.2295,  0.4903],\n",
      "         [ 0.8137,  0.5887,  0.8587,  ..., -0.2271,  0.0606,  0.8889],\n",
      "         [-1.6856, -0.2705,  1.8404,  ..., -0.5777,  0.0534, -0.9785],\n",
      "         ...,\n",
      "         [ 0.5401,  1.3172,  1.0089,  ...,  0.5507,  0.7845,  0.4390],\n",
      "         [ 0.5559,  0.7803,  1.5476,  ..., -0.2226, -0.0289,  0.6780],\n",
      "         [-0.5018, -1.2135, -1.3466,  ...,  1.0426,  0.4904,  0.4175]]],\n",
      "       grad_fn=<AddBackward0>), None, None)\n",
      "\n",
      "all_output (tensor([[[-1.8813, -0.9042, -1.3539,  ...,  1.3607, -0.9123, -0.2844],\n",
      "         [ 0.9312,  0.5110,  1.5855,  ..., -0.1380,  0.8588,  1.3339],\n",
      "         [-1.4198,  0.5177, -1.3163,  ...,  0.3885,  1.3246,  0.4021],\n",
      "         ...,\n",
      "         [ 2.1745,  0.4645,  2.6006,  ..., -0.3081,  0.7121,  0.5009],\n",
      "         [ 1.9166,  0.6316,  3.1090,  ..., -0.5055,  1.3145,  0.9914],\n",
      "         [-1.9530, -1.1701, -1.4682,  ...,  1.2063, -1.1428, -0.5825]],\n",
      "\n",
      "        [[-2.0246, -0.6932, -0.6081,  ..., -0.5520, -3.1941, -0.3383],\n",
      "         [ 1.3739,  0.8137,  0.8405,  ...,  1.4918,  0.5858,  2.0375],\n",
      "         [ 0.6680, -0.2720,  0.9638,  ...,  0.7812,  0.5519,  0.5819],\n",
      "         ...,\n",
      "         [-0.1931,  1.0423, -1.0534,  ...,  0.8078,  0.9389, -0.6681],\n",
      "         [ 1.9641,  1.0397,  0.6229,  ...,  2.5383,  1.8582,  1.5259],\n",
      "         [-1.6058, -1.0028, -0.9817,  ..., -0.8574, -2.1800, -0.3028]],\n",
      "\n",
      "        [[-1.3933,  0.1716, -0.4819,  ...,  0.9928, -1.1549,  0.9800],\n",
      "         [ 0.6302,  1.1618,  1.0299,  ..., -0.2671,  0.7761, -0.6280],\n",
      "         [ 0.7385, -0.1300, -1.1589,  ..., -0.1424, -0.4701,  0.9041],\n",
      "         ...,\n",
      "         [-0.8069,  0.5918,  2.3539,  ...,  0.0525,  0.7378,  0.4196],\n",
      "         [ 0.8717,  0.6494,  1.5160,  ..., -0.5992,  1.7090, -0.5724],\n",
      "         [-1.3702, -0.2982, -0.5076,  ...,  0.7278, -1.1074,  1.6528]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6667, -0.4479, -0.3939,  ...,  1.1735,  0.2087,  0.4800],\n",
      "         [ 0.3859,  0.3505,  0.5685,  ...,  0.0159,  1.0880, -0.7064],\n",
      "         [ 0.6366,  0.0852,  0.3407,  ..., -0.4668, -0.3346,  0.7905],\n",
      "         ...,\n",
      "         [-1.6370, -0.8545, -0.3602,  ...,  1.7173,  0.4300,  0.1202],\n",
      "         [-0.0372,  0.2513,  0.4286,  ..., -0.3100,  0.6134, -0.9012],\n",
      "         [-0.8872, -0.3469, -0.6334,  ...,  0.8480, -0.0067,  1.1340]],\n",
      "\n",
      "        [[-2.0081, -1.3071, -0.3744,  ...,  0.2975, -0.0624,  0.7230],\n",
      "         [ 0.6967,  0.5117,  1.0626,  ..., -1.2663,  1.5187, -0.2875],\n",
      "         [-0.6184, -0.2801,  0.5934,  ...,  1.7157, -2.5673, -0.3265],\n",
      "         ...,\n",
      "         [ 0.8673,  2.2486,  1.1244,  ..., -1.2121,  1.1983, -0.1831],\n",
      "         [ 1.3622,  1.9051,  1.6865,  ..., -0.6026,  1.5126, -0.4228],\n",
      "         [-1.2440, -0.8701, -0.9557,  ...,  1.0861, -0.3991,  0.8099]],\n",
      "\n",
      "        [[-0.3102, -0.7617, -1.4266,  ...,  1.1883,  0.2295,  0.4903],\n",
      "         [ 0.8137,  0.5887,  0.8587,  ..., -0.2271,  0.0606,  0.8889],\n",
      "         [-1.6856, -0.2705,  1.8404,  ..., -0.5777,  0.0534, -0.9785],\n",
      "         ...,\n",
      "         [ 0.5401,  1.3172,  1.0089,  ...,  0.5507,  0.7845,  0.4390],\n",
      "         [ 0.5559,  0.7803,  1.5476,  ..., -0.2226, -0.0289,  0.6780],\n",
      "         [-0.5018, -1.2135, -1.3466,  ...,  1.0426,  0.4904,  0.4175]]],\n",
      "       grad_fn=<AddBackward0>), None, None)\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "model = ModelBase(configuration=config, projection_dim=128)\n",
    "\n",
    "t = torch.randn((32,3,224,224))\n",
    "print(t.shape)\n",
    "print(model(t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GroupViTVisionConfig().from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "# model = GroupViTCrossAttentionLayer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = torch.randn((32, 64, 384))\n",
    "# key = torch.randn((32, 196, 384))\n",
    "\n",
    "# print('query', query.shape) # torch.Size([32, 64, 384])\n",
    "# print('key', key.shape) # torch.Size([32, 196, 384])\n",
    "\n",
    "# print(model(query, key).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uuwerq7N9s5S"
   },
   "source": [
    "### Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677512218962,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "dvuxcmejkKt8",
    "outputId": "4e6311d9-6fd0-43ed-c40a-e5541e35f105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(arch='resnet18', batch_size=32, bn_splits=8, cos=True, epochs=200, finetune_data_dir='/home/../lab_06/fine-tune_set/siim-acr-pneumothorax', image_size=650, knn_k=200, knn_t=0.1, lr=0.007, moco_dim=128, moco_k=4096, moco_m=0.99, moco_t=0.1, pretrain_data_dir='/home/unlabel_pre-training_set', results_dir='/home/230312_v0.1.02023-03-22-02-49-23-moco', resume='', schedule=[], seed=1, symmetric=False, wd=0.0005)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Train MoCo on CIFAR-10')\n",
    "\n",
    "parser.add_argument('-a', '--arch', default='resnet18')\n",
    "\n",
    "parser.add_argument('--finetune_data_dir', default=os.path.join(ROOT_PATH, '../lab_06', 'fine-tune_set', 'siim-acr-pneumothorax'))\n",
    "# parser.add_argument('--pretrain_data_dir', default=os.path.join(ROOT_PATH, '../lab_05', 'unlabel_pre-training_set'))\n",
    "parser.add_argument('--pretrain_data_dir', default=os.path.join(ROOT_PATH, 'unlabel_pre-training_set'))\n",
    "\n",
    "parser.add_argument('--image_size', default=650, type=int)\n",
    "\n",
    "parser.add_argument('--seed', default=1)\n",
    "\n",
    "# lr: 0.06 for batch 512 (or 0.03 for batch 256)\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.007, type=float, metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--epochs', default=200, type=int, metavar='N', help='number of total epochs to run')\n",
    "parser.add_argument('--schedule', default=[120, 160], nargs='*', type=int, help='learning rate schedule (when to drop lr by 10x); does not take effect if --cos is on')\n",
    "parser.add_argument('--cos', action='store_true', help='use cosine lr schedule')\n",
    "\n",
    "parser.add_argument('--batch-size', default=32, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
    "\n",
    "# moco specific configs:\n",
    "parser.add_argument('--moco-dim', default=128, type=int, help='feature dimension')#####\n",
    "parser.add_argument('--moco-k', default=4096, type=int, help='queue size; number of negative keys')\n",
    "parser.add_argument('--moco-m', default=0.99, type=float, help='moco momentum of updating key encoder')\n",
    "parser.add_argument('--moco-t', default=0.1, type=float, help='softmax temperature')\n",
    "\n",
    "parser.add_argument('--bn-splits', default=8, type=int, help='simulate multi-gpu behavior of BatchNorm in one gpu; 1 is SyncBatchNorm in multi-gpu')\n",
    "\n",
    "parser.add_argument('--symmetric', action='store_true', help='use a symmetric loss function that backprops to both crops')\n",
    "\n",
    "# knn monitor\n",
    "parser.add_argument('--knn-k', default=200, type=int, help='k in kNN monitor')\n",
    "parser.add_argument('--knn-t', default=0.1, type=float, help='softmax temperature in kNN monitor; could be different with moco-t')\n",
    "\n",
    "# utils\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--results-dir', default='', type=str, metavar='PATH', help='path to cache (default: none)')\n",
    "\n",
    "'''\n",
    "args = parser.parse_args()  # running in command line\n",
    "'''\n",
    "args = parser.parse_args('')  # running in ipynb\n",
    "\n",
    "# set command line arguments here when running in ipynb\n",
    "args.epochs = 200\n",
    "args.cos = True\n",
    "args.schedule = []  # cos in use\n",
    "args.symmetric = False\n",
    "if args.results_dir == '':\n",
    "    args.results_dir = root_folder + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S-moco\")\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ygQeHtsngrC8"
   },
   "source": [
    "### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as T\n",
    "# from transformers import AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processor(tensor):\n",
    "#     processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "#     transform = T.ToPILImage()\n",
    "\n",
    "#     img = transform(tensor)\n",
    "#     inputs = processor(images=img, return_tensors=\"pt\")\n",
    "#     pixel_values = np.array(inputs[\"pixel_values\"])\n",
    "#     pixel_values = pixel_values.squeeze()\n",
    "#     pixel_values = torch.tensor(pixel_values)\n",
    "\n",
    "#     return pixel_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677512218962,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "PvfVDZ8cdNqR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/unlabel_pre-training_set/images_001/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/unlabel_pre-training_set/images_001/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/unlabel_pre-training_set/images_001/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/unlabel_pre-training_set/images_001/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/unlabel_pre-training_set/images_001/imag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images\n",
       "0  /home/unlabel_pre-training_set/images_001/imag...\n",
       "1  /home/unlabel_pre-training_set/images_001/imag...\n",
       "2  /home/unlabel_pre-training_set/images_001/imag...\n",
       "3  /home/unlabel_pre-training_set/images_001/imag...\n",
       "4  /home/unlabel_pre-training_set/images_001/imag..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "i = 0\n",
    "\n",
    "for get_folder in os.listdir(args.pretrain_data_dir):\n",
    "    if get_folder.split('_')[0] == 'images' and get_folder.split('.')[-1] != 'zip':\n",
    "        for get_png in os.listdir(os.path.join(args.pretrain_data_dir, get_folder, 'images')):\n",
    "            images += [os.path.join(args.pretrain_data_dir, get_folder, 'images', get_png)]\n",
    "            i = i+1\n",
    "\n",
    "PathDF = pd.DataFrame({'images': images})\n",
    "print(i)\n",
    "PathDF.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(idx):\n",
    "    img = Image.open(PathDF['images'].iloc[idx])\n",
    "    print(np.array(img.convert('RGB')).shape)\n",
    "    \n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(args.image_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(args.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set dataset & loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CXR_Dataset_pair(Dataset):\n",
    "    def __init__(self, path_df, transform=None):\n",
    "\n",
    "        self.path_df = path_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.path_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(Image.open(self.path_df.iloc[idx]['images']).convert('RGB'))\n",
    "            im_2 = self.transform(Image.open(self.path_df.iloc[idx]['images']).convert('RGB'))\n",
    "        \n",
    "        return im_1, im_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179,
     "referenced_widgets": [
      "17032952ca804b558931b93c0fde1540",
      "cc091016bb8d423f80dddca00096ba0b",
      "6bbbd0d7f0f749939610ccc1aa47bfec",
      "eb9b54187a9b4404b93ce96cb5297a1e",
      "48854cfeccd84183a1819d703353a4fa",
      "7cdb20bd656249fe85674962d2a4ba7e",
      "20faf3fda02c4257b5ac68099de45581",
      "a4d8fcd96c2b44c1a21e6a0cf46d736d",
      "5bffaeb6f389499c958f4a12dca192e4",
      "d9070ee51e9c4ebe868777345a25a62d",
      "cf90228e48af46809d35402d94eb568e"
     ]
    },
    "executionInfo": {
     "elapsed": 23888,
     "status": "ok",
     "timestamp": 1677512242845,
     "user": {
      "displayName": "野菜浅",
      "userId": "15074908195438095604"
     },
     "user_tz": -480
    },
    "id": "AoliFX5AnBJ0",
    "outputId": "978c2de8-f216-4ff2-b94f-ae3d2c15be6a"
   },
   "outputs": [],
   "source": [
    "train_data = CXR_Dataset_pair(PathDF, transform=train_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "# memory_data = MRI_Dataset(train_df, transform=test_transform)\n",
    "# memory_loader = DataLoader(memory_data, batch_size=Config.valid_batch, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# test_data = MRI_Dataset(test_df, transform=test_transform)\n",
    "# test_loader = DataLoader(test_data, batch_size=Config.test_batch, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader)) # get a batch from the dataloader\n",
    "im_1, im_2 = batch\n",
    "\n",
    "# plot some random images in the `batch`\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "idx = random.choice(range(args.batch_size))\n",
    "ax[0].imshow(im_1[idx][0].T, cmap='bone')\n",
    "ax[1].imshow(im_2[idx][0].T, cmap='bone')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KsAVAtRoiBbG"
   },
   "source": [
    "### Define Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define base encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SplitBatchNorm: simulate multi-gpu behavior of BatchNorm in one gpu by splitting alone the batch dimension\n",
    "# implementation adapted from https://github.com/davidcpage/cifar10-fast/blob/master/torch_backend.py\n",
    "# class SplitBatchNorm(nn.BatchNorm2d):\n",
    "#     def __init__(self, num_features, num_splits, **kw):\n",
    "#         super().__init__(num_features, **kw)\n",
    "#         self.num_splits = num_splits\n",
    "        \n",
    "#     def forward(self, input):\n",
    "#         N, C, H, W = input.shape\n",
    "#         if self.training or not self.track_running_stats:\n",
    "#             running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "#             running_var_split = self.running_var.repeat(self.num_splits)\n",
    "#             outcome = nn.functional.batch_norm(\n",
    "#                 input.view(-1, C * self.num_splits, H, W), running_mean_split, running_var_split, \n",
    "#                 self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
    "#                 True, self.momentum, self.eps).view(N, C, H, W)\n",
    "#             self.running_mean.data.copy_(running_mean_split.view(self.num_splits, C).mean(dim=0))\n",
    "#             self.running_var.data.copy_(running_var_split.view(self.num_splits, C).mean(dim=0))\n",
    "#             return outcome\n",
    "#         else:\n",
    "#             return nn.functional.batch_norm(\n",
    "#                 input, self.running_mean, self.running_var, \n",
    "#                 self.weight, self.bias, False, self.momentum, self.eps)\n",
    "\n",
    "# class ModelBase(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Common CIFAR ResNet recipe.\n",
    "#     Comparing with ImageNet ResNet recipe, it:\n",
    "#     (i) replaces conv1 with kernel=3, str=1\n",
    "#     (ii) removes pool1\n",
    "#     \"\"\"\n",
    "#     def __init__(self, feature_dim=128, arch=None, bn_splits=16):\n",
    "#         super(ModelBase, self).__init__()\n",
    "\n",
    "#         # use split batchnorm\n",
    "#         norm_layer = partial(SplitBatchNorm, num_splits=bn_splits) if bn_splits > 1 else nn.BatchNorm2d\n",
    "#         resnet_arch = getattr(resnet, arch)\n",
    "#         net = resnet_arch(num_classes=feature_dim, norm_layer=norm_layer)\n",
    "\n",
    "#         self.net = []\n",
    "#         for name, module in net.named_children():\n",
    "#             if name == 'conv1':\n",
    "#                 module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#             if isinstance(module, nn.MaxPool2d):\n",
    "#                 continue\n",
    "#             if isinstance(module, nn.Linear):\n",
    "#                 self.net.append(nn.Flatten(1))\n",
    "#             self.net.append(module)\n",
    "\n",
    "#         self.net = nn.Sequential(*self.net)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.net(x)\n",
    "#         # note: not normalized here\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "configuration = GroupViTVisionConfig().from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "# print(configuration)\n",
    "print(configuration.image_size)\n",
    "\n",
    "configuration.image_size = args.image_size\n",
    "print(configuration.image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBase(nn.Module):\n",
    "    def __init__(self, configuration, projection_dim):\n",
    "        super(ModelBase, self).__init__()\n",
    "        \n",
    "        self.model = GroupViTVisionModel(configuration, projection_dim)\n",
    "\n",
    "    def forward(self, x, segmap=False):\n",
    "        vision_outputs, logits, image_features= self.model(x)\n",
    "\n",
    "        if segmap:\n",
    "            return image_features, logits\n",
    "        else:\n",
    "            return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelBase(configuration=configuration)\n",
    "\n",
    "# t = torch.randn((32,3,512,512))\n",
    "# print(t.shape)\n",
    "# print(model(t).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MoCo wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMoCo(nn.Module):\n",
    "    def __init__(self, configuration, dim=128, K=4096, m=0.99, T=0.1, symmetric=True):\n",
    "        super(ModelMoCo, self).__init__()\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.symmetric = symmetric\n",
    "\n",
    "        # create the encoders\n",
    "        self.encoder_q = ModelBase(configuration, dim)\n",
    "        self.encoder_k = ModelBase(configuration, dim)\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.t()  # transpose\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_single_gpu(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        \"\"\"\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(x.shape[0]).cuda()\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_single_gpu(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        \"\"\"\n",
    "        return x[idx_unshuffle]\n",
    "\n",
    "    def contrastive_loss(self, im_q, im_k):\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)  # already normalized\n",
    "\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            # shuffle for making use of BN\n",
    "            im_k_, idx_unshuffle = self._batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k_)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)  # already normalized\n",
    "\n",
    "            # undo shuffle\n",
    "            k = self._batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss().cuda()(logits, labels)\n",
    "\n",
    "        return loss, q, k\n",
    "\n",
    "    def forward(self, im1, im2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # update the key encoder\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()\n",
    "\n",
    "        # compute loss\n",
    "        if self.symmetric:  # asymmetric loss\n",
    "            loss_12, q1, k2 = self.contrastive_loss(im1, im2)\n",
    "            loss_21, q2, k1 = self.contrastive_loss(im2, im1)\n",
    "            loss = loss_12 + loss_21\n",
    "            k = torch.cat([k1, k2], dim=0)\n",
    "        else:  # asymmetric loss\n",
    "            loss, q, k = self.contrastive_loss(im1, im2)\n",
    "\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return loss\n",
    "\n",
    "# create model\n",
    "model = ModelMoCo(\n",
    "        configuration=configuration,\n",
    "        dim=args.moco_dim,\n",
    "        K=args.moco_k,\n",
    "        m=args.moco_m,\n",
    "        T=args.moco_t,\n",
    "        symmetric=args.symmetric,\n",
    "    ).cuda()\n",
    "# print(model.encoder_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): ModelMoCo(\n",
      "    (encoder_q): ModelBase(\n",
      "      (model): GroupViTVisionModel(\n",
      "        (vision_model): GroupViTVisionTransformer(\n",
      "          (embeddings): GroupViTVisionEmbeddings(\n",
      "            (patch_embeddings): GroupViTPatchEmbeddings(\n",
      "              (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "            )\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (encoder): GroupViTVisionEncoder(\n",
      "            (stages): ModuleList(\n",
      "              (0): GroupViTStage(\n",
      "                (layers): ModuleList(\n",
      "                  (0): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (3): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (4): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (5): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (downsample): GroupViTTokenAssign(\n",
      "                  (norm_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_inter): GroupViTMixerMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=64, out_features=192, bias=True)\n",
      "                    (fc2): Linear(in_features=192, out_features=64, bias=True)\n",
      "                  )\n",
      "                  (norm_post_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (norm_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (pre_assign_attn): GroupViTCrossAttentionLayer(\n",
      "                    (attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (assign): GroupViTAssignAttention(\n",
      "                    (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  )\n",
      "                  (norm_new_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_channels): GroupViTMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                    (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (1): GroupViTStage(\n",
      "                (layers): ModuleList(\n",
      "                  (0): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (downsample): GroupViTTokenAssign(\n",
      "                  (norm_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_inter): GroupViTMixerMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=8, out_features=192, bias=True)\n",
      "                    (fc2): Linear(in_features=192, out_features=8, bias=True)\n",
      "                  )\n",
      "                  (norm_post_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (norm_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (pre_assign_attn): GroupViTCrossAttentionLayer(\n",
      "                    (attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (assign): GroupViTAssignAttention(\n",
      "                    (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  )\n",
      "                  (norm_new_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_channels): GroupViTMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                    (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  )\n",
      "                )\n",
      "                (group_projector): Sequential(\n",
      "                  (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (1): GroupViTMixerMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=64, out_features=192, bias=True)\n",
      "                    (fc2): Linear(in_features=192, out_features=8, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (2): GroupViTStage(\n",
      "                (layers): ModuleList(\n",
      "                  (0): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (visual_projection): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=4096, bias=True)\n",
      "          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Linear(in_features=4096, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoder_k): ModelBase(\n",
      "      (model): GroupViTVisionModel(\n",
      "        (vision_model): GroupViTVisionTransformer(\n",
      "          (embeddings): GroupViTVisionEmbeddings(\n",
      "            (patch_embeddings): GroupViTPatchEmbeddings(\n",
      "              (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "            )\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (encoder): GroupViTVisionEncoder(\n",
      "            (stages): ModuleList(\n",
      "              (0): GroupViTStage(\n",
      "                (layers): ModuleList(\n",
      "                  (0): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (3): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (4): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (5): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (downsample): GroupViTTokenAssign(\n",
      "                  (norm_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_inter): GroupViTMixerMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=64, out_features=192, bias=True)\n",
      "                    (fc2): Linear(in_features=192, out_features=64, bias=True)\n",
      "                  )\n",
      "                  (norm_post_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (norm_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (pre_assign_attn): GroupViTCrossAttentionLayer(\n",
      "                    (attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (assign): GroupViTAssignAttention(\n",
      "                    (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  )\n",
      "                  (norm_new_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_channels): GroupViTMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                    (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (1): GroupViTStage(\n",
      "                (layers): ModuleList(\n",
      "                  (0): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "                (downsample): GroupViTTokenAssign(\n",
      "                  (norm_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_inter): GroupViTMixerMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=8, out_features=192, bias=True)\n",
      "                    (fc2): Linear(in_features=192, out_features=8, bias=True)\n",
      "                  )\n",
      "                  (norm_post_tokens): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (norm_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (pre_assign_attn): GroupViTCrossAttentionLayer(\n",
      "                    (attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (norm_post): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (assign): GroupViTAssignAttention(\n",
      "                    (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  )\n",
      "                  (norm_new_x): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (mlp_channels): GroupViTMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                    (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                  )\n",
      "                )\n",
      "                (group_projector): Sequential(\n",
      "                  (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  (1): GroupViTMixerMLP(\n",
      "                    (activation_fn): GELUActivation()\n",
      "                    (fc1): Linear(in_features=64, out_features=192, bias=True)\n",
      "                    (fc2): Linear(in_features=192, out_features=8, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (2): GroupViTStage(\n",
      "                (layers): ModuleList(\n",
      "                  (0): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (1): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                  (2): GroupViTEncoderLayer(\n",
      "                    (self_attn): GroupViTAttention(\n",
      "                      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): GroupViTMLP(\n",
      "                      (activation_fn): GELUActivation()\n",
      "                      (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                      (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                    )\n",
      "                    (layer_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (visual_projection): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=4096, bias=True)\n",
      "          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Linear(in_features=4096, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ### for_multi_GPU\n",
    "model = nn.DataParallel(model)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9YXcpXBwi8KV"
   },
   "source": [
    "### Define train/test\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss and metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define train & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def train(net, data_loader, train_optimizer, epoch, args):\n",
    "    net.train()\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
    "    for im_1, im_2 in train_bar:\n",
    "\n",
    "        # print(im_1.shape, type(im_1), type(im_1[0][0][0][0]), im_1[0][0][0][0], im_1)\n",
    "\n",
    "        im_1, im_2 = im_1.cuda(non_blocking=True), im_2.cuda(non_blocking=True)\n",
    "\n",
    "        loss = net(im_1, im_2) # torch.Size([512, 3, 32, 32])*2\n",
    "        \n",
    "#         print(loss)\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        train_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        total_num += data_loader.batch_size\n",
    "        total_loss += loss.item() * data_loader.batch_size\n",
    "        train_bar.set_description('Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(epoch, args.epochs, optimizer.param_groups[0]['lr'], total_loss / total_num))\n",
    "\n",
    "    return total_loss / total_num\n",
    "\n",
    "# lr scheduler for training\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    lr = args.lr\n",
    "    if args.cos:  # cosine lr schedule\n",
    "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in args.schedule:\n",
    "            lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test using a knn monitor\n",
    "def test(net, memory_data_loader, test_data_loader, epoch, args):\n",
    "    net.eval()\n",
    "    classes = len(memory_data_loader.dataset.classes)\n",
    "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
    "    with torch.no_grad():\n",
    "        # generate feature bank\n",
    "        for data, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
    "            feature = net(data.cuda(non_blocking=True))\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            feature_bank.append(feature)\n",
    "        # [D, N]\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        # [N]\n",
    "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
    "        # loop test data to predict the label by weighted knn search\n",
    "        test_bar = tqdm(test_data_loader)\n",
    "        for data, target in test_bar:\n",
    "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
    "            feature = net(data)\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            \n",
    "            pred_labels = knn_predict(feature, feature_bank, feature_labels, classes, args.knn_k, args.knn_t)\n",
    "\n",
    "            total_num += data.size(0)\n",
    "            total_top1 += (pred_labels[:, 0] == target).float().sum().item()\n",
    "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}%'.format(epoch, args.epochs, total_top1 / total_num * 100))\n",
    "\n",
    "    return total_top1 / total_num * 100\n",
    "\n",
    "# knn monitor as in InstDisc https://arxiv.org/abs/1805.01978\n",
    "# implementation follows http://github.com/zhirongw/lemniscate.pytorch and https://github.com/leftthomas/SimCLR\n",
    "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t):\n",
    "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    # [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    # [B, K]\n",
    "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "\n",
    "    # counts for each class\n",
    "    one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\n",
    "    # [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "    # weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(args.image_size),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "def ade_palette():\n",
    "    return [[  0,   0,   0], [  0,   0, 255], [  0, 255,   0], [255,   0,   0],\n",
    "            [255, 255, 255], [255, 255,   0], [255,   0, 255], [  0, 255, 255]]\n",
    "\n",
    "def get_input_image(get_id, processor):\n",
    "    img_path = PathDF['images'].iloc[get_id]\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "#     inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = transform(image)\n",
    "\n",
    "#     return inputs[\"pixel_values\"].cuda(), image, img_path.split('/')[-1]\n",
    "    return inputs, image, img_path.split('/')[-1]\n",
    "\n",
    "def get_color_seg(logits, image):\n",
    "    # First, rescale logits to original image size\n",
    "    logits = nn.functional.interpolate(logits.detach().cpu(),\n",
    "                    size=image.size[::-1], # (height, width)\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False)\n",
    "\n",
    "    # Second, apply argmax on the class dimension\n",
    "    seg = logits.argmax(dim=1)[0]\n",
    "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "    palette = np.array(ade_palette())\n",
    "    for label, color in enumerate(palette):\n",
    "        color_seg[seg == label, :] = color\n",
    "    # Convert to BGR\n",
    "    color_seg = color_seg[..., ::-1]\n",
    "\n",
    "    return color_seg\n",
    "\n",
    "def plot(image, color_seg, text):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(8,4))\n",
    "    ax[0].imshow(np.array(image).astype(np.uint8))\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(np.array(color_seg).astype(np.uint8))\n",
    "    ax[1].set_title(\"Mask\")\n",
    "    img = np.array(image) * 0.7 + color_seg * 0.3\n",
    "    img = img.astype(np.uint8)\n",
    "    ax[2].imshow(img)\n",
    "    ax[2].set_title(text)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "def looker(idx, processor):\n",
    "    input, image, name = get_input_image(idx, processor)\n",
    "#     _, logits = model.encoder_q(input, segmap=True)\n",
    "\n",
    "    # ### for_multi_GPU\n",
    "    _, logits = model.module.encoder_q(input, segmap=True)\n",
    "    \n",
    "    color_seg = get_color_seg(logits, image)\n",
    "\n",
    "    plot(image, color_seg, 'trained')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "86lHkiKox3KO"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3503 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Train Epoch: [1/200], lr: 0.007000, Loss: 7.0288:   6%|▌         | 198/3503 [24:47<6:58:51,  7.60s/it]"
     ]
    }
   ],
   "source": [
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wd, momentum=0.9)\n",
    "\n",
    "# load model if resume\n",
    "epoch_start = 1\n",
    "if args.resume is not '':\n",
    "    checkpoint = torch.load(args.resume)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_start = checkpoint['epoch'] + 1\n",
    "    print('Loaded from: {}'.format(args.resume))\n",
    "\n",
    "# logging\n",
    "results = {'train_loss': [], 'test_acc@1': []}\n",
    "if not os.path.exists(args.results_dir):\n",
    "    os.mkdir(args.results_dir)\n",
    "# dump args\n",
    "with open(args.results_dir + '/args.json', 'w') as fid:\n",
    "    json.dump(args.__dict__, fid, indent=2)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epoch_start, args.epochs + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, epoch, args)\n",
    "    results['train_loss'].append(train_loss)\n",
    "#     looker(5, processor)\n",
    "    # test_acc_1 = test(model.encoder_q, memory_loader, test_loader, epoch, args)\n",
    "    results['test_acc@1'].append(0.5)\n",
    "    # save statistics\n",
    "    data_frame = pd.DataFrame(data=results, index=range(epoch_start, epoch + 1))\n",
    "    data_frame.to_csv(args.results_dir + '/log.csv', index_label='epoch')\n",
    "    \n",
    "    # save model\n",
    "#     torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/model_last.pth')\n",
    "#     torch.save({'epoch': epoch, 'encoder_q_state_dict': model.encoder_q.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/encoder_q_model_last.pth')\n",
    "\n",
    "    # ### for_multi_GPU\n",
    "    torch.save({'epoch': epoch, 'state_dict': model.module.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/model_last.pth')\n",
    "    torch.save({'epoch': epoch, 'encoder_q_state_dict': model.module.encoder_q.state_dict(), 'optimizer' : optimizer.state_dict(),}, args.results_dir + '/encoder_q_model_last.pth')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_model_with_pretrain_weight(model, weight_path):\n",
    "#     checkpoint = torch.load(os.path.abspath(os.path.join(ROOT_PATH, weight_path, 'model_last.pth')))\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "#     return model.encoder_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ = get_model_with_pretrain_weight(model, '../lab_05/230307_v0.0.62023-03-07-13-03-04-moco')\n",
    "# model__ = GroupViTVisionModel.from_pretrained(\"nvidia/groupvit-gcc-yfcc\", ignore_mismatched_sizes=True)\n",
    "# processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "# for get_id in range(PathDF.shape[0]):\n",
    "\n",
    "#     input, image, name = get_input_image(get_id, processor)\n",
    "#     _, logits = model_(input)\n",
    "#     color_seg = get_color_seg(logits, image)\n",
    "\n",
    "#     plot(image, color_seg, 'trained')\n",
    "\n",
    "#     inputs__ = processor(images=image, return_tensors=\"pt\")\n",
    "#     _, logits__, _ = model__(**inputs__)\n",
    "#     color_seg = get_color_seg(logits__, image)\n",
    "\n",
    "#     plot(image, color_seg, 'untrain')\n",
    "\n",
    "\n",
    "# print('\\n\\nSuccessfully Completed!!!\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# i = 0\n",
    "\n",
    "# for get_folder in os.listdir(args.finetune_data_dir):\n",
    "#     if get_folder == 'png_images':\n",
    "#         for get_file in os.listdir(os.path.join(args.finetune_data_dir, 'png_images')):\n",
    "#             if get_file in os.listdir(os.path.join(args.finetune_data_dir, 'png_masks')):\n",
    "#                 images += [os.path.join(args.finetune_data_dir, 'png_images', get_file)]\n",
    "#                 i = i+1\n",
    "\n",
    "# PathDF = pd.DataFrame({'images': images})\n",
    "# print(i)\n",
    "# PathDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_example(idx):\n",
    "#     img = Image.open(PathDF['images'].iloc[idx])\n",
    "#     print(np.array(img.convert('RGB')).shape)\n",
    "    \n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_example(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ = get_model_with_pretrain_weight(model, '../lab_05/230307_v0.0.62023-03-07-13-03-04-moco')\n",
    "# processor = AutoProcessor.from_pretrained(\"nvidia/groupvit-gcc-yfcc\")\n",
    "\n",
    "# path = os.path.join(args.finetune_data_dir, 'step_set_')\n",
    "# checkpath(path)\n",
    "\n",
    "# for get_id in range(PathDF.shape[0]):\n",
    "\n",
    "#     input, image, name = get_input_image(get_id, processor)\n",
    "#     _, logits = model_(input)\n",
    "#     color_seg = get_color_seg(logits, image)\n",
    "\n",
    "#     kokonopath = os.path.join(path, 'logits_' + name)\n",
    "#     cv2.imwrite(kokonopath, np.array(color_seg).astype(np.uint8))\n",
    "#     print(kokonopath)\n",
    "\n",
    "# print('\\n\\nSuccessfully Completed!!!\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb",
     "timestamp": 1677256490794
    }
   ]
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06768cfdf690415e9affdf2a74e59a30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17032952ca804b558931b93c0fde1540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc091016bb8d423f80dddca00096ba0b",
       "IPY_MODEL_6bbbd0d7f0f749939610ccc1aa47bfec",
       "IPY_MODEL_eb9b54187a9b4404b93ce96cb5297a1e"
      ],
      "layout": "IPY_MODEL_48854cfeccd84183a1819d703353a4fa"
     }
    },
    "1d94bafa0c204861869e3c8656f88338": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20faf3fda02c4257b5ac68099de45581": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23596ead25e842da821eee9281ddd44b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce5a59adc10e4ad3bbd5ee949704a493",
      "placeholder": "​",
      "style": "IPY_MODEL_2e92aabde375495f880ae9752b55e057",
      "value": " 4.64k/4.64k [00:00&lt;00:00, 115kB/s]"
     }
    },
    "2e92aabde375495f880ae9752b55e057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31ea43544fcd44a19f86c920afaa12ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3deab35d86db420c963d21fde4f4f770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d94bafa0c204861869e3c8656f88338",
      "placeholder": "​",
      "style": "IPY_MODEL_06768cfdf690415e9affdf2a74e59a30",
      "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
     }
    },
    "3e187d79da6f477180cac4b95d949388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48854cfeccd84183a1819d703353a4fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5528a5ca02bc4cde9fa1bad142519e35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79cc1507b29d4125ae5e3c704b2b8b75",
      "placeholder": "​",
      "style": "IPY_MODEL_31ea43544fcd44a19f86c920afaa12ab",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "55606bf393b940278f76baf65170eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bffaeb6f389499c958f4a12dca192e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5d806cd2fe7e4424b7fb90371815f4d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3deab35d86db420c963d21fde4f4f770",
       "IPY_MODEL_e3214b7f823d4a12bed90f36b6cd3bbe",
       "IPY_MODEL_6bec28962d4740aabe8e9896e00134b7"
      ],
      "layout": "IPY_MODEL_5da754b21ef34dc9a7eff14bdc3a34bc"
     }
    },
    "5da754b21ef34dc9a7eff14bdc3a34bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bbbd0d7f0f749939610ccc1aa47bfec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d8fcd96c2b44c1a21e6a0cf46d736d",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5bffaeb6f389499c958f4a12dca192e4",
      "value": 170498071
     }
    },
    "6bec28962d4740aabe8e9896e00134b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d083420df95d42ecb16cedd5037dc2a3",
      "placeholder": "​",
      "style": "IPY_MODEL_55606bf393b940278f76baf65170eeab",
      "value": " 223M/223M [00:02&lt;00:00, 86.7MB/s]"
     }
    },
    "73487b45ea444f8e81410a9627c85b40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79cc1507b29d4125ae5e3c704b2b8b75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cdb20bd656249fe85674962d2a4ba7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cf2f5d1a7894a73861ce8bd69675ed1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d8fcd96c2b44c1a21e6a0cf46d736d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeabbf27ff5e4ef5a0c3de652c86d632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5528a5ca02bc4cde9fa1bad142519e35",
       "IPY_MODEL_c3b291f042fe422aa3a2b22f1208d0ca",
       "IPY_MODEL_23596ead25e842da821eee9281ddd44b"
      ],
      "layout": "IPY_MODEL_d74ac37d81974a4780581b554f3e7d23"
     }
    },
    "c3b291f042fe422aa3a2b22f1208d0ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73487b45ea444f8e81410a9627c85b40",
      "max": 4642,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e187d79da6f477180cac4b95d949388",
      "value": 4642
     }
    },
    "cc091016bb8d423f80dddca00096ba0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cdb20bd656249fe85674962d2a4ba7e",
      "placeholder": "​",
      "style": "IPY_MODEL_20faf3fda02c4257b5ac68099de45581",
      "value": "100%"
     }
    },
    "ce5a59adc10e4ad3bbd5ee949704a493": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf90228e48af46809d35402d94eb568e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d083420df95d42ecb16cedd5037dc2a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d74ac37d81974a4780581b554f3e7d23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9070ee51e9c4ebe868777345a25a62d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3214b7f823d4a12bed90f36b6cd3bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f48ad91e88b340258d9fbe66bc58696b",
      "max": 223137427,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cf2f5d1a7894a73861ce8bd69675ed1",
      "value": 223137427
     }
    },
    "eb9b54187a9b4404b93ce96cb5297a1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9070ee51e9c4ebe868777345a25a62d",
      "placeholder": "​",
      "style": "IPY_MODEL_cf90228e48af46809d35402d94eb568e",
      "value": " 170498071/170498071 [00:14&lt;00:00, 14802420.28it/s]"
     }
    },
    "f48ad91e88b340258d9fbe66bc58696b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
